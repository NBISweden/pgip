[
  {
    "objectID": "exercises/population_structure/pca_mds_toy_example.html",
    "href": "exercises/population_structure/pca_mds_toy_example.html",
    "title": "PCA and MDS for population genetics",
    "section": "",
    "text": "In this notebook, we will learn similarities and differences between PCA and MDS and compute both of them from scratch.\n\n\nPCA is a matrix factorization (eigen value decomposition) problem that attempts to project the data into a low dimensional space that explains the largest amount of variance in the data. The motivation is that, if the data is high-dimensional, many features (axes) can be redundant, therefore one can reduce the number of dimensions and make the statistical analysis more robust in this way. Graphically, PCA can be viewed as rotation and shift of coordinate system where the original 2D data with XY-coordinates are replaced by e.g. 1D data as PC1 which keeps most of the variation in the data. Note, that some information can be lost in this way, however, it can be statistically very benificial to work with lower-dimensional data.\n\n\n\nidea of PCA\n\n\nIn population genetics, we typically work with genetic variation (genotype) data encoded as 0, 1 and 2 by the number of minor allele carrier in the sample. Let us generate a toy genotype matrix for 5 individuals and 7 genetic variants.\n\ngen &lt;- t(matrix(c(1, 0, 2, 0, 2, 0, 2, 1, 1, 1, 0, 1, 0, 2, 1, 2, 1, 1, 1, 1, 1, 0, 1, 0, 2, 0, 1, 1, 0, 2, 1, 2, 0, 1, 0), 5, by = TRUE))\ncolnames(gen) &lt;- paste0(\"Ind\", 1:5)\nrownames(gen) &lt;- paste0(\"SNP\", 1:7)\nprint(gen)\n\n     Ind1 Ind2 Ind3 Ind4 Ind5\nSNP1    1    1    1    0    0\nSNP2    0    1    2    1    2\nSNP3    2    1    1    0    1\nSNP4    0    0    1    2    2\nSNP5    2    1    1    0    0\nSNP6    0    0    1    1    1\nSNP7    2    2    1    1    0\n\n\nNow we are going to compute PCA from scratch in R. The PCA algorithm includes three steps:\n\nmean centering the data\ncomputing variance-covariance matrix\nperforming eigen value decomposition on the variance-covariance matrix\n\nBelow, we will implement the three steps with repsect to the genotype matrix, and display the fraction of variance explained by each principal component.\n\ngen_centered &lt;- scale(gen, center = TRUE, scale = FALSE) # mean centering\ncovariance &lt;- t(gen_centered) %*% gen_centered # computing variance-covariance matrix\neig &lt;- eigen(covariance) # performing eigen value decomposition of the variance-covariance matrix\n\nbarplot(eig$values / sum(eig$values), names = paste0(\"PC\", 1:5))\n\n\n\n\n\n\n\n\nFrom the barplot above we can conclude that PC1 explains most of the variation (approximately 70%) in the genotype data, while the other PCs explain limited amount of variation, therefore one can say that our original 7-dimensional data is essentially 1-dimensional, or can be approximated with only one dimension with good accuracy. In this way we dramatically reduced dimensionality of the data from seven to one. Finally, let us visualize the 5 generated samples in two-dimensional space, i.e. using the leading PC1 and PC2 variables.\n\nplot(eig$vectors[, 1:2], xlab = \"PC1\", ylab = \"PC2\", pch = 16, cex = 5, col = 2:6)\npoints(eig$vectors[, 1:2], pch = as.character(1:5))\n\n\n\n\n\n\n\n\n\n\n\nMultidimensional Scaling (MDS) is very closely related to PCA and sometimes used as a synonim. The idea of MDS is to project the data into a low dimensional space and preserve pairwise distances between data points as much as possible. Under the hood this is done by solving eigen value decomposition problem for a matrix of paiwise distances. Compare with PCA, where we did eigen value decomposition of a variance-covariance matrix, the latter can be sometimes viewed as a pairwise distance matrix. This is how MDS is related to PCA. Both do eigen value decomposition of some sort of matrix of pairwise distances. Note, some implementation of MDS do not perform eigen value decomposition but instead do a gradient descent minimization of euclidean distance between the original data and an approximation as a product of two matrices (loadings and scores). This represents an alternative, machine learning style of matrix factorization.\n\n\n\nmachine learning idea of MDS\n\n\nBelow, we will use the same genotype matrix as for PCA, and compute Manhattan distances between all pairs of data points, which is the sum of absolute values of pairwise genotype differences.\n\ngen &lt;- t(matrix(c(1, 0, 2, 0, 2, 0, 2, 1, 1, 1, 0, 1, 0, 2, 1, 2, 1, 1, 1, 1, 1,\n    0, 1, 0, 2, 0, 1, 1, 0, 2, 1, 2, 0, 1, 0), 5, by = TRUE))\ncolnames(gen) &lt;- paste0(\"Ind\", 1:5)\nrownames(gen) &lt;- paste0(\"SNP\", 1:7)\nprint(gen)\n\n     Ind1 Ind2 Ind3 Ind4 Ind5\nSNP1    1    1    1    0    0\nSNP2    0    1    2    1    2\nSNP3    2    1    1    0    1\nSNP4    0    0    1    2    2\nSNP5    2    1    1    0    0\nSNP6    0    0    1    1    1\nSNP7    2    2    1    1    0\n\n\n\nmy_dist &lt;- dist(t(gen), method = \"manhattan\", upper = TRUE, diag = TRUE)\nmy_dist\n\n     Ind1 Ind2 Ind3 Ind4 Ind5\nInd1    0    3    7   10   11\nInd2    3    0    4    7    8\nInd3    7    4    0    5    4\nInd4   10    7    5    0    3\nInd5   11    8    4    3    0\n\n\nHere, we can see that the Manhattan distance between for example individuals one and two is equal to 3 because there are three genotype differences at SNP2, SNP3 and SNP5. Now, we will use the cmdscale function in R that performs the classic / metric MDS. Under the hood this function does an eigen value decomposition of the matrix of pairwise Manhattan distances.\n\nmy_mds &lt;- cmdscale(my_dist)\nmy_mds\n\n\nA matrix: 5 × 2 of type dbl\n\n\nInd1\n-6.114866\n0.2977272\n\n\nInd2\n-3.077094\n0.2402932\n\n\nInd3\n0.621230\n-1.7944048\n\n\nInd4\n3.723118\n2.1483083\n\n\nInd5\n4.847612\n-0.8919238\n\n\n\n\n\nPlease take a look at the first latent variable in my_mds. Interestengly, if you look at the absolute value of the difference between e.g. individuals 1 and 2, it will be close to 3, between individuals 1 and 3 will be nearly 7 etc. This corresponds to the values in the pairwise Manhattan distances in the my_dist matrix above. Therefore, as it was emphasized previously, the point of MDS is to preserve pairwise distances while doing dimension reduction. Finally, let us visualize the 5 individuals in the MDS space and compare it with PCA.\n\nplot(my_mds, xlab = \"MDS1\", ylab = \"MDS2\", pch = 16, cex = 5, col = 6:2)\npoints(my_mds, pch = as.character(5:1))\n\n\n\n\n\n\n\n\nOverall, this picture looks quite similar to the PCA plot above. This is not suprising since both PCA and MDS are based on very similar principles, and typically agree with each other for real-world datasets."
  },
  {
    "objectID": "exercises/population_structure/pca_mds_toy_example.html#pca-for-population-genetics",
    "href": "exercises/population_structure/pca_mds_toy_example.html#pca-for-population-genetics",
    "title": "PCA and MDS for population genetics",
    "section": "",
    "text": "PCA is a matrix factorization (eigen value decomposition) problem that attempts to project the data into a low dimensional space that explains the largest amount of variance in the data. The motivation is that, if the data is high-dimensional, many features (axes) can be redundant, therefore one can reduce the number of dimensions and make the statistical analysis more robust in this way. Graphically, PCA can be viewed as rotation and shift of coordinate system where the original 2D data with XY-coordinates are replaced by e.g. 1D data as PC1 which keeps most of the variation in the data. Note, that some information can be lost in this way, however, it can be statistically very benificial to work with lower-dimensional data.\n\n\n\nidea of PCA\n\n\nIn population genetics, we typically work with genetic variation (genotype) data encoded as 0, 1 and 2 by the number of minor allele carrier in the sample. Let us generate a toy genotype matrix for 5 individuals and 7 genetic variants.\n\ngen &lt;- t(matrix(c(1, 0, 2, 0, 2, 0, 2, 1, 1, 1, 0, 1, 0, 2, 1, 2, 1, 1, 1, 1, 1, 0, 1, 0, 2, 0, 1, 1, 0, 2, 1, 2, 0, 1, 0), 5, by = TRUE))\ncolnames(gen) &lt;- paste0(\"Ind\", 1:5)\nrownames(gen) &lt;- paste0(\"SNP\", 1:7)\nprint(gen)\n\n     Ind1 Ind2 Ind3 Ind4 Ind5\nSNP1    1    1    1    0    0\nSNP2    0    1    2    1    2\nSNP3    2    1    1    0    1\nSNP4    0    0    1    2    2\nSNP5    2    1    1    0    0\nSNP6    0    0    1    1    1\nSNP7    2    2    1    1    0\n\n\nNow we are going to compute PCA from scratch in R. The PCA algorithm includes three steps:\n\nmean centering the data\ncomputing variance-covariance matrix\nperforming eigen value decomposition on the variance-covariance matrix\n\nBelow, we will implement the three steps with repsect to the genotype matrix, and display the fraction of variance explained by each principal component.\n\ngen_centered &lt;- scale(gen, center = TRUE, scale = FALSE) # mean centering\ncovariance &lt;- t(gen_centered) %*% gen_centered # computing variance-covariance matrix\neig &lt;- eigen(covariance) # performing eigen value decomposition of the variance-covariance matrix\n\nbarplot(eig$values / sum(eig$values), names = paste0(\"PC\", 1:5))\n\n\n\n\n\n\n\n\nFrom the barplot above we can conclude that PC1 explains most of the variation (approximately 70%) in the genotype data, while the other PCs explain limited amount of variation, therefore one can say that our original 7-dimensional data is essentially 1-dimensional, or can be approximated with only one dimension with good accuracy. In this way we dramatically reduced dimensionality of the data from seven to one. Finally, let us visualize the 5 generated samples in two-dimensional space, i.e. using the leading PC1 and PC2 variables.\n\nplot(eig$vectors[, 1:2], xlab = \"PC1\", ylab = \"PC2\", pch = 16, cex = 5, col = 2:6)\npoints(eig$vectors[, 1:2], pch = as.character(1:5))"
  },
  {
    "objectID": "exercises/population_structure/pca_mds_toy_example.html#mds-for-population-genetics",
    "href": "exercises/population_structure/pca_mds_toy_example.html#mds-for-population-genetics",
    "title": "PCA and MDS for population genetics",
    "section": "",
    "text": "Multidimensional Scaling (MDS) is very closely related to PCA and sometimes used as a synonim. The idea of MDS is to project the data into a low dimensional space and preserve pairwise distances between data points as much as possible. Under the hood this is done by solving eigen value decomposition problem for a matrix of paiwise distances. Compare with PCA, where we did eigen value decomposition of a variance-covariance matrix, the latter can be sometimes viewed as a pairwise distance matrix. This is how MDS is related to PCA. Both do eigen value decomposition of some sort of matrix of pairwise distances. Note, some implementation of MDS do not perform eigen value decomposition but instead do a gradient descent minimization of euclidean distance between the original data and an approximation as a product of two matrices (loadings and scores). This represents an alternative, machine learning style of matrix factorization.\n\n\n\nmachine learning idea of MDS\n\n\nBelow, we will use the same genotype matrix as for PCA, and compute Manhattan distances between all pairs of data points, which is the sum of absolute values of pairwise genotype differences.\n\ngen &lt;- t(matrix(c(1, 0, 2, 0, 2, 0, 2, 1, 1, 1, 0, 1, 0, 2, 1, 2, 1, 1, 1, 1, 1,\n    0, 1, 0, 2, 0, 1, 1, 0, 2, 1, 2, 0, 1, 0), 5, by = TRUE))\ncolnames(gen) &lt;- paste0(\"Ind\", 1:5)\nrownames(gen) &lt;- paste0(\"SNP\", 1:7)\nprint(gen)\n\n     Ind1 Ind2 Ind3 Ind4 Ind5\nSNP1    1    1    1    0    0\nSNP2    0    1    2    1    2\nSNP3    2    1    1    0    1\nSNP4    0    0    1    2    2\nSNP5    2    1    1    0    0\nSNP6    0    0    1    1    1\nSNP7    2    2    1    1    0\n\n\n\nmy_dist &lt;- dist(t(gen), method = \"manhattan\", upper = TRUE, diag = TRUE)\nmy_dist\n\n     Ind1 Ind2 Ind3 Ind4 Ind5\nInd1    0    3    7   10   11\nInd2    3    0    4    7    8\nInd3    7    4    0    5    4\nInd4   10    7    5    0    3\nInd5   11    8    4    3    0\n\n\nHere, we can see that the Manhattan distance between for example individuals one and two is equal to 3 because there are three genotype differences at SNP2, SNP3 and SNP5. Now, we will use the cmdscale function in R that performs the classic / metric MDS. Under the hood this function does an eigen value decomposition of the matrix of pairwise Manhattan distances.\n\nmy_mds &lt;- cmdscale(my_dist)\nmy_mds\n\n\nA matrix: 5 × 2 of type dbl\n\n\nInd1\n-6.114866\n0.2977272\n\n\nInd2\n-3.077094\n0.2402932\n\n\nInd3\n0.621230\n-1.7944048\n\n\nInd4\n3.723118\n2.1483083\n\n\nInd5\n4.847612\n-0.8919238\n\n\n\n\n\nPlease take a look at the first latent variable in my_mds. Interestengly, if you look at the absolute value of the difference between e.g. individuals 1 and 2, it will be close to 3, between individuals 1 and 3 will be nearly 7 etc. This corresponds to the values in the pairwise Manhattan distances in the my_dist matrix above. Therefore, as it was emphasized previously, the point of MDS is to preserve pairwise distances while doing dimension reduction. Finally, let us visualize the 5 individuals in the MDS space and compare it with PCA.\n\nplot(my_mds, xlab = \"MDS1\", ylab = \"MDS2\", pch = 16, cex = 5, col = 6:2)\npoints(my_mds, pch = as.character(5:1))\n\n\n\n\n\n\n\n\nOverall, this picture looks quite similar to the PCA plot above. This is not suprising since both PCA and MDS are based on very similar principles, and typically agree with each other for real-world datasets."
  },
  {
    "objectID": "recipes/slides/index.html",
    "href": "recipes/slides/index.html",
    "title": "\n1 Recipes in slides",
    "section": "",
    "text": "Code to generate Hardy-Weinberg equilibrium plot.\n\nBash script to download data from 1000 genomeswget https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz\nwget https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz.tbi\nwget https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20130502.ALL.panel\n\n# Make population-specific sample files\npanel=integrated_call_samples_v3.20130502.ALL.panel\nawk '{if ($2 == \"CEU\") print $1}' $panel &gt; CEU.samples.txt\nawk '{if ($2 == \"CHB\") print $1}' $panel &gt; CHB.samples.txt\nawk '{if ($2 == \"YRI\") print $1}' $panel &gt; YRI.samples.txt\n\n# Subset vcf to these files\nVCF=ALL.chr22.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz\nREGION=22:17000000-20000000\nfor pop in CEU CHB YRI; do\n    echo $pop\n    bcftools view -v snps -m 2 -M 2 -S $pop.samples.txt $VCF $REGION | bgzip -c &gt; $pop.$REGION.vcf.gz\n    tabix -f $pop.$REGION.vcf.gz\n    plink --vcf $pop.$REGION.vcf.gz --hardy --out $pop.$REGION\n    gzip -v $pop.${REGION}.hwe\ndone\n\n\n\nR code to plot HWE proportions# Read genotypes from files generated by hwe.sh\npops &lt;- c(\"CEU\", \"CHB\", \"YRI\")\nfn &lt;- file.path(\"data/Homo_sapiens/1000g/genotypes\", paste0(pops, \".22:17000000-20000000.hwe.gz\"))\nnames(fn) &lt;- pops\n# Make data frame from all populations\nx &lt;- do.call(\"rbind\", lapply(pops, function(p) {\n    y &lt;- cbind(population = p, read.table(fn[[p]], header = TRUE))\n    # GENO column holds genotypes as minor/het/major counts.\n    geno &lt;- do.call(\"rbind\", lapply(strsplit(y$GENO, \"/\"), as.numeric))\n    # Find n that splits geno in two equally sized lists\n    n &lt;- round(nrow(geno)/2)\n    # Because minor is always less than 50, we need to reverse the order of\n    # half of the genotypes to produce nicer plots\n    geno &lt;- rbind(geno[1:n, ], geno[(n + 1):nrow(geno), 3:1])\n    colnames(geno) &lt;- c(\"AA.cnt\", \"Aa.cnt\", \"aa.cnt\")\n    # Normalize counts to frequencies\n    geno_frq &lt;- as.data.frame(geno/apply(geno, 1, sum))\n    colnames(geno_frq) &lt;- c(\"AA\", \"Aa\", \"aa\")\n    # Calculate allele frequencies under HWE assumption\n    allele_frq &lt;- as.data.frame(cbind(geno_frq$AA + 0.5 * geno_frq$Aa, geno_frq$aa +\n        0.5 * geno_frq$Aa))\n    colnames(allele_frq) &lt;- c(\"p\", \"q\")\n    # Make one large table with genotypes, genotype frequencies, and allele\n    # frequencies\n    cbind(y, geno, geno_frq, allele_frq)\n}))\n# Pivot genotypes to value column\nx &lt;- pivot_longer(x, cols = c(\"AA\", \"Aa\", \"aa\"), names_to = \"genotype\")\np &lt;- seq(0, 1, 0.01)\nn &lt;- 10000\n# Sample 10000 snps from each population\nz &lt;- do.call(\"rbind\", by(x, x$population, function(y) {\n    y[sample(nrow(y), 10000), ]\n}))\nz$population &lt;- factor(z$population)\nlevels(z$population) &lt;- c(\"European\", \"Chinese\", \"Yoruban\")\n\n# Plotting colors\nvend &lt;- 0.8\ncols_hwe &lt;- c(viridis_pal(end = vend)(3), \"black\", \"black\")\nlt_hwe &lt;- c(rep(\"blank\", 3), \"dashed\", \"solid\")\nshape_hwe &lt;- c(rep(16, 3), NA, NA)\ncnames &lt;- c(\"aa\", \"Aa\", \"AA\", \"Hardy Weinberg Equilibrium\", \"Mean\")\nnames(cols_hwe) &lt;- cnames\nnames(lt_hwe) &lt;- cnames\nnames(shape_hwe) &lt;- cnames\n\n# Make plot\nggplot(z, aes(x = p, y = value)) + geom_point(size = 2, alpha = 0.6, aes(color = genotype)) +\n    geom_smooth(method = \"loess\", linewidth = 1, show.legend = TRUE, lty = \"dashed\",\n        aes(group = genotype, color = \"Mean\")) + geom_line(inherit.aes = FALSE, aes(x = p,\n    y = p^2, color = \"Hardy Weinberg Equilibrium\")) + geom_line(inherit.aes = FALSE,\n    aes(x = p, y = 2 * p * (1 - p), color = \"Hardy Weinberg Equilibrium\")) + geom_line(inherit.aes = FALSE,\n    aes(x = p, y = (1 - p)^2, color = \"Hardy Weinberg Equilibrium\")) + xlab(\"allele frequency\") +\n    ylab(\"genotype frequency\") + facet_grid(. ~ population) + scale_color_viridis_d(end = vend) +\n    scale_color_manual(name = NULL, values = cols_hwe, guide = guide_legend(override.aes = list(linetype = lt_hwe,\n        shape = shape_hwe)))\n\n\n\n\nR code to generate and plot allele frequency distribution# Recipe to generate genetic drift histogram. The procedure consists of\n# tracking a fixed number of allelic states for a system with two alleles (say,\n# a and A), where the variable x corresponds to the *probability* of being in a\n# particular state. Default setting reproduce the data in Figure 3.4 in The\n# neutral theory of molecular evolution (Kimura, 1983).\n\nlibrary(expm)  # Matrix exponential library\n\n# Number of possible allelic states. Setting this too large results in a\n# prohibitively large transition matrix\nn &lt;- 10\n\n# The x vector traces the *probability* of samples/sequences in a given allelic\n# state, where x[1]=probability of fixation for allele a, x[n+1]=probability of\n# fixation for allele A, x[i]=i/n, i=2,..., n, probability of being in state i\n# (i alleles of type a, n-i alleles of type A)\nx &lt;- vector(mode = \"numeric\", length = n + 1)  # Init x to vector of 0's\n\n# Start with state n_a = n_A; find the index corresponding to the state with\n# number of a alleles = number of A alleles and set to 1\nn_a &lt;- ceiling(length(x)/2)\nx[n_a] &lt;- 1\n\n# States 1, n+1 are absorbing states (alleles are fixed)\nclass &lt;- c(\"absorbing\", rep(\"normal\", n - 1), \"absorbing\")\nclass_col &lt;- c(\"black\", rep(\"white\", n - 1), \"black\")\n\n# Make transition matrix, where an entry p_ij states the probability of\n# transitioning from a state (i, n-i) with i alleles of type a, (n-i) alleles\n# of type A, to state (j, n-j)\ntransmat &lt;- do.call(\"rbind\", lapply(0:n, function(i) {\n    dbinom(0:n, n, i/n)\n}))\n\n# Number of generations\nt &lt;- 30\n\n# The distribution at any time point is given as the initial distribution x\n# times the transition matrix to the power of t\ndata &lt;- t(x %*% (transmat %^% t))\n\n# Make labels corresponding to the fraction of a alleles\nxlabels &lt;- unlist(lapply(0:n, function(x) {\n    sprintf(\"frac(%i, %i)\", x, n)\n}))\nxl &lt;- do.call(c, lapply(xlabels, function(l) {\n    parse(text = l)\n}))\n# Plot the results\nbarplot(height = data, beside = TRUE, col = class_col, names.arg = xl)\n\n\n\n\nR code to download dn/ds data for H.sapiens versus R.norvegicus from ensembl and plotfn &lt;- \"assets/data/hsapiens_rat.dnds.tsv\"\nif (!file.exists(fn)) {\n    library(biomaRt)\n    ensembl &lt;- useEnsembl(version = 99, biomart = \"ENSEMBL_MART_ENSEMBL\", dataset = \"hsapiens_gene_ensembl\")\n    genes &lt;- getBM(mart = ensembl, attributes = c(\"ensembl_gene_id\"))\n    hsapiens_rat &lt;- getBM(attributes = c(\"ensembl_gene_id\", \"rnorvegicus_homolog_ensembl_gene\",\n        \"rnorvegicus_homolog_dn\", \"rnorvegicus_homolog_ds\", \"rnorvegicus_homolog_orthology_type\"),\n        filters = \"ensembl_gene_id\", values = genes$ensembl_gene_id, mart = ensembl)\n    hsapiens_rat &lt;- subset(hsapiens_rat, !is.na(rnorvegicus_homolog_ds) & !is.na(rnorvegicus_homolog_dn) &\n        rnorvegicus_homolog_orthology_type == \"ortholog_one2one\")\n    hsapiens_rat$dnds &lt;- hsapiens_rat$rnorvegicus_homolog_dn/hsapiens_rat$rnorvegicus_homolog_ds\n    hsapiens_rat &lt;- subset(hsapiens_rat, !is.nan(dnds))\n    write.table(hsapiens_rat, file = \"assets/data/hsapiens_rat.dnds.tsv\", sep = \"\\t\",\n        quote = FALSE, row.names = FALSE)\n}\nx &lt;- read.table(fn, header = TRUE)\nggplot(x, aes(x = dnds)) + geom_histogram(bins = 100, aes(y = ..count../sum(..count..)),\n    fill = \"white\", color = \"black\") + xlim(0, 2) + xlab(expression(d[n] ~ \"/\" ~\n    d[s])) + ylab(\"Frequency\") + ggtitle(paste0(nrow(x), \" human-rat orthologue pairs\"))\n\n\n\n\n\nPython code to generate four coalescent trees under different evolutionary scenarios.import msprime\n\n\ndef tree_topology(\n    model,\n    *,\n    svgid,\n    size=(300, 500),\n    x_axis=False,\n    node_labels={},\n    symbol_size=0,\n    style=\".edge {stroke-width: 2px}\",\n):\n    \"\"\"Plot tree topology under different evolutionary scenarios\"\"\"\n    kwargs = dict(\n        size=size,\n        x_axis=x_axis,\n        node_labels=node_labels,\n        symbol_size=symbol_size,\n        style=f\"#{svgid} {{ {style} }}\",\n        root_svg_attributes={\"id\": svgid},\n    )\n    if model == \"neutral\":\n        ts = msprime.sim_ancestry(10, random_seed=12)\n    elif model == \"expansion\":\n        demography = msprime.Demography()\n        demography.add_population(name=\"A\", initial_size=10_000, growth_rate=0.1)\n        ts = msprime.sim_ancestry(\n            samples={\"A\": 10}, demography=demography, random_seed=12\n        )\n    elif model == \"bottleneck\":\n        demography = msprime.Demography()\n        demography.add_population(name=\"A\", initial_size=1_000)\n        demography.add_instantaneous_bottleneck(time=100, strength=1000, population=0)\n        ts = msprime.sim_ancestry(\n            samples={\"A\": 10}, demography=demography, random_seed=12\n        )\n    elif model == \"selection\":\n        Ne = 1_000\n        L = 1e6\n        sweep_model = msprime.SweepGenicSelection(\n            position=L / 2,\n            start_frequency=1.0 / (2 * Ne),\n            end_frequency=1.0 - (1.0 / (2 * Ne)),\n            s=0.25,\n            dt=1e-6,\n        )\n        ts = msprime.sim_ancestry(\n            10,\n            model=[sweep_model, msprime.StandardCoalescent()],\n            population_size=Ne,\n            sequence_length=L,\n            random_seed=119,\n        )\n    return ts.draw_svg(**kwargs)\n\n\n\n\n\nPython code to generate example coalescent trees.import msprime\nimport pandas as pd\n\n# Small tree for calculation purposes\nts_small = msprime.sim_ancestry(2, sequence_length=1e4, random_seed=38)\nts_small_mut = msprime.sim_mutations(ts_small, rate=3e-5, random_seed=4)\n\n# Balancing selection topology\nts_small_balance = msprime.sim_ancestry(2, sequence_length=1e4, random_seed=7)\nts_small_balance_mut = msprime.sim_mutations(\n    ts_small_balance, rate=2.5e-5, random_seed=7\n)\n\n\ndef genotypes(ts, *, sample_names=True, sample_prefix=\"sample \", collapse=True):\n    gt = ts.genotype_matrix().T\n    x = pd.DataFrame(gt)\n    if collapse:\n        x = x.apply(lambda row: \"\".join(row.values.astype(str)), axis=1)\n    if sample_names:\n        x.index = [f\"{sample_prefix}{i}\" for i in x.index]\n    return x\n\n\ndef plot_tree(\n    ts, *, id_string, show_sequences=True, node_labels=dict(), size=(250, 300), **kwargs\n):\n    css_extra = kwargs.pop(\"css_extra\", \"\")\n    css_string = (\n        \".edge {stroke: black; stroke-width: 3px}\"\n        \".node &gt; .lab {text-anchor: end; transform: rotate(-45deg) translate(-5px, 8px);}\"\n        \".node &gt; .sym, .node:not(.leaf) &gt; .lab {display: none}\"\n        \".node:not(.leaf) &gt; .lab {display: none}\"\n    ) + css_extra\n    css = kwargs.pop(\"css_string\", css_string)\n    node_labels = kwargs.pop(\"node_labels\", None)\n    if show_sequences:\n        node_labels = dict()\n        for ind in range(ts.num_samples):\n            node_labels[ind] = f\"{ind}: \" + \"\".join(\n                [str(x) for x in ts.genotype_matrix()[:, ind]]\n            )\n    style = f\"#{id_string} {{\" + css + \"}\"\n    return ts.draw_svg(\n        size=size,\n        node_labels=node_labels,\n        style=style,\n        root_svg_attributes={\"id\": id_string},\n        **kwargs,\n    )"
  },
  {
    "objectID": "recipes/slides/index.html#foundations",
    "href": "recipes/slides/index.html#foundations",
    "title": "\n1 Recipes in slides",
    "section": "",
    "text": "Code to generate Hardy-Weinberg equilibrium plot.\n\nBash script to download data from 1000 genomeswget https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz\nwget https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz.tbi\nwget https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20130502.ALL.panel\n\n# Make population-specific sample files\npanel=integrated_call_samples_v3.20130502.ALL.panel\nawk '{if ($2 == \"CEU\") print $1}' $panel &gt; CEU.samples.txt\nawk '{if ($2 == \"CHB\") print $1}' $panel &gt; CHB.samples.txt\nawk '{if ($2 == \"YRI\") print $1}' $panel &gt; YRI.samples.txt\n\n# Subset vcf to these files\nVCF=ALL.chr22.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz\nREGION=22:17000000-20000000\nfor pop in CEU CHB YRI; do\n    echo $pop\n    bcftools view -v snps -m 2 -M 2 -S $pop.samples.txt $VCF $REGION | bgzip -c &gt; $pop.$REGION.vcf.gz\n    tabix -f $pop.$REGION.vcf.gz\n    plink --vcf $pop.$REGION.vcf.gz --hardy --out $pop.$REGION\n    gzip -v $pop.${REGION}.hwe\ndone\n\n\n\nR code to plot HWE proportions# Read genotypes from files generated by hwe.sh\npops &lt;- c(\"CEU\", \"CHB\", \"YRI\")\nfn &lt;- file.path(\"data/Homo_sapiens/1000g/genotypes\", paste0(pops, \".22:17000000-20000000.hwe.gz\"))\nnames(fn) &lt;- pops\n# Make data frame from all populations\nx &lt;- do.call(\"rbind\", lapply(pops, function(p) {\n    y &lt;- cbind(population = p, read.table(fn[[p]], header = TRUE))\n    # GENO column holds genotypes as minor/het/major counts.\n    geno &lt;- do.call(\"rbind\", lapply(strsplit(y$GENO, \"/\"), as.numeric))\n    # Find n that splits geno in two equally sized lists\n    n &lt;- round(nrow(geno)/2)\n    # Because minor is always less than 50, we need to reverse the order of\n    # half of the genotypes to produce nicer plots\n    geno &lt;- rbind(geno[1:n, ], geno[(n + 1):nrow(geno), 3:1])\n    colnames(geno) &lt;- c(\"AA.cnt\", \"Aa.cnt\", \"aa.cnt\")\n    # Normalize counts to frequencies\n    geno_frq &lt;- as.data.frame(geno/apply(geno, 1, sum))\n    colnames(geno_frq) &lt;- c(\"AA\", \"Aa\", \"aa\")\n    # Calculate allele frequencies under HWE assumption\n    allele_frq &lt;- as.data.frame(cbind(geno_frq$AA + 0.5 * geno_frq$Aa, geno_frq$aa +\n        0.5 * geno_frq$Aa))\n    colnames(allele_frq) &lt;- c(\"p\", \"q\")\n    # Make one large table with genotypes, genotype frequencies, and allele\n    # frequencies\n    cbind(y, geno, geno_frq, allele_frq)\n}))\n# Pivot genotypes to value column\nx &lt;- pivot_longer(x, cols = c(\"AA\", \"Aa\", \"aa\"), names_to = \"genotype\")\np &lt;- seq(0, 1, 0.01)\nn &lt;- 10000\n# Sample 10000 snps from each population\nz &lt;- do.call(\"rbind\", by(x, x$population, function(y) {\n    y[sample(nrow(y), 10000), ]\n}))\nz$population &lt;- factor(z$population)\nlevels(z$population) &lt;- c(\"European\", \"Chinese\", \"Yoruban\")\n\n# Plotting colors\nvend &lt;- 0.8\ncols_hwe &lt;- c(viridis_pal(end = vend)(3), \"black\", \"black\")\nlt_hwe &lt;- c(rep(\"blank\", 3), \"dashed\", \"solid\")\nshape_hwe &lt;- c(rep(16, 3), NA, NA)\ncnames &lt;- c(\"aa\", \"Aa\", \"AA\", \"Hardy Weinberg Equilibrium\", \"Mean\")\nnames(cols_hwe) &lt;- cnames\nnames(lt_hwe) &lt;- cnames\nnames(shape_hwe) &lt;- cnames\n\n# Make plot\nggplot(z, aes(x = p, y = value)) + geom_point(size = 2, alpha = 0.6, aes(color = genotype)) +\n    geom_smooth(method = \"loess\", linewidth = 1, show.legend = TRUE, lty = \"dashed\",\n        aes(group = genotype, color = \"Mean\")) + geom_line(inherit.aes = FALSE, aes(x = p,\n    y = p^2, color = \"Hardy Weinberg Equilibrium\")) + geom_line(inherit.aes = FALSE,\n    aes(x = p, y = 2 * p * (1 - p), color = \"Hardy Weinberg Equilibrium\")) + geom_line(inherit.aes = FALSE,\n    aes(x = p, y = (1 - p)^2, color = \"Hardy Weinberg Equilibrium\")) + xlab(\"allele frequency\") +\n    ylab(\"genotype frequency\") + facet_grid(. ~ population) + scale_color_viridis_d(end = vend) +\n    scale_color_manual(name = NULL, values = cols_hwe, guide = guide_legend(override.aes = list(linetype = lt_hwe,\n        shape = shape_hwe)))\n\n\n\n\nR code to generate and plot allele frequency distribution# Recipe to generate genetic drift histogram. The procedure consists of\n# tracking a fixed number of allelic states for a system with two alleles (say,\n# a and A), where the variable x corresponds to the *probability* of being in a\n# particular state. Default setting reproduce the data in Figure 3.4 in The\n# neutral theory of molecular evolution (Kimura, 1983).\n\nlibrary(expm)  # Matrix exponential library\n\n# Number of possible allelic states. Setting this too large results in a\n# prohibitively large transition matrix\nn &lt;- 10\n\n# The x vector traces the *probability* of samples/sequences in a given allelic\n# state, where x[1]=probability of fixation for allele a, x[n+1]=probability of\n# fixation for allele A, x[i]=i/n, i=2,..., n, probability of being in state i\n# (i alleles of type a, n-i alleles of type A)\nx &lt;- vector(mode = \"numeric\", length = n + 1)  # Init x to vector of 0's\n\n# Start with state n_a = n_A; find the index corresponding to the state with\n# number of a alleles = number of A alleles and set to 1\nn_a &lt;- ceiling(length(x)/2)\nx[n_a] &lt;- 1\n\n# States 1, n+1 are absorbing states (alleles are fixed)\nclass &lt;- c(\"absorbing\", rep(\"normal\", n - 1), \"absorbing\")\nclass_col &lt;- c(\"black\", rep(\"white\", n - 1), \"black\")\n\n# Make transition matrix, where an entry p_ij states the probability of\n# transitioning from a state (i, n-i) with i alleles of type a, (n-i) alleles\n# of type A, to state (j, n-j)\ntransmat &lt;- do.call(\"rbind\", lapply(0:n, function(i) {\n    dbinom(0:n, n, i/n)\n}))\n\n# Number of generations\nt &lt;- 30\n\n# The distribution at any time point is given as the initial distribution x\n# times the transition matrix to the power of t\ndata &lt;- t(x %*% (transmat %^% t))\n\n# Make labels corresponding to the fraction of a alleles\nxlabels &lt;- unlist(lapply(0:n, function(x) {\n    sprintf(\"frac(%i, %i)\", x, n)\n}))\nxl &lt;- do.call(c, lapply(xlabels, function(l) {\n    parse(text = l)\n}))\n# Plot the results\nbarplot(height = data, beside = TRUE, col = class_col, names.arg = xl)\n\n\n\n\nR code to download dn/ds data for H.sapiens versus R.norvegicus from ensembl and plotfn &lt;- \"assets/data/hsapiens_rat.dnds.tsv\"\nif (!file.exists(fn)) {\n    library(biomaRt)\n    ensembl &lt;- useEnsembl(version = 99, biomart = \"ENSEMBL_MART_ENSEMBL\", dataset = \"hsapiens_gene_ensembl\")\n    genes &lt;- getBM(mart = ensembl, attributes = c(\"ensembl_gene_id\"))\n    hsapiens_rat &lt;- getBM(attributes = c(\"ensembl_gene_id\", \"rnorvegicus_homolog_ensembl_gene\",\n        \"rnorvegicus_homolog_dn\", \"rnorvegicus_homolog_ds\", \"rnorvegicus_homolog_orthology_type\"),\n        filters = \"ensembl_gene_id\", values = genes$ensembl_gene_id, mart = ensembl)\n    hsapiens_rat &lt;- subset(hsapiens_rat, !is.na(rnorvegicus_homolog_ds) & !is.na(rnorvegicus_homolog_dn) &\n        rnorvegicus_homolog_orthology_type == \"ortholog_one2one\")\n    hsapiens_rat$dnds &lt;- hsapiens_rat$rnorvegicus_homolog_dn/hsapiens_rat$rnorvegicus_homolog_ds\n    hsapiens_rat &lt;- subset(hsapiens_rat, !is.nan(dnds))\n    write.table(hsapiens_rat, file = \"assets/data/hsapiens_rat.dnds.tsv\", sep = \"\\t\",\n        quote = FALSE, row.names = FALSE)\n}\nx &lt;- read.table(fn, header = TRUE)\nggplot(x, aes(x = dnds)) + geom_histogram(bins = 100, aes(y = ..count../sum(..count..)),\n    fill = \"white\", color = \"black\") + xlim(0, 2) + xlab(expression(d[n] ~ \"/\" ~\n    d[s])) + ylab(\"Frequency\") + ggtitle(paste0(nrow(x), \" human-rat orthologue pairs\"))"
  },
  {
    "objectID": "recipes/slides/index.html#simulation",
    "href": "recipes/slides/index.html#simulation",
    "title": "\n1 Recipes in slides",
    "section": "",
    "text": "Python code to generate four coalescent trees under different evolutionary scenarios.import msprime\n\n\ndef tree_topology(\n    model,\n    *,\n    svgid,\n    size=(300, 500),\n    x_axis=False,\n    node_labels={},\n    symbol_size=0,\n    style=\".edge {stroke-width: 2px}\",\n):\n    \"\"\"Plot tree topology under different evolutionary scenarios\"\"\"\n    kwargs = dict(\n        size=size,\n        x_axis=x_axis,\n        node_labels=node_labels,\n        symbol_size=symbol_size,\n        style=f\"#{svgid} {{ {style} }}\",\n        root_svg_attributes={\"id\": svgid},\n    )\n    if model == \"neutral\":\n        ts = msprime.sim_ancestry(10, random_seed=12)\n    elif model == \"expansion\":\n        demography = msprime.Demography()\n        demography.add_population(name=\"A\", initial_size=10_000, growth_rate=0.1)\n        ts = msprime.sim_ancestry(\n            samples={\"A\": 10}, demography=demography, random_seed=12\n        )\n    elif model == \"bottleneck\":\n        demography = msprime.Demography()\n        demography.add_population(name=\"A\", initial_size=1_000)\n        demography.add_instantaneous_bottleneck(time=100, strength=1000, population=0)\n        ts = msprime.sim_ancestry(\n            samples={\"A\": 10}, demography=demography, random_seed=12\n        )\n    elif model == \"selection\":\n        Ne = 1_000\n        L = 1e6\n        sweep_model = msprime.SweepGenicSelection(\n            position=L / 2,\n            start_frequency=1.0 / (2 * Ne),\n            end_frequency=1.0 - (1.0 / (2 * Ne)),\n            s=0.25,\n            dt=1e-6,\n        )\n        ts = msprime.sim_ancestry(\n            10,\n            model=[sweep_model, msprime.StandardCoalescent()],\n            population_size=Ne,\n            sequence_length=L,\n            random_seed=119,\n        )\n    return ts.draw_svg(**kwargs)"
  },
  {
    "objectID": "recipes/slides/index.html#genetic-diversity",
    "href": "recipes/slides/index.html#genetic-diversity",
    "title": "\n1 Recipes in slides",
    "section": "",
    "text": "Python code to generate example coalescent trees.import msprime\nimport pandas as pd\n\n# Small tree for calculation purposes\nts_small = msprime.sim_ancestry(2, sequence_length=1e4, random_seed=38)\nts_small_mut = msprime.sim_mutations(ts_small, rate=3e-5, random_seed=4)\n\n# Balancing selection topology\nts_small_balance = msprime.sim_ancestry(2, sequence_length=1e4, random_seed=7)\nts_small_balance_mut = msprime.sim_mutations(\n    ts_small_balance, rate=2.5e-5, random_seed=7\n)\n\n\ndef genotypes(ts, *, sample_names=True, sample_prefix=\"sample \", collapse=True):\n    gt = ts.genotype_matrix().T\n    x = pd.DataFrame(gt)\n    if collapse:\n        x = x.apply(lambda row: \"\".join(row.values.astype(str)), axis=1)\n    if sample_names:\n        x.index = [f\"{sample_prefix}{i}\" for i in x.index]\n    return x\n\n\ndef plot_tree(\n    ts, *, id_string, show_sequences=True, node_labels=dict(), size=(250, 300), **kwargs\n):\n    css_extra = kwargs.pop(\"css_extra\", \"\")\n    css_string = (\n        \".edge {stroke: black; stroke-width: 3px}\"\n        \".node &gt; .lab {text-anchor: end; transform: rotate(-45deg) translate(-5px, 8px);}\"\n        \".node &gt; .sym, .node:not(.leaf) &gt; .lab {display: none}\"\n        \".node:not(.leaf) &gt; .lab {display: none}\"\n    ) + css_extra\n    css = kwargs.pop(\"css_string\", css_string)\n    node_labels = kwargs.pop(\"node_labels\", None)\n    if show_sequences:\n        node_labels = dict()\n        for ind in range(ts.num_samples):\n            node_labels[ind] = f\"{ind}: \" + \"\".join(\n                [str(x) for x in ts.genotype_matrix()[:, ind]]\n            )\n    style = f\"#{id_string} {{\" + css + \"}\"\n    return ts.draw_svg(\n        size=size,\n        node_labels=node_labels,\n        style=style,\n        root_svg_attributes={\"id\": id_string},\n        **kwargs,\n    )"
  },
  {
    "objectID": "recipes/index.html",
    "href": "recipes/index.html",
    "title": "Code recipes",
    "section": "",
    "text": "08-Nov-2023: This page is under construction!"
  },
  {
    "objectID": "recipes/index.html#slides",
    "href": "recipes/index.html#slides",
    "title": "Code recipes",
    "section": "Slides",
    "text": "Slides\nCollection of recipes to generate data and figures for lecture notes. For full listing, see slides/index.html."
  },
  {
    "objectID": "recipes/index.html#slim-recipes",
    "href": "recipes/index.html#slim-recipes",
    "title": "Code recipes",
    "section": "SLiM recipes",
    "text": "SLiM recipes\nCollection of SLiM recipes (Haller, Ben, 2016) used to generate figures and examples. See slim/index.html for full listing."
  },
  {
    "objectID": "slides/demography/index.html",
    "href": "slides/demography/index.html",
    "title": "Demographic inference",
    "section": "",
    "text": "Important\n\n\n\nSlides uploaded as PDF files."
  },
  {
    "objectID": "slides/genetic_diversity/index.html#what-determines-diversity-levels",
    "href": "slides/genetic_diversity/index.html#what-determines-diversity-levels",
    "title": "Genetic diversity",
    "section": "What determines diversity levels?",
    "text": "What determines diversity levels?\n\n\n\n\n\n\n\n\nThe usual questions:\n\nWhat evolutionary forces maintain genetic diversity in natural populations? How do diversity levels relate to census population sizes…? Do low levels of diversity limit adaptation to selective pressures?\n\n\nLeffler et al. (2012)\n\n\n\nAfter allozyme era, the study of genetic diversity was largely neglected due to lack of genome-wide data, but with advent of population genomics becoming a hot topic again.\n\nEllegren & Galtier (2016)\n\n\n\nLewontin’s paradox: genetic diversity range smaller than variation among species in population size\n\n\n\n\nRiddle: why is genetic diversity range so narrow? Possibly there are lower and upper limits.\nLower limit: censoring effect, i.e., when diversity passes a lower limit, population is driven to extinction due to inability to adapt\nUpper limit: functional/structural constraints, e.g., impaired chromosome pairing or reproductive incompatibilities\nLinked selection, that is, variation-reducing selection. Larger populations have higher influx of new mutations, so if more draft, higher reduction in diversity. Would require strong frequent levels of selection; little support for this in literature.\nPurifying selection. Nearly neutral model could explain narrow range.\n(Ellegren & Galtier, 2016) Upper limit could in part be explained by linked selection (Corbett-Detig et al., 2015)"
  },
  {
    "objectID": "slides/genetic_diversity/index.html#factors-that-influence-genetic-diversity",
    "href": "slides/genetic_diversity/index.html#factors-that-influence-genetic-diversity",
    "title": "Genetic diversity",
    "section": "Factors that influence genetic diversity",
    "text": "Factors that influence genetic diversity\n\n\n\n\n\n\nFigure 1: Overview of determinants of genetic diversity (Ellegren & Galtier, 2016, Fig 2)\n\n\n\n\n\n\nGenetic drift\nReduces diversity at loss \\(\\propto \\frac{1}{N}\\)\nSelection\nAdaptive selection decreases variation, more so if acting on new mutations compared to standing variation.\nBalancing selection may increase variation.\nRecombination\nLow recombination rates lead to less “reshuffling” of variation and hence lower diversity.\n\n\n\nNote: lower recombination lowers diversity presumably because more neutral variants linked to selected sites. There are intriguing differences between taxa (Leffler et al., 2012)\nEllegren & Galtier (2016) point out that with advent of population genomic data, we are at the brink of understanding Lewontin’s paradox, namely (Charlesworth & Jensen, 2022)\n\nthe observation that the range of levels of genetic diversity in natural populations appears to be far smaller than the extent of variation among species in population size"
  },
  {
    "objectID": "slides/genetic_diversity/index.html#why-we-measure-patterns-of-genetic-variation",
    "href": "slides/genetic_diversity/index.html#why-we-measure-patterns-of-genetic-variation",
    "title": "Genetic diversity",
    "section": "Why we measure patterns of genetic variation",
    "text": "Why we measure patterns of genetic variation\nGenetic variation patterns are informative of evolutionary and demographic processes. We often use summary statistics to describe the patterns, and to estimate parameters such as effective population size and mutation rate from genetic variation data (\\(\\theta = 4N_e\\mu\\))\n\n\nOften critical first step of analysis, such as\n\nexploratory study\ntest of an evolutionary hypothesis\ntraining of machine-learning models\n\n\n\n(Korunes & Samuk, 2021)"
  },
  {
    "objectID": "slides/genetic_diversity/index.html#genetic-diversity-in-conservation-biology",
    "href": "slides/genetic_diversity/index.html#genetic-diversity-in-conservation-biology",
    "title": "Genetic diversity",
    "section": "Genetic diversity in conservation biology",
    "text": "Genetic diversity in conservation biology\n\n\n\n\nKuderna et al. (2023), Fig 2\n\n\n\n\n…no global relationship between numerically coded IUCN extinction risk categories and estimated heterozygosity…\n\n\n\nLow genetic diversity symptom of past genetic drift inbreeding (higher levels of homozygosity), caused by low \\(N_e\\)\n\nGarcía-Dorado & Caballero (2021)\n\n\n\n\nHowever: if population decline is rapid, may be too little time for inbreeding to occur \\(\\Rightarrow\\) genetic diversity within species not necessarily aligned to extinction risk\n\nLewis (2023)\n\n\n\n\n\nTake home (Lewis, 2023): genetic diversity within a species does not necessarily align with its extinction risk. Possible explanation: population decline has been so rapid that there hasn’t been time for inbreeding to occur. Other factors (e.g., habitat destruction) greater threat.\nCaption:\n\nRuns of homozygosity and impact of extinction risk on diversity (A) Relationship between IUCN extinction risk categories and heterozygosity. Solid black circles and bars denote median and IQR. (B) Partition into threatened (T: VU, EN, CR) and nonthreatened (N: LC, NT) categories for all families with more than one species in either partition. Significant differences (p &lt; 0.05, one-sided rank-sum test) are marked with an asterisk. (C) Median number of tracts of homozygosity versus median proportion of the genome in runs of homozygosity per species. Species with a fraction over 1/3 are highlighted. Solid black dots within highlights denote threatened species (VU, EN, CR).\n\nOn Figure 2A:\n\nWe investigated whether genetic diversity estimates are correlated with extinction risk in primates, a subject of previous debate (17, 33, 34). Despite our broad sampling, we find no global relationship between numerically coded IUCN extinction risk categories and estimated heterozygosity [p &gt; 0.05, phylogenetic generalized least squares (PGLS)] (Fig. 2A) (16)."
  },
  {
    "objectID": "slides/genetic_diversity/index.html#nucleotide-diversity",
    "href": "slides/genetic_diversity/index.html#nucleotide-diversity",
    "title": "Genetic diversity",
    "section": "Nucleotide diversity",
    "text": "Nucleotide diversity\n\n\n\n\nsample 0:   00100\nsample 1:   00001\nsample 2:   01010\nsample 3:   10010\n\n\n\nDiversity: for each site, count and sum differences between all (unique) pairs of samples, and divide by unique pairs. For \\(n\\) samples, there are \\(n \\choose 2\\) such pairs.\n\n\nExample: for site 0, start comparing samples 0-1 (0 diffs), samples 0-2 (0), samples 0-3 (1), samples 1-2 (0) and so on. Call these differences \\(k_{ij}\\). Then\n\n\n\\[\n\\pi = \\frac{\\sum_{i&lt;j}k_{ij}}{n \\choose 2}\n\\]\n\n\n\n\n\n\n20: 0010041: 0000112: 0101003: 100103"
  },
  {
    "objectID": "slides/genetic_diversity/index.html#wattersons-theta_w",
    "href": "slides/genetic_diversity/index.html#wattersons-theta_w",
    "title": "Genetic diversity",
    "section": "Watterson’s \\(\\theta_W\\)",
    "text": "Watterson’s \\(\\theta_W\\)\n\n\n\n\nsample 0:   00100\nsample 1:   00001\nsample 2:   01010\nsample 3:   10010\n\n\n\nAlternative measure of diversity: simply count the number of segregating sites (\\(S\\)). However, must correct for the number of samples \\(n\\) as we expect that more samples \\(\\Rightarrow\\) more sites\n\n\n\\[\n\\theta_W = \\frac{S}{a} = \\frac{S}{\\sum_{i=1}^{n-1}\\frac{1}{i}}\n\\]\n\n\nImportant: under neutrality, \\(\\theta = E(\\pi) = E(\\theta_W)\\). Difference between two the basis for Tajima’s D that is a test for selection\n\n\n\n\n\n\n20: 0010041: 0000112: 0101003: 100103\n\n\nTree plot with mutations and sequences \n\n\n\n\n\nIntuitive example to understand of Tajimas: balancing selection has long internal branches -&gt; long haplotype. This will elevate pi since many samples will be different for many sites."
  },
  {
    "objectID": "slides/genetic_diversity/index.html#calculating-diversity-measures---pi-and-theta_w",
    "href": "slides/genetic_diversity/index.html#calculating-diversity-measures---pi-and-theta_w",
    "title": "Genetic diversity",
    "section": "Calculating diversity measures - \\(\\pi\\) and \\(\\theta_W\\)",
    "text": "Calculating diversity measures - \\(\\pi\\) and \\(\\theta_W\\)\n\n\n\n\nsample 0:   00100\nsample 1:   00001\nsample 2:   01010\nsample 3:   10010\n\n\n\n\nfrom trees import ts_small_mut as ts\n\n# Calculate correction factor a for Watterson's\n# theta: the larger the sample size, the more\n# segregating sites we expect to see\na = sum([1/i for i in range(1, ts.num_samples)])\n\npi = ts.diversity()\nthetaW = ts.num_sites / a / ts.sequence_length\n\nprint(f\"Diversity:           {pi:.6f}\",\n      f\"Watterson's theta:   {thetaW:.6f}\",\n      f\"Sequence length:     {ts.sequence_length:.0f}\",\n      sep=\"\\n\")\n\nDiversity:           0.000267\nWatterson's theta:   0.000273\nSequence length:     10000\n\n\n\n\n\n\n\n\nGenome position01000020: 0010041: 0000112: 0101003: 100103\n\n\nTree plot with mutations and sequences"
  },
  {
    "objectID": "slides/genetic_diversity/index.html#divergence---dxy",
    "href": "slides/genetic_diversity/index.html#divergence---dxy",
    "title": "Genetic diversity",
    "section": "Divergence - dXY",
    "text": "Divergence - dXY\n\n\n\n\nsample 0:   00100\nsample 1:   00001\nsample 2:   01010\nsample 3:   10010\n\n\nDivergence: for each site, count and sum differences between all pairs of samples between two populations\n\nExample: for site 0, compare samples 0-2 (0 diffs), samples 0-3 (1 diff), samples 1-2 (0 diffs), samples 1-3 (1 diff), and so on. Call differences \\(k_ij\\), let \\(n_X\\), \\(n_Y\\) be sample size in populations \\(X\\), \\(Y\\). Then\n\n\n\\[\nd_{XY} = \\frac{1}{n_Xn_Y}\\sum_{i=1}^{n_X}\\sum_{i=1}^{n_Y}k_{ij}\n\\]\n\n\n\n\n\n20: 0010041: 0000112: 0101003: 100103\n\n\nTree plot with mutations and sequences"
  },
  {
    "objectID": "slides/genetic_diversity/index.html#divergence---dxy-1",
    "href": "slides/genetic_diversity/index.html#divergence---dxy-1",
    "title": "Genetic diversity",
    "section": "Divergence - dXY",
    "text": "Divergence - dXY\n\n\n\n\nsample 0:   00100\nsample 1:   00001\nsample 2:   01010\nsample 3:   10010\n\n\n\nfrom trees import ts_small_mut as ts\n\nsample_sets = [[0, 1], [2, 3]]\n\ndxy = ts.divergence(sample_sets=sample_sets)\n\nprint(f\"Divergence:   {dxy:.6f}\")\n\nDivergence:   0.000300\n\n\n\n\n\n\n20: 0010041: 0000112: 0101003: 100103\n\n\nTree plot with mutations and sequences \n\n\n\n\n\\(F_ST\\) (later) and related statistics are strongly affected by within-subpopulation genetic variance. Nei (1973) proposed dXY as an alternative that does not depend on the levels of diversity within subpopulations."
  },
  {
    "objectID": "slides/genetic_diversity/index.html#differentiation---afd-allele-frequency-difference",
    "href": "slides/genetic_diversity/index.html#differentiation---afd-allele-frequency-difference",
    "title": "Genetic diversity",
    "section": "Differentiation - AFD (allele frequency difference)",
    "text": "Differentiation - AFD (allele frequency difference)\n\n\n\n\nsample 0:   00100\nsample 1:   00001\nsample 2:   01010\nsample 3:   10010\n\n\nAllele Frequency Difference (AFD) proposed as intuitive alternative to \\(F_{\\mathrm{ST}}\\). For each site, count the difference in allele frequency between two populations.\n\nExample: site 0, frequency in blue is 0, in black 1/2, so difference=1/2, site 1, frequency in blue 0, in black 1/2, and so on\n\n\n\\[\nAFD = \\frac{1}{2}\\sum_{i=1}^n| (f_{i1} - f_{i2})|\n\\]\nwhere \\(n\\) is the number of different alleles (\\(n=2\\) for biallelic SNPs), \\(f_{ij}\\) is the frequency of allele \\(i\\) in population \\(j\\)\n\nBerner (2019)\n\n\n\n\n\n\n20: 0010041: 0000112: 0101003: 100103\n\n\nTree plot with mutations and sequences \n\n\n\n\nAFD proposed as a more intuitive and easier to understand statistic than Fst"
  },
  {
    "objectID": "slides/genetic_diversity/index.html#differentiation---var-fst",
    "href": "slides/genetic_diversity/index.html#differentiation---var-fst",
    "title": "Genetic diversity",
    "section": "Differentiation - \\(F_{\\mathrm{ST}}\\)",
    "text": "Differentiation - \\(F_{\\mathrm{ST}}\\)\n\n\n\n\nsample 0:   00100\nsample 1:   00001\nsample 2:   01010\nsample 3:   10010\n\n\n\\(F_{\\mathrm{ST}}\\) is another measure of differention among subpopulations (Wright, 1931). It ranges between 0 and 1 and has the interpretation 0: no differentiation, 1: complete fixation of alternate alleles in subpopulations\n\nExample: site 3 has \\(F_{\\mathrm{ST}}\\)=1 as it is fixed in black, not present in blue\n\n\nThere are many ways to express and calculate \\(F_{\\mathrm{ST}}\\). Example:\n\\[\nF_{\\mathrm{ST}} = \\frac{h_{\\mathrm{T}} - h_{\\mathrm{S}}}{h_{\\mathrm{T}}}\n\\]\nwhere \\(h_{\\mathrm{T}}\\) is the expected heterozygosity in the total population, \\(h_{\\mathrm{S}}\\) the average of expected heterozygosities across subpopulations. For site 3, \\(h_{\\mathrm{S}}=0\\), \\(h_{\\mathrm{T}}=2/3\\).\n\n\nCaveats: strongly influenced by within subpopulation levels of variation. Therefore considered relative measure (cf \\(d_{\\mathrm{XY}}\\), which is an absolute measure).\n\n\n\n\n\n20: 0010041: 0000112: 0101003: 100103\n\n\nTree plot with mutations and sequences \n\n\n\n\nWright’s fst measures differentiation among subpopulations. Interpretation: 0 no differentiation, 1 complete fixation of alternate alleles. Has therefore become a popular statistic for quantifying differentiation from molecular data."
  },
  {
    "objectID": "slides/genetic_diversity/index.html#differentiation---var-fst-1",
    "href": "slides/genetic_diversity/index.html#differentiation---var-fst-1",
    "title": "Genetic diversity",
    "section": "Differentiation - \\(F_{\\mathrm{ST}}\\)",
    "text": "Differentiation - \\(F_{\\mathrm{ST}}\\)\n\n\n\n\nsample 0:   00100\nsample 1:   00001\nsample 2:   01010\nsample 3:   10010\n\n\n\n\nfrom trees import ts_small_mut as ts\n\nsample_sets = [[0, 1], [2, 3]]\nwin = [0] + [int(x.position)+1 for x in ts.sites()]\n_ = win.pop()\nwin = win + [ts.sequence_length]\n\nfst = ts.Fst(sample_sets=sample_sets)\nfst_sites = ts.Fst(sample_sets=sample_sets,\n                   windows=win)\n\nprint(f\"Site id:       {list(range(5))}\",\n      f\"Fst per site:  {fst_sites}\",\n      f\"Overall Fst:   {fst:.6f}\",\n      sep=\"\\n\")\n\nSite id:       [0, 1, 2, 3, 4]\nFst per site:  [0. 0. 0. 1. 0.]\nOverall Fst:   0.200000\n\n\n\n\n\n\n\nGenome position01000020: 0010041: 0000112: 0101003: 100103\n\n\nTree plot with mutations and sequences"
  },
  {
    "objectID": "slides/genetic_diversity/index.html#many-programs-treat-missing-data-as-invariant",
    "href": "slides/genetic_diversity/index.html#many-programs-treat-missing-data-as-invariant",
    "title": "Genetic diversity",
    "section": "Many programs treat missing data as invariant",
    "text": "Many programs treat missing data as invariant\n\n\n\n\n\nKorunes & Samuk (2021), Fig 1\n\n\n\n\n\nDiversity:\n\\[\n\\pi = \\frac{\\sum_{i&lt;j}k_{ij}}{n \\choose 2}\n\\]\nDivergence:\n\\[\nd_{XY} = \\frac{1}{n_Xn_Y}\\sum_{i=1}^{n_X}\\sum_{j=1}^{n_Y}k_{ij}\n\\]\nHere, \\(n\\) is the number of samples, \\(k_{ij}\\) tally of allelic differences between two haplotypes within (\\(\\pi\\)) a population or between (\\(d_{XY}\\)) populations\n\n\n\nPaper caption:\n\nThe logic and input/ouput of pixy demonstrated with a simple haploid example. (a) Comparison of two methods for computing π (or dXY) in the face of missing data. These methods follow the first expression of Equation 1 but differ in how they calculate the numerator and denominator. In Case 1, all missing data is assumed to be present but invariant. This results in a deflated estimate of π. In Case 2, missing data are simply omitted from the calculation, both in terms of the number of sites (the final denominator) and the component denominators for each site (the n choose two terms). This results in an unbiased estimate of π. (b) The adjusted π method (Case 2) as implemented for VCFs in pixy. The example VCF (input) contains the same four haplotypes as (a). Invariant sites are represented as sites with no ALT allele, and greyed-out sites are those that failed to pass a genotype filter requiring a minimum number of reads covering the genotype (Depth ≥ 10 in this case)"
  },
  {
    "objectID": "slides/genetic_diversity/index.html#missing-data-may-bias-diversity-measures-downwards",
    "href": "slides/genetic_diversity/index.html#missing-data-may-bias-diversity-measures-downwards",
    "title": "Genetic diversity",
    "section": "Missing data may bias diversity measures downwards",
    "text": "Missing data may bias diversity measures downwards\n\n\n\n\nKorunes & Samuk (2021), Fig 4\n\n\n\n\n\n\nReal data: strong tendency of commonly adopted tools to underestimate pi, dxy (even for 30X data sets)\nCaption:\n\nComparisons of estimates of π from whole genome data derived from 18 Anopheles gambiae individuals from the Ag1000G Burkina Faso (BFS) population. Each panel (a–d) depicts the estimates of π for the X chromosome performed using pixy (y-axis) and four other methods (x-axis, a–d). Points are coloured according to the proportion of missing data (of any type) calculated by pixy. The 1:1 line is shown in red"
  },
  {
    "objectID": "slides/genetic_diversity/index.html#nucleotide-diversity-landscapes",
    "href": "slides/genetic_diversity/index.html#nucleotide-diversity-landscapes",
    "title": "Genetic diversity",
    "section": "Nucleotide diversity landscapes",
    "text": "Nucleotide diversity landscapes\n\nvcftools --gzvcf allsites.vcf.gz --window-pi 1000\ncsvtk plot line --tabs out.windowed.pi -x BIN_START -y PI \\\n   --point-size 0.01 --xlab \"Position (bp)\" \\\n   --ylab \"Diversity\" --title LG4 --width 9.0 --height 3.5 \\\n   &gt; out.windowed.pi.png\n\n\n\n\n\nWindow-based plot is seque into genome scans"
  },
  {
    "objectID": "slides/genetic_diversity/index.html#genetic-basis-of-adaptation-and-genome-scans",
    "href": "slides/genetic_diversity/index.html#genetic-basis-of-adaptation-and-genome-scans",
    "title": "Genetic diversity",
    "section": "Genetic basis of adaptation and genome scans",
    "text": "Genetic basis of adaptation and genome scans\n\n\n\n\n\n\n\n\nFundamental questions:\n\nHow many genes are involved in the evolution of adaptive traits?\nWhat is the distribution of phenotypic effects among successive allelic substitutions?\nIs adaptation typically based on standing variation or new mutations?\nWhat is the relative importance of additive vs. nonadditive effects on adaptive trait variation?\nAnd what is the relative importance of structural vs. regulatory changes in phenotypic evolution?\n\n\nStorz (2005), Fig 1\n\n\n\n\nStorz (2005) lays out genomic scans as an alternative approach to GWAS and QTL mapping for finding genetic determinants of adaptation. The reason is GWAS/QTL requires a phenotype whereas genome scans are data-driven.\nCaption (fig 1):\n\nFig. 1 (a) Effects of genetic hitch-hiking along a recombining chromosome. Hori- zontal lines depict a population sample of homologous chromosomes, and filled symbols depict neutral mutations. In this example an advantageous mutation (open symbol) arises and is rapidly driven to fixation by positive selection. Although the mutation is recombined against new genetic backgrounds during the course of the selective sweep, a sizable fraction of the ancestral haplotype (shown in red) also becomes fixed. Consequently, neutral variants that were initially linked to the advantageous mutation undergo a dramatic increase in frequency as a result of hitchhiking. (b) In this example, locus 3 has been rendered monomorphic by a selective sweep. Sampled gene copies (denoted by tips of the gene tree) share a very recent common ancestor, and π = 0 (where π = nucleotide diversity; Nei & Li 1979). comparison, unlinked, neutrally evolving regions of the genome (loci 1, 2, and 4) are characterized by deeper genealogies, and higher levels of nucleotide diversity (π = 0.019–0.020). Note that the gene trees depict the true genealogies of the samples, not the genealogies inferred from observed variation."
  },
  {
    "objectID": "slides/genetic_diversity/index.html#example",
    "href": "slides/genetic_diversity/index.html#example",
    "title": "Genetic diversity",
    "section": "Example",
    "text": "Example\n\nvcftools --gzvcf allsites.vcf.gz --weir-fst-pop PUN-Y.txt \\\n   --weir-fst-pop PUN-R.txt \\\n   --fst-window-size 1000\ncsvtk plot line --tabs out.windowed.weir.fst \\\n   -x BIN_START -y MEAN_FST \\\n   --point-size 2 --xlab \"Position (bp)\" \\\n   --ylab \"Fst\" --title \"LG4: PUN-Y vs PUN-R\" \\\n   --width 9.0 --height 3.5 --scatter \\\n   &gt; out.windowed.weir.fst.mean.png"
  },
  {
    "objectID": "slides/genetic_diversity/index.html#z-scores-can-help-identifying-outliers",
    "href": "slides/genetic_diversity/index.html#z-scores-can-help-identifying-outliers",
    "title": "Genetic diversity",
    "section": "Z-scores can help identifying outliers",
    "text": "Z-scores can help identifying outliers\n\n\n\ndata &lt;- read.table(\"out.windowed.weir.fst\", header = TRUE)\nx &lt;- data$MEAN_FST\nz &lt;- (x - mean(x))/sd(x)\nplot(x = data$BIN_START, y = z, xlab = \"Position (bp)\")\n\n\n\n\n\nRaw data can be converted to Z-scores to highlight outliers. A Z-score is a measure of how far a data point is from the mean in terms of the number of standard deviations:\n\\[\nZ = \\frac{X - \\mu}{\\sigma}\n\\]\nThreshold of a couple of standard deviations common."
  },
  {
    "objectID": "slides/genetic_diversity/index.html#ld-decay-and-choice-of-window-size",
    "href": "slides/genetic_diversity/index.html#ld-decay-and-choice-of-window-size",
    "title": "Genetic diversity",
    "section": "LD decay and choice of window size",
    "text": "LD decay and choice of window size\n\n\n\n\n\n\n\n\n\n\nProperties of genetic variation and inferred demographic history in sampled A. millepora. Fuller et al. (2020), Figure 2. Upper left plot illustrates LD as a function of physical distance. Here, choosing a window size 20-30kb would ensure that most windows are independent."
  },
  {
    "objectID": "slides/genetic_diversity/index.html#annotations",
    "href": "slides/genetic_diversity/index.html#annotations",
    "title": "Genetic diversity",
    "section": "Annotations",
    "text": "Annotations\n\ncsvtk filter2 --tabs annotation.gff --filter ' $3 == \"CDS\" ' |\\\n csvtk mutate2 --tabs -H -e '$4 - 12000000' -w 0 |\\\n csvtk mutate2 --tabs -H -e '$5 - 12000000' -w 0 |\\\n csvtk cut --tabs --fields 1,10,11 | bedtools sort | bedtools merge \\\n    &gt; CDS.bed 2&gt;/dev/null\nhead -n 3 CDS.bed\n\nLG4 12032   12121\nLG4 12214   12658\nLG4 12774   12830\n\n\n\npixy --vcf allsites.vcf.gz --stats pi \\\n --populations populations.txt \\\n --output_prefix cds --bed_file CDS.bed\npixy --vcf allsites.vcf.gz --stats pi \\\n --populations populations.txt --window_size 1000 \\\n --output_prefix all\n\n\n\n\ncsvtk summary --tabs -i -g pop \\\n   -f avg_pi:mean cds_pi.txt -w 5\n\npop avg_pi:mean\nPUN-R   0.00391\nPUN-Y   0.00516\n\n\n\n\ncsvtk summary --tabs -i -g pop \\\n   -f avg_pi:mean all_pi.txt -w 5\n\npop avg_pi:mean\nPUN-R   0.00796\nPUN-Y   0.01129"
  },
  {
    "objectID": "slides/genetic_diversity/index.html#dissecting-differentiation-landscapes",
    "href": "slides/genetic_diversity/index.html#dissecting-differentiation-landscapes",
    "title": "Genetic diversity",
    "section": "Dissecting differentiation landscapes",
    "text": "Dissecting differentiation landscapes\n\n\n\nBurri (2017) Fig. 1"
  },
  {
    "objectID": "slides/genetic_diversity/index.html#monkeyflower-genomic-landscape",
    "href": "slides/genetic_diversity/index.html#monkeyflower-genomic-landscape",
    "title": "Genetic diversity",
    "section": "Monkeyflower genomic landscape",
    "text": "Monkeyflower genomic landscape\n\n\n\n\nStankowski et al. (2019) Fig. 1"
  },
  {
    "objectID": "slides/genetic_diversity/index.html#exercise",
    "href": "slides/genetic_diversity/index.html#exercise",
    "title": "Genetic diversity",
    "section": "Exercise",
    "text": "Exercise"
  },
  {
    "objectID": "slides/genetic_diversity/index.html#bibliography",
    "href": "slides/genetic_diversity/index.html#bibliography",
    "title": "Genetic diversity",
    "section": "Bibliography",
    "text": "Bibliography\n\n\nBerner, D. (2019). Allele Frequency Difference AFD to FST for Quantifying Genetic Population Differentiation. Genes, 10(4), 308. https://doi.org/10.3390/genes10040308\n\n\nBurri, R. (2017). Dissecting differentiation landscapes: A linked selection’s perspective. Journal of Evolutionary Biology, 30(8), 1501–1505. https://doi.org/10.1111/jeb.13108\n\n\nCharlesworth, B., & Jensen, J. D. (2022). How Can We Resolve Lewontin’s Paradox? Genome Biology and Evolution, 14(7), evac096. https://doi.org/10.1093/gbe/evac096\n\n\nCorbett-Detig, R. B., Hartl, D. L., & Sackton, T. B. (2015). Natural Selection Constrains Neutral Diversity across A Wide Range of Species. PLOS Biology, 13(4), e1002112. https://doi.org/10.1371/journal.pbio.1002112\n\n\nEllegren, H., & Galtier, N. (2016). Determinants of genetic diversity. Nature Reviews Genetics, 17(7), 422–433. https://doi.org/10.1038/nrg.2016.58\n\n\nFuller, Z. L., Mocellin, V. J. L., Morris, L. A., Cantin, N., Shepherd, J., Sarre, L., Peng, J., Liao, Y., Pickrell, J., Andolfatto, P., Matz, M., Bay, L. K., & Przeworski, M. (2020). Population genetics of the coral Acropora millepora: Toward genomic prediction of bleaching. Science, 369(6501), eaba4674. https://doi.org/10.1126/science.aba4674\n\n\nGarcía-Dorado, A., & Caballero, A. (2021). Neutral genetic diversity as a useful tool for conservation biology. Conservation Genetics, 22(4), 541–545. https://doi.org/10.1007/s10592-021-01384-9\n\n\nKorunes, K. L., & Samuk, K. (2021). Pixy: Unbiased estimation of nucleotide diversity and divergence in the presence of missing data. Molecular Ecology Resources, 21(4), 1359–1368. https://doi.org/10.1111/1755-0998.13326\n\n\nKuderna, L. F. K., Gao, H., Janiak, M. C., Kuhlwilm, M., Orkin, J. D., Bataillon, T., Manu, S., Valenzuela, A., Bergman, J., Rousselle, M., Silva, F. E., Agueda, L., Blanc, J., Gut, M., de Vries, D., Goodhead, I., Harris, R. A., Raveendran, M., Jensen, A., … Marques Bonet, T. (2023). A global catalog of whole-genome diversity from 233 primate species. Science, 380(6648), 906–913. https://doi.org/10.1126/science.abn7829\n\n\nLeffler, E. M., Bullaughey, K., Matute, D. R., Meyer, W. K., Ségurel, L., Venkat, A., Andolfatto, P., & Przeworski, M. (2012). Revisiting an Old Riddle: What Determines Genetic Diversity Levels within Species? PLOS Biology, 10(9), e1001388. https://doi.org/10.1371/journal.pbio.1001388\n\n\nLewis, D. (2023). Biggest ever study of primate genomes has surprises for humanity. Nature. https://doi.org/10.1038/d41586-023-01776-6\n\n\nNei, M. (1973). Analysis of Gene Diversity in Subdivided Populations. Proceedings of the National Academy of Sciences, 70(12), 3321–3323. https://doi.org/10.1073/pnas.70.12.3321\n\n\nStankowski, S., Chase, M. A., Fuiten, A. M., Rodrigues, M. F., Ralph, P. L., & Streisfeld, M. A. (2019). Widespread selection and gene flow shape the genomic landscape during a radiation of monkeyflowers. PLOS Biology, 17(7), e3000391. https://doi.org/10.1371/journal.pbio.3000391\n\n\nStorz, J. F. (2005). INVITED REVIEW: Using genome scans of DNA polymorphism to infer adaptive population divergence. Molecular Ecology, 14(3), 671–688. https://doi.org/10.1111/j.1365-294X.2005.02437.x\n\n\nWright, S. (1931). Evolution in Mendelian Populations. Genetics, 16(2), 97–159. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1201091/\n\n\n\n\nGenetic diversity"
  },
  {
    "objectID": "slides/variant_calling/index.html#yesterday",
    "href": "slides/variant_calling/index.html#yesterday",
    "title": "Variant calling",
    "section": "Yesterday",
    "text": "Yesterday\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\nT\nT\nA\nC\nA\nA\nT\nC\nC\nG\nA\nT\nC\nG\nT\n\n\nT\nT\nA\nC\nG\nA\nT\nG\nC\nG\nC\nT\nC\nG\nT\n\n\nT\nC\nA\nC\nA\nA\nT\nG\nC\nG\nA\nT\nG\nG\nA\n\n\nT\nT\nA\nC\nG\nA\nT\nG\nC\nG\nC\nT\nC\nG\nT\n\n\n\n*\n\n\n*\n\n\n*\n\n\n*\n\n*\n\n*\n\n\n\n\n\n\\[\n\\begin{align}\n\\pi & = \\sum_{j=1}^S h_j = \\sum_{j=1}^{S} \\frac{n}{n-1}\\left(1 - \\sum_i p_i^2 \\right) \\\\\n& \\stackrel{S=6,\\\\ n=4}{=} \\sum_{j=1}^{6} \\frac{4}{3}\\left(1 - \\sum_i p_i^2\\right) \\\\\n& = \\frac{4}{3}\\left(\\mathbf{\\color{#a7c947}{4}}\\left(1-\\frac{1}{16}-\n\\frac{9}{16}\\right) + \\mathbf{\\color{#a7c947}{2}}\\left(1 - \\frac{1}{4} -\n\\frac{1}{4}\\right)\\right) = \\frac{10}{3}\n\\end{align}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{align}\n\\pi & = \\frac{\\sum_{i=1}^{n-1}i(n-i)\\xi_i}{n(n-1)/2} \\\\\n& \\stackrel{n=4}{=} \\frac{1*(4-1)*4 + 2*(4-2)*2}{6} = \\frac{10}{3}\n\\end{align}\n\\]\n\n\n\n\nThis is not how real data looks like from the beginning…\n\n\nWe have previously looked at how to simulate sequence data and performed some simple calculations on data that are “well-behaved” in some sense; textbook data is usually clean without missing data points or at least high quality in some sense. This lecture will focus on how data is generated through the process of variant calling, starting from a set of reads and a reference sequence (it does not cover sequencing technologies or assembly)."
  },
  {
    "objectID": "slides/variant_calling/index.html#the-real-data",
    "href": "slides/variant_calling/index.html#the-real-data",
    "title": "Variant calling",
    "section": "The real data",
    "text": "The real data\n\n\n\n\n@SRR9309790.10003134\nTAAATCGATTCGTTTTTGCTATCTTCGTCT\n+\nAAFFFJJJJJJJFJJJJJJJJJJJJJJJJJ\n@SRR9309790.10003222\nTAAATCGATTCGTTTTTGCTATCTTCGTCT\n+\nAAFFFJJJJJJJJJJJJJJJJJJJJJJJJJ\n\n\n\n\n\n\nLG4:30430\n\n\n\n\n\n\nLG4:30430\n\n 30431     30441     30451     30461           CATTGGCAATGGCATCAGTTGAGCATCTTAGTACGAACTAAAAGCTG...............M..............................................A...                            ...............A.................              .............................................. .............................................. .............................................. ...............A..............................................A...............................,,,,,,,,,,,,a,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,a,,,,,aa,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,  ,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n\n\n\n\n\n\nBefore getting to variants and genotypes a lot of processing has to be done, from FASTQ input, to mapped data, to variant and genotype calls."
  },
  {
    "objectID": "slides/variant_calling/index.html#the-process",
    "href": "slides/variant_calling/index.html#the-process",
    "title": "Variant calling",
    "section": "The process",
    "text": "The process\n\n\n\n\nIn short: going from sample collection through data processing to variant data is a long and winding road. Here we will focus on the data processing part that generates a raw variant call set.\nThe end result is a table consisting of variant positions, and for each individual, information about genetic variation."
  },
  {
    "objectID": "slides/variant_calling/index.html#variant-and-genotype-calling",
    "href": "slides/variant_calling/index.html#variant-and-genotype-calling",
    "title": "Variant calling",
    "section": "Variant and genotype calling",
    "text": "Variant and genotype calling\n\n\n\n\n\n\n\n\n\n\nNielsen et al. (2011)\n\n\n\nSNP calling\n\nIdentification of polymorphic sites (\\(&gt;1\\)% allele frequency)\n\nVariant calling\n\nIdentification of variant sites (sufficient that any allele differs)\n\nGenotype calling\n\nDetermine the allele combination for each individual (aa, aA, or AA for bi-allelic variants)\n\n\n\nKnowing variant sites informs us of possible genotypes and improves genotyping.\nExample: knowing a site has A or C limits possible genotype calls to AA, AC, or CC\n\n\n\n\nFigure caption from (Nielsen et al., 2011):\n\nPre-processing steps (shown in yellow) transform the raw data from next-generation sequencing technology into a set of aligned reads that have a measure of confidence, or quality score, associated with the bases of each read. The per-base quality scores produced by base-calling algorithms may need to be recalibrated to accurately reflect the true error rates. Depending on the number of samples and the depth of coverage, either a multi-sample calling procedure (green) or a single-sample calling procedure (orange) may then be applied to obtain SNP or genotype calls and associated quality scores. Note that the multi-sample procedure may include a linkage-based analysis, which can substantially improve the accuracy of SNP or genotype calls. Finally, post-processing (purple) uses both known data and simple heuristics to filter the set of SNPs and/or improve the associated quality scores. Optional, although recommended, steps are shown in dashed lines."
  },
  {
    "objectID": "slides/variant_calling/index.html#sequencing-technologies",
    "href": "slides/variant_calling/index.html#sequencing-technologies",
    "title": "Variant calling",
    "section": "Sequencing technologies",
    "text": "Sequencing technologies\n\n\n\n\n\n\n\n\n\n\n\n\n\nIllumina NovaSeq 600\n\n\nScale up and down with a tunable output of up to 6 Tb and 20B single reads in &lt; 2 days.\n\n\nUp to 2X250 bp read length. Price example: 8,000 SEK total for resequencing 3Gbp genome to 30X\n\nhttps://www.illumina.com/systems/sequencing-platforms/novaseq.html\n\n\nPacBio Revio\n\n\nUp to 360 Gb of HiFi reads per day, equivalent to 1,300 human whole genomes per year.\n\n\nTens of kilobases long HiFi reads. Price example (Sequel II): ~35kSEK per library and SMRT cell\n\nhttps://www.pacb.com/revio/"
  },
  {
    "objectID": "slides/variant_calling/index.html#dna-sequences-in-fastq-format",
    "href": "slides/variant_calling/index.html#dna-sequences-in-fastq-format",
    "title": "Variant calling",
    "section": "DNA sequences in FASTQ format",
    "text": "DNA sequences in FASTQ format\n\nls --long --human *.fastq.gz\n\n\n\n-rw-r--r-- 1 runner docker 302K Nov  8 14:14 PUN-Y-INJ_R1.fastq.gz\n-rw-r--r-- 1 runner docker 393K Nov  8 14:14 PUN-Y-INJ_R2.fastq.gz\n\n\n\nCount number of lines:\n\nzcat PUN-Y-INJ_R1.fastq.gz | wc --lines\n\n15768\n\n\n\n\n\n\n\nFormat:\n\nsequence id (prefixed by @)\nDNA sequence\nseparator (+)\nPhred base quality scores\n\n\n\nzcat PUN-Y-INJ_R1.fastq.gz | head --lines 8 | cut --characters -30\n\n@SRR9309790.10003134\nTAAATCGATTCGTTTTTGCTATCTTCGTCT\n+\nAAFFFJJJJJJJFJJJJJJJJJJJJJJJJJ\n@SRR9309790.10003222\nTAAATCGATTCGTTTTTGCTATCTTCGTCT\n+\nAAFFFJJJJJJJJJJJJJJJJJJJJJJJJJ\n\n\n\n\n\n\n\nFirst data encounter is usually FASTQ files from sequencing center. Files contain sequence reads that are generated by the sequencing machine. They correspond to short stretches of DNA that have been sequentially read by the machine, resulting in a string of base calls that constitute the reads. Every DNA base has an associated so-called Phred-scaled quality score from 0 to 93 that are encoded using ASCII 33 to 126.\nThe format consists of 1. @ title with id 2. raw sequence 3. +: a separator with optional description 4. the quality scores"
  },
  {
    "objectID": "slides/variant_calling/index.html#dna-sequence-quality-control",
    "href": "slides/variant_calling/index.html#dna-sequence-quality-control",
    "title": "Variant calling",
    "section": "DNA sequence quality control",
    "text": "DNA sequence quality control\nQuality values represent the probability \\(P\\) that the call is incorrect. They are coded as Phred quality scores \\(Q\\). Here, \\(Q=20\\) implies 1% probability of error, \\(Q=30\\) 0.1% and so on. Typically you should not rely on quality values below \\(20\\).\n\\[\nQ = -10 \\log_{10} P\n\\]\n\n\nA common way to do QC is with fastqc:\n\nfastqc --outdir . --extract *fastq.gz"
  },
  {
    "objectID": "slides/variant_calling/index.html#sequencing-approaches",
    "href": "slides/variant_calling/index.html#sequencing-approaches",
    "title": "Variant calling",
    "section": "Sequencing approaches",
    "text": "Sequencing approaches\n\n\n\n\n\n\n\n\n\nDespite price drop, still need to make choices regarding depth and breadth of sequencing coverage and number of samples.\n\n\n\n\n\n\n\nLou et al. (2021)\n\nHere focus on Whole Genome reSequencing (WGS), mostly high-coverage.\n\n\n\nDespite the fact that sequencing costs have dropped dramatically (left), there still are choices to be made regarding the distribution of costs along 1) sequencing coverage depth, i.e., the mean depth of sequencing 2) sequencing coverage breadth, i.e., whether or not to do targeted or whole-genome resequencing or 3) sample size; how many individuals to sample. Whole-genome resequencing of individuals from populations to sufficient depth (30X) is still very expensive, but often needed to understand mechanisms of adaptation (Lou et al., 2021, p. 5967). Various protocols have been developed to meet the challenges that cost imposes:\n\nRAD-seq, restriction site-associated DNA sequencing, targets regions flanking given restriction sites. Downside: much of genome is missed\npool-seq, pooled sequencing. Cost-effective, but loses information about individuals\nlcWGS, low-coverage whole genome sequencing increasing in popularity. Genotyping low coverage is problematic however.\n\nOur focus here is WGS (whole-genome resequencing), primarily high-coverage, despite the cost it may incur."
  },
  {
    "objectID": "slides/variant_calling/index.html#genome-assembly-and-population-resequencing",
    "href": "slides/variant_calling/index.html#genome-assembly-and-population-resequencing",
    "title": "Variant calling",
    "section": "Genome assembly and population resequencing",
    "text": "Genome assembly and population resequencing\n\n\n\nGenome assembly\n\n\n\nAllendorf et al. (2022)\n\n\n\nPopulation resequencing\n\n\n\n\n\nDNA sequences are generated from DNA fragments, often as paired-end reads, or long reads. For population genomics, it is often necessary to generate a reference sequence through genome assembly, the quality of which will impact the types of downstream analyses that can be done. Reads are assembled into contigs (contiguous sequences) that with the aid of genetic maps are pieced together into scaffolds. In the left figure, note that the scaffolds contain areas of unknown sequence.\nOnce a reference sequence has been produced, (short) reads from individuals are mapped to the reference (right)."
  },
  {
    "objectID": "slides/variant_calling/index.html#sequence-alignment-maps-reads-to-a-reference",
    "href": "slides/variant_calling/index.html#sequence-alignment-maps-reads-to-a-reference",
    "title": "Variant calling",
    "section": "Sequence alignment maps reads to a reference",
    "text": "Sequence alignment maps reads to a reference\n\n\n\nFigure 1: Screenshot of reference sequence (top) and aligned reads (bottom). Second line with . characters is the consensus sequence. Bases are colored by nucleotide. Letter case indicates forward (upper-case) or reverse (lower-case) alignment. * is placeholder for deleted base.\n\n\n\n\nAim of sequence alignment (read mapping) is to determine source in reference sequence. Some commonly used read mappers for resequencing are\n\n\n\nBWA, BWA-MEM (H. Li, 2013)\nNovoalign (https://www.novocraft.com/)\nMinimap2 (H. Li, 2018)\n\n\nFor a recent comprehensive comparison see Donato et al. (2021)"
  },
  {
    "objectID": "slides/variant_calling/index.html#alignments-are-stored-in-bam-format",
    "href": "slides/variant_calling/index.html#alignments-are-stored-in-bam-format",
    "title": "Variant calling",
    "section": "Alignments are stored in BAM format",
    "text": "Alignments are stored in BAM format\n\n\nHeader information\n\n\nsamtools view --header-only PUN-Y-INJ.sort.dup.bam | head --lines 4\n\n@HD VN:1.6  SO:coordinate\n@SQ SN:LG4  LN:100000\n@RG ID:SRR9309790   SM:PUN-Y-INJ    PL:ILLUMINA\n@PG ID:bwa  PN:bwa  VN:0.7.17-r1188 CL:bwa mem -R @RG\\tID:SRR9309790\\tSM:PUN-Y-INJ\\tPL:ILLUMINA -p -t 14 -M tiny/M_aurantiacus_v1_splitline_ordered.fasta -\n\n\nFormat: metadata record types prefixed with @, e.g., @RG is the read group\n\n\n\nAlignments\n\n\nsamtools view PUN-Y-INJ.sort.dup.bam | head --lines 1\n\nSRR9309790.7750070  65  LG4 1   39  45S9M1I96M  =   83782   83781   TGAACTATAGTCGATGGGACGAATACCCCCCTGAACTTGCGAAGGGGACAATTACCCCCCTCTGTTATGTTTCAGTCAATTTCATGTTTGATTTTTAGATTTTTAATTAATTATATATTTTTTGCAATTTGTAACCTCTTTAACCTTTATT AAFFFJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJAJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJFJJJJJJJJJJJFFJFJJJJJJJJJJFJJJJJJJJFJJJJJJJJJAJJJJJJJJJJJJJJJJJFA&lt;FFJJ7FF SA:Z:LG4,83018,+,30M2I28M91S,37,5;  MC:Z:12S10M2I123M4S MD:Z:16C28C59   PG:Z:MarkDuplicates RG:Z:SRR9309790 NM:i:3  MQ:i:50 AS:i:88 XS:i:70 ms:i:5185\n\n\nSome important columns: 1:QUERY, 3:REFERENCE, 4:POSITION, 5:MAPQ, 6:CIGAR. The CIGAR string compiles information on the alignment, such as match (M), soft clipping (S), and insertion to reference (I)\n\n\ncf https://samtools.github.io/hts-specs/SAMv1.pdf\n\n\nFor a complete description, see the specification. Suffice to say that the alignment format consists of a header section, with metadata and provenance data, and an alignment section, which is a column-based format with information pertaining to the query sequence being mapped and the reference sequence to which the query is mapped."
  },
  {
    "objectID": "slides/variant_calling/index.html#mapped-alignments-can-be-viewed-with-samtools-tview",
    "href": "slides/variant_calling/index.html#mapped-alignments-can-be-viewed-with-samtools-tview",
    "title": "Variant calling",
    "section": "Mapped alignments can be viewed with samtools tview",
    "text": "Mapped alignments can be viewed with samtools tview\n\n\nsamtools tview -p LG4:30430 -d H -w 60 \\\n   PUN-Y-INJ.sort.dup.bam \\\n   M_aurantiacus_v1.fasta\n\n\n\nLG4:30430\n\n\n\n\n\n\nLG4:30430\n\n 30431     30441     30451     30461     30471              CATTGGCAATGGCATCAGTTGAGCATCTTAGTACGAACTAAAAGCTGCGAAAAAATATTT...............M...........................................................A...                               ,,,,,,,,,,...............A.................                 ,,,,,,,,,,..............................................      ,,,,,,,,..............................................              ..............................................              ...............A...........................................................A............................................,,,,,,,,,,,,a,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,a,,,,,aa,a,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,  ,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n\n\n\n\nsamtools tview -p LG4:30430 -d H -w 60 \\\n   PUN-R-ELF.sort.dup.bam \\\n   M_aurantiacus_v1.fasta\n\n\n\nLG4:30430\n\n\n\n\n\n\nLG4:30430\n\n 30431     30441     30451     30461     30471              CATTGGCAATGGCATCAGTTGAGCATCTTAGTACGAACTAAAAGCTGCGAAAAAATATTT...............A............................................,,,,,,,                           .........................................A.....                  ....................................A...A....               ....................................A.........                                   ...............A...........C.............                   ,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,...............A............................................,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,...............A............................................,,,g,,,,,,,a,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,  .............A............................................\n\n\n\n\n\nAka pileup format. Forward (.) and backward (,) mapping reads. Mismatches shown as letters.\n\nAfter preprocessing, reads are mapped to a reference. Observations:\n\ndifferent coverage\nsequencing error randomly distributed"
  },
  {
    "objectID": "slides/variant_calling/index.html#potential-error-corrections-and-pitfalls",
    "href": "slides/variant_calling/index.html#potential-error-corrections-and-pitfalls",
    "title": "Variant calling",
    "section": "Potential error corrections and pitfalls",
    "text": "Potential error corrections and pitfalls\nInstrument\n\nPCR duplicates -&gt; MarkDuplicates\nsystematic errors from sequencing machine -&gt; Base Quality Score Recalibration (BQSR)\n\nReference\n\nquality of reference sequence!\nrepetitive sequence"
  },
  {
    "objectID": "slides/variant_calling/index.html#variants-show-up-in-pileup-alignments",
    "href": "slides/variant_calling/index.html#variants-show-up-in-pileup-alignments",
    "title": "Variant calling",
    "section": "Variants show up in pileup alignments",
    "text": "Variants show up in pileup alignments\n\n\n\nSample PUN-Y-INJ\n\n\n\n\nLG4:30430\n\n\n\n\n\n\nLG4:30430\n\n 30431     30441     30451     30461     30471              CATTGGCAATGGCATCAGTTGAGCATCTTAGTACGAACTAAAAGCTGCGAAAAAATATTT...............M...........................................................A...                               ,,,,,,,,,,...............A.................                 ,,,,,,,,,,..............................................      ,,,,,,,,..............................................              ..............................................              ...............A...........................................................A............................................,,,,,,,,,,,,a,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,a,,,,,aa,a,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,  ,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n\n\n\n\n\nSample PUN-R-ELF\n\n\n\n\nLG4:30430\n\n\n\n\n\n\nLG4:30430\n\n 30431     30441     30451     30461     30471              CATTGGCAATGGCATCAGTTGAGCATCTTAGTACGAACTAAAAGCTGCGAAAAAATATTT...............A............................................,,,,,,,                           .........................................A.....                  ....................................A...A....               ....................................A.........                                   ...............A...........C.............                   ,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,...............A............................................,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,...............A............................................,,,g,,,,,,,a,,,a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,  .............A............................................\n\n\n\n\n\n\n\n\nPotential variants show up as multiple mismatches in a column. Two questions arise:\n\nhow do we detect variant sites?\nhow do we distinguish variants from sequencing error?\n\n\n\n\nSimple approach: filter bases on quality (e.g., Q20), call heterozygous if 20-80% bases non-reference.\nIssues: undercalls heterozygotes, no measure of uncertainty\n\n\nSolution: probabilistic methods!\n\n\n(Nielsen et al., 2011)\n\n\n\n\nPotential variants show up as multiple mismatches in a column. Left sample has three reads that match the reference so is probably heterozygote. For the right sample no read matches reference so most likely call is homozygote alternate."
  },
  {
    "objectID": "slides/variant_calling/index.html#we-can-calculate-likelihoods-of-observed-data",
    "href": "slides/variant_calling/index.html#we-can-calculate-likelihoods-of-observed-data",
    "title": "Variant calling",
    "section": "We can calculate likelihoods of observed data",
    "text": "We can calculate likelihoods of observed data\nExample (exluding sequencing error!)\n\n\n\n\n\n\n\n\n\n\n\n\n\n   TGC.K....,,,.T..T....,,,,t,\n\n\n\n\n\n\nGoal: calculate likelihood of observing \\(X=\\)G,g,T,T,G,g,t from a genotype \\(G\\). We assume each observation \\(X_i\\) can be treated independently. We restrict possible genotypes to the observed alleles (i.e., G, T). Some observations:\n\nProb(\\(X_1=\\)G assuming genotype T,T) = P(\\(X_1=\\)G|T,T) = \\(0\\)\n\n\nProb(\\(X_1=\\)G assuming genotype G,G) = P(\\(X_1=\\)G|G,G) = \\(1\\)\n\n\nProb(\\(X_1=\\)G assuming genotype G,T) = P(\\(X_1=\\)G|G,T) = \\(0.5\\)\n\n\nTo get total likelihood \\(P(X|G)\\) assuming a genotype \\(G\\) (here G,T), we can multiply over all observations (reads):\n\\[\n\\begin{align}\nP(X|G,T) & = P(X_1=G|G,T)P(X_2=g|G,T)P(X_3=T|G,T)P(X_4=T|G,T) \\\\\n    & P(X_5=G|G,T)P(X_6=g|G,T)P(X_7=t|G,T) = 0.5^7\n\\end{align}\n\\]\n\n\n\n\nWe restrict the possible genotypes to the observed alleles at a site (here G and T). If there are more than two observed alleles, a common procedure is to pick the two with highest frequencies, under the assumption that the rarest observation is a sequencing error.\nIn reality, we also need to take into account sequencing error. There are different ways of doing this (e.g. Maruki & Lynch (2017), DePristo et al. (2011)), but we leave the details to the interested reader."
  },
  {
    "objectID": "slides/variant_calling/index.html#we-can-use-bayes-theorem-to-genotype",
    "href": "slides/variant_calling/index.html#we-can-use-bayes-theorem-to-genotype",
    "title": "Variant calling",
    "section": "We can use Bayes’ theorem to genotype",
    "text": "We can use Bayes’ theorem to genotype\nExample\n\n\n\n\n\n\n\n\n\n\n\n\n\n   TGC.K....,,,.T..T....,,,,t,\n\n\n\n\n\n\nFor a given site, we have a number of observations \\(X\\). We have shown we can calculate the likelihood of observing \\(X\\) given a genotype \\(G\\), \\(P(X|G)\\).\n\nHowever; what we really want to know is the most likely genotype \\(G\\) given the data \\(X\\), or \\(P(G|X)\\).\n\n\nApply Bayes’ theorem:\n\n\\[\nP(G|X) \\sim P(X|G)\\cdot P(G)\n\\]\n\n\n\n\\[\n\\text{posterior} \\sim \\text{likelihood} \\cdot \\text{prior}\n\\]\n\n\nConsequently we need to set a prior on \\(G\\). If allele frequencies are known, we can constrain the frequencies; for example, if A is known to be low (\\(\\sim1\\)%) AA genotype is very unlikely. Otherwise, could set all equal (flat prior).\n\n\n\n\ncf https://gatk.broadinstitute.org/hc/en-us/articles/360035890511\nR. Li et al. (2009), Table 1, shows a nice numerical example of one way of setting priors. The authors assume a specific allele, G, in the reference sequence:\n–G–\nThey start by calculating the frequency of haploid genotypes. They first determine \\(p_G\\) by assuming a heterozygous SNP rate \\(f=0.001\\), which means 1 in a 1000 sites has G/G genotype mutated to G/X, where X is one of {A,C,T}. They assume a transition to transversion (ts/tv) ratio of 4, meaning X=A four times as often as C or T (there is an error in the text where C is taken to be the transition; the numbers in the table are correct however). This gives the following haploid genotype frequencies:\n\\[\\begin{align}\np_G & = 1-f = 0.999 \\\\\np_A & = 4f/6 = 6.67\\times10^{-4} \\\\\np_C & = f/6 = 1.67\\times10^{-4}\\\\\np_T & = f/6 =1.67\\times10^{-4}\n\\end{align}\\]\nTo get the diploid genotypes, we simply multiply the corresponding entries, e.g., \\(p_{AC} = p_Ap_C\\). For homozygote ALT, we need to account for the homozygous SNP rate \\(r = 0.0005\\), where G/G mutates to X/X, for X one of {A,C,T}:\n\\[\\begin{align}\np_{AA} & = p_Ap_A + 4r/6 = 3.33\\times10^{-4} \\\\\np_{AC} & = p_Ap_C = 1.11\\times10^{-7}\\\\\np_{AT} & = p_Ap_T = 1.11\\times10^{-7}\\\\\np_{CC} & = p_Cp_C + r/6 = 8.34\\times10^{-5} \\\\\np_{CG} & = p_Cp_G = 1.67\\times10^{-4}\\\\\np_{CT} & = p_Cp_T = 2.78\\times10^{-8}\\\\\np_{GG} & = 1 - f - r = 0.9985 \\\\\np_{GT} & = p_Gp_T = 1.67\\times10^{-4}\\\\\np_{TT} & = p_Tp_T + r = 8.34\\times10^{-5}\\\\\n\\end{align}\\]"
  },
  {
    "objectID": "slides/variant_calling/index.html#genotype-likelihoods",
    "href": "slides/variant_calling/index.html#genotype-likelihoods",
    "title": "Variant calling",
    "section": "Genotype likelihoods",
    "text": "Genotype likelihoods\nWe have outlined a probabilistic approach to variant calling where we obtain a posterior probability of observing a genotype \\(G\\) given data \\(X\\):\n\\[\nP(G|X) \\sim P(X|G)P(G)\n\\]\n\nAssuming a bi-allelic site, and letting \\(H_1, H_2\\) denote the two alleles, we have three possible genotype likelihoods \\(P(H_1H_1|X)\\), \\(P(H_1H_2|X)\\), and \\(P(H_2H_2|X)\\).\n\n\nThe highest posterior probability is typically chosen as the genotype call, with a measure confidence represented by the genotype probability or ratio between the two most probable calls.\n\n\nGenotype likelihoods are often represented as Phred-scaled likelihoods (again!):\n\\[\n\\text{QUAL} = -10 \\log_{10} P(G|X)\n\\]"
  },
  {
    "objectID": "slides/variant_calling/index.html#variant-call-format-vcf---header",
    "href": "slides/variant_calling/index.html#variant-call-format-vcf---header",
    "title": "Variant calling",
    "section": "Variant Call Format (VCF) - header",
    "text": "Variant Call Format (VCF) - header\n\n\nbcftools view --header-only allsites.vcf.gz | head --lines 1\nbcftools view --header-only allsites.vcf.gz | grep \"##FILTER\"\nbcftools view -h allsites.vcf.gz | grep \"##INFO\" | head -n 4\nbcftools view -h allsites.vcf.gz | grep \"##FORMAT\" | head -n 8\n\n##fileformat=VCFv4.2\n##FILTER=&lt;ID=PASS,Description=\"All filters passed\"&gt;\n##FILTER=&lt;ID=LowQual,Description=\"Low quality\"&gt;\n##INFO=&lt;ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes, for each ALT allele, in the same order as listed\"&gt;\n##INFO=&lt;ID=AF,Number=A,Type=Float,Description=\"Allele Frequency, for each ALT allele, in the same order as listed\"&gt;\n##INFO=&lt;ID=AN,Number=1,Type=Integer,Description=\"Total number of alleles in called genotypes\"&gt;\n##INFO=&lt;ID=BaseQRankSum,Number=1,Type=Float,Description=\"Z-score from Wilcoxon rank sum test of Alt Vs. Ref base qualities\"&gt;\n##FORMAT=&lt;ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\"&gt;\n##FORMAT=&lt;ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"&gt;\n##FORMAT=&lt;ID=GQ,Number=1,Type=Integer,Description=\"Genotype Quality\"&gt;\n##FORMAT=&lt;ID=GT,Number=1,Type=String,Description=\"Genotype\"&gt;\n##FORMAT=&lt;ID=MIN_DP,Number=1,Type=Integer,Description=\"Minimum DP observed within the GVCF block\"&gt;\n##FORMAT=&lt;ID=PGT,Number=1,Type=String,Description=\"Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another; will always be heterozygous and is not intended to describe called alleles\"&gt;\n##FORMAT=&lt;ID=PID,Number=1,Type=String,Description=\"Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group\"&gt;\n##FORMAT=&lt;ID=PL,Number=G,Type=Integer,Description=\"Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification\"&gt;\n\n\nFILTER defines applied filters , INFO fields provide additional information to genotypes, FORMAT specification fields define genotype entries, and more. NB: PL format definition.\n\n\nhttps://samtools.github.io/hts-specs/VCFv4.4.pdf"
  },
  {
    "objectID": "slides/variant_calling/index.html#variant-call-format-vcf---data",
    "href": "slides/variant_calling/index.html#variant-call-format-vcf---data",
    "title": "Variant calling",
    "section": "Variant Call Format (VCF) - data",
    "text": "Variant Call Format (VCF) - data\n\nbcftools view --header-only --samples PUN-R-ELF,PUN-Y-INJ allsites.vcf.gz |\\\n tail --lines 1\nbcftools view --no-header  --samples PUN-R-ELF,PUN-Y-INJ allsites.vcf.gz LG4:6886\n\n#CHROM  POS ID  REF ALT QUAL    FILTER  INFO    FORMAT  PUN-R-ELF   PUN-Y-INJ\nLG4 6886    .   C   T   722.43  .   AC=2;AF=0.222;AN=4;BaseQRankSum=0;DP=82;ExcessHet=1.8123;FS=1.309;InbreedingCoeff=-0.155;MLEAC=4;MLEAF=0.222;MQ=60;MQRankSum=0;QD=18.52;ReadPosRankSum=0.577;SOR=0.44   GT:AD:DP:GQ:PGT:PID:PL:PS   0/1:3,8:11:50:.:.:189,0,50:.    0/1:2,2:4:45:.:.:45,0,45:.\n\n\n\nQUAL: Phred-scaled quality score for Prob(ALT is wrong): \\(722.43\\) (\\(p=10^{-Q/10}=5.7e-73\\))\nINFO field summarizes data for all samples. For instance:\n\nallele count 2 (AC=2)\nallele frequency minor allele 0.222 (AF=0.222)\n\n\n\nhttps://samtools.github.io/hts-specs/VCFv4.4.pdf"
  },
  {
    "objectID": "slides/variant_calling/index.html#variant-call-format-vcf---data-1",
    "href": "slides/variant_calling/index.html#variant-call-format-vcf---data-1",
    "title": "Variant calling",
    "section": "Variant Call Format (VCF) - data",
    "text": "Variant Call Format (VCF) - data\n\n\n#CHROM  POS ID  REF ALT QUAL    FILTER  INFO    FORMAT  PUN-R-ELF   PUN-Y-INJ\nLG4 6886    .   C   T   722.43  .   AC=2;AF=0.222;AN=4;BaseQRankSum=0;DP=82;ExcessHet=1.8123;FS=1.309;InbreedingCoeff=-0.155;MLEAC=4;MLEAF=0.222;MQ=60;MQRankSum=0;QD=18.52;ReadPosRankSum=0.577;SOR=0.44   GT:AD:DP:GQ:PGT:PID:PL:PS   0/1:3,8:11:50:.:.:189,0,50:.    0/1:2,2:4:45:.:.:45,0,45:.\n\n\n\n\n\nGenotypes (GT:AD:DP:GQ:PGT:PID:PL:PS)\n\nPUN-R-ELF: 0/1:3,8:11:50:.:.:189,0,50:.\nGT=0/1, AD=3,8 =&gt; 3 REF, 8 ALT, DP=11 =&gt; sequence depth = 11, PL=189,0,50\nPUN-Y-INJ: 0/1:2,2:4:45:.:.:45,0,45:.\nGT=0/1, AD=2,2 =&gt; 2 REF, 2 ALT, DP=4 =&gt; sequence depth = 4, PL=45,0,45\n\n\nRelative genotype probabilities\n\nCan convert Phred-scaled quality scores to probabilities as\n\\[\np = 10^{-Q/10}\n\\]\nFor PUN-R-ELF the relative probabilities are \\(10^{-189/10}\\approx1.26e-9\\), \\(10^{0}=1\\), \\(10^{50}=10^{-5}\\).\nInterpretation: 0/1 10,000 times more likely than 1/1 (\\(1/10^{-5}\\))\n\n\n\n\n\n\n\nELF\n\n\n\n\n\n\nELF\n\n   TCT.Y..T.....T.,,,.T.,,,.T..........,t,,t,,t,,t,\n\n\n\n\n\n\n\nINJ\n\n\n\n\n\n\nINJ\n\n   TCT.Y..T....,,,,,,,,,.T.\n\n\n\n\n\n:::::\n::::::\n\nQUAL: Phred-scaled quality score for the assertion made in ALT. i.e. \\(-10log_{10}\\) prob(call in ALT is wrong)"
  },
  {
    "objectID": "slides/variant_calling/index.html#gatk-best-practice",
    "href": "slides/variant_calling/index.html#gatk-best-practice",
    "title": "Variant calling",
    "section": "GATK best practice",
    "text": "GATK best practice\n\n\n\n\n\n\n\n\nhttps://gatk.broadinstitute.org/hc/en-us/articles/360035535932-Germline-short-variant-discovery-SNPs-Indels-\n\n\n\nPros\n\n\nBest practices\nLarge documentation\nVariant quality score recalibration\n\n\nCons\n\n\nHuman-centric - very slow runtime on genomes with many sequences\nComplicated setup"
  },
  {
    "objectID": "slides/variant_calling/index.html#alternative-variant-callers",
    "href": "slides/variant_calling/index.html#alternative-variant-callers",
    "title": "Variant calling",
    "section": "Alternative variant callers",
    "text": "Alternative variant callers\n\n\nfreebayes\nBayesian genetic variant detector. Simpler setup.\nMay struggle in high-coverage regions.\n\n(Garrison & Marth, 2012)\n\n\nbcftools\nUtilities for variant calling and manipulating VCFs and BCFs.\n\n(Danecek et al., 2021)\n\n\nANGSD\nFor low-coverage sequencing. Doesn’t do explicit genotyping; most methods take genotype uncertainty into account.\n\n(Korneliussen et al., 2014)\n\n\n\n\nReference bias: plot no. hets vs coverage for real data, e.g., conifer\n\n\nNB: samtools and GATK may actually produce different genotypes despite having identical GLs. Samtools applies prior \\(10^{-3}\\) to het call, GATK has no prior (H. Li, 2014)"
  },
  {
    "objectID": "slides/variant_calling/index.html#the-monkeyflower-system",
    "href": "slides/variant_calling/index.html#the-monkeyflower-system",
    "title": "Variant calling",
    "section": "The monkeyflower system",
    "text": "The monkeyflower system\n\n\n\n\n\n\n\n\n\nFrom https://jgi.doe.gov/csp-2021-genomic-resources-for-mimulus/\n\nPlants in the genus Mimulus inhabit highly variable habitats and are famous for their extraordinary ecological diversity. Mimulus is now a powerful system for ecological genomic studies, thanks to its experimental tractability, rapidly growing research community, and the JGI-generated reference genome for M. guttatus."
  },
  {
    "objectID": "slides/variant_calling/index.html#learning-outcomes",
    "href": "slides/variant_calling/index.html#learning-outcomes",
    "title": "Variant calling",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nFollow GATK best practices to\n\nPerform qc on sequencing reads and interpret results\nPrepare reference for read mapping\nMap reads to reference\nMark duplicates\nPerform raw variant calling to generate a set of sites to exclude from recalibration\nPerform base quality score recalibration\nPerform variant calling on base recalibrated data\nDo genotyping on all samples and combine results to a raw variant call set"
  },
  {
    "objectID": "slides/variant_calling/index.html#bibliography",
    "href": "slides/variant_calling/index.html#bibliography",
    "title": "Variant calling",
    "section": "Bibliography",
    "text": "Bibliography\n\n\nVariant calling\n\n\n\nAllendorf, F. W., Funk, W. C., Aitken, S. N., Byrne, M., & Luikart, G. (2022). Population Genomics. In F. W. Allendorf, W. C. Funk, S. N. Aitken, M. Byrne, G. Luikart, & A. Antunes (Eds.), Conservation and the Genomics of Populations (p. 0). Oxford University Press. https://doi.org/10.1093/oso/9780198856566.003.0004\n\n\nDanecek, P., Bonfield, J. K., Liddle, J., Marshall, J., Ohan, V., Pollard, M. O., Whitwham, A., Keane, T., McCarthy, S. A., Davies, R. M., & Li, H. (2021). Twelve years of SAMtools and BCFtools. GigaScience, 10(2), giab008. https://doi.org/10.1093/gigascience/giab008\n\n\nDePristo, M. A., Banks, E., Poplin, R., Garimella, K. V., Maguire, J. R., Hartl, C., Philippakis, A. A., del Angel, G., Rivas, M. A., Hanna, M., McKenna, A., Fennell, T. J., Kernytsky, A. M., Sivachenko, A. Y., Cibulskis, K., Gabriel, S. B., Altshuler, D., & Daly, M. J. (2011). A framework for variation discovery and genotyping using next-generation DNA sequencing data. Nature Genetics, 43(5), 491–498. https://doi.org/10.1038/ng.806\n\n\nDonato, L., Scimone, C., Rinaldi, C., D’Angelo, R., & Sidoti, A. (2021). New evaluation methods of read mapping by 17 aligners on simulated and empirical NGS data: An updated comparison of DNA- and RNA-Seq data from Illumina and Ion Torrent technologies. Neural Computing and Applications, 33(22), 15669–15692. https://doi.org/10.1007/s00521-021-06188-z\n\n\nGarrison, E., & Marth, G. (2012). Haplotype-based variant detection from short-read sequencing. arXiv:1207.3907 [q-Bio]. http://arxiv.org/abs/1207.3907\n\n\nKorneliussen, T. S., Albrechtsen, A., & Nielsen, R. (2014). ANGSD: Analysis of Next Generation Sequencing Data. BMC Bioinformatics, 15(1), 356. https://doi.org/10.1186/s12859-014-0356-4\n\n\nLi, H. (2013). Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM. arXiv:1303.3997 [q-Bio]. https://arxiv.org/abs/1303.3997\n\n\nLi, H. (2014). Toward better understanding of artifacts in variant calling from high-coverage samples. Bioinformatics, 30(20), 2843–2851. https://doi.org/10.1093/bioinformatics/btu356\n\n\nLi, H. (2018). Minimap2: Pairwise alignment for nucleotide sequences. Bioinformatics, 34(18), 3094–3100. https://doi.org/10.1093/bioinformatics/bty191\n\n\nLi, R., Li, Y., Fang, X., Yang, H., Wang, J., Kristiansen, K., & Wang, J. (2009). SNP detection for massively parallel whole-genome resequencing. Genome Research, 19(6), 1124–1132. https://doi.org/10.1101/gr.088013.108\n\n\nLou, R. N., Jacobs, A., Wilder, A. P., & Therkildsen, N. O. (2021). A beginner’s guide to low-coverage whole genome sequencing for population genomics. Molecular Ecology, 30(23), 5966–5993. https://doi.org/10.1111/mec.16077\n\n\nMaruki, T., & Lynch, M. (2017). Genotype Calling from Population-Genomic Sequencing Data. G3 Genes|Genomes|Genetics, 7(5), 1393–1404. https://doi.org/10.1534/g3.117.039008\n\n\nNielsen, R., Paul, J. S., Albrechtsen, A., & Song, Y. S. (2011). Genotype and SNP calling from next-generation sequencing data. Nature Reviews Genetics, 12(6), 443–451. https://doi.org/10.1038/nrg2986"
  },
  {
    "objectID": "slides/foundations/index.html#intended-learning-outcomes",
    "href": "slides/foundations/index.html#intended-learning-outcomes",
    "title": "Population genetics",
    "section": "Intended learning outcomes",
    "text": "Intended learning outcomes\nIntroduction to foundations of population genetics with an emphasis on genealogies\n\nDescription of DNA variation data\nWright-Fisher population model and genealogies\nGenetic drift\nWright-Fisher model with mutation\nMutation-drift balance\nNeutral theory\nSelection basics\n\n\nObjective: introduce the foundations of population genetics, with an emphasis on genealogies. Framing population genetic concepts in trees will facilitate the introduction of the coalescent in the afternoon.\nThe lecture presents sequence data, the Wright-Fisher model, genetic drift, mutation, and selection. The focus is to familiarise students with concepts and basic theory."
  },
  {
    "objectID": "slides/foundations/index.html#dna-variation-1",
    "href": "slides/foundations/index.html#dna-variation-1",
    "title": "Population genetics",
    "section": "DNA variation",
    "text": "DNA variation\n\n\nSequence aligmnent of four DNA sequences (Hahn, 2019, Fig 1.1). \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\nT\nT\nA\nC\nA\nA\nT\nC\nC\nG\nA\nT\nC\nG\nT\n\n\nT\nT\nA\nC\nG\nA\nT\nG\nC\nG\nC\nT\nC\nG\nT\n\n\nT\nC\nA\nC\nA\nA\nT\nG\nC\nG\nA\nT\nG\nG\nA\n\n\nT\nT\nA\nC\nG\nA\nT\nG\nC\nG\nC\nT\nC\nG\nT\n\n\n\n\nThe main data for molecular population genetics are DNA sequences. The alignment above shows a sample of four DNA sequences. Each sequence has 15 nucleotides (sites) “from the same locus (location) on a chromosome” (p.2 Hahn, 2019)\n\n\n\nAlternative names for sequence:\n\n\n\n\n\nchromosome\ngene\n\n\n\n\n\nallele (different by origin)\nsample\ncistron\n\n\n\n\n\n\nWe will preferentially use sequence or chromosome to refer to an entire sequence, and allele to refer to individual nucleotides that differ."
  },
  {
    "objectID": "slides/foundations/index.html#dna-variation---monomorphic-sites",
    "href": "slides/foundations/index.html#dna-variation---monomorphic-sites",
    "title": "Population genetics",
    "section": "DNA variation - monomorphic sites",
    "text": "DNA variation - monomorphic sites\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\nT\nT\nA\nC\nA\nA\nT\nC\nC\nG\nA\nT\nC\nG\nT\n\n\nT\nT\nA\nC\nG\nA\nT\nG\nC\nG\nC\nT\nC\nG\nT\n\n\nT\nC\nA\nC\nA\nA\nT\nG\nC\nG\nA\nT\nG\nG\nA\n\n\nT\nT\nA\nC\nG\nA\nT\nG\nC\nG\nC\nT\nC\nG\nT\n\n\n*\n\n*\n*\n\n*\n*\n\n*\n*\n\n*\n\n*\nT\n\n\n\n\nThe alignment has 4 DNA sequences where each sequence has length \\(L=15\\). A site where all nucleotides (alleles) are identical is called a monomorphic site (indicated with asterisks above). There are 9 monomorphic sites."
  },
  {
    "objectID": "slides/foundations/index.html#dna-variation---segregating-sites",
    "href": "slides/foundations/index.html#dna-variation---segregating-sites",
    "title": "Population genetics",
    "section": "DNA variation - segregating sites",
    "text": "DNA variation - segregating sites\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\nT\nT\nA\nC\nA\nA\nT\nC\nC\nG\nA\nT\nC\nG\nT\n\n\nT\nT\nA\nC\nG\nA\nT\nG\nC\nG\nC\nT\nC\nG\nT\n\n\nT\nC\nA\nC\nA\nA\nT\nG\nC\nG\nA\nT\nG\nG\nA\n\n\nT\nT\nA\nC\nG\nA\nT\nG\nC\nG\nC\nT\nC\nG\nT\n\n\n\n*\n\n\n*\n\n\n*\n\n\n*\n\n*\n\n*\n\n\n\n\nA site where there are different nucleotides (alleles) is called a segregating site (indicated with asterisks above), often denoted S. There are \\(S=6\\) segregating sites.\n\n\n\nAlternative names for segregating site are:\n\n\n\npolymorphism\nmutation\nsingle nucleotide polymorphism (SNP)\n\n\n\n\nmutation here and onwards refers to the process that generates new variation and the new variants generated by this process\nIn contrast to mutation which corresponds to within-species variation, a substitution refers to DNA differences between species."
  },
  {
    "objectID": "slides/foundations/index.html#dna-variation---major-and-minor-alleles",
    "href": "slides/foundations/index.html#dna-variation---major-and-minor-alleles",
    "title": "Population genetics",
    "section": "DNA variation - major and minor alleles",
    "text": "DNA variation - major and minor alleles\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\nT\nT\nA\nC\nA\nA\nT\nC\nC\nG\nA\nT\nC\nG\nT\n\n\nT\nT\nA\nC\nG\nA\nT\nG\nC\nG\nC\nT\nC\nG\nT\n\n\nT\nC\nA\nC\nA\nA\nT\nG\nC\nG\nA\nT\nG\nG\nA\n\n\nT\nT\nA\nC\nG\nA\nT\nG\nC\nG\nC\nT\nC\nG\nT\n\n\n\n*\n\n\n*\n\n\n*\n\n\n*\n\n*\n\n*\n\n\n\n\nMuch of the nucleotide variation we study consists of bi-allelic SNPs. The most common variant is called the major allele, and the least common the minor allele.\nThe set of alleles found on a single sequence is called haplotype."
  },
  {
    "objectID": "slides/foundations/index.html#describing-dna-variation---heterozygosity",
    "href": "slides/foundations/index.html#describing-dna-variation---heterozygosity",
    "title": "Population genetics",
    "section": "Describing DNA variation - heterozygosity",
    "text": "Describing DNA variation - heterozygosity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\nT\nT\nA\nC\nA\nA\nT\nC\nC\nG\nA\nT\nC\nG\nT\n\n\nT\nT\nA\nC\nG\nA\nT\nG\nC\nG\nC\nT\nC\nG\nT\n\n\nT\nC\nA\nC\nA\nA\nT\nG\nC\nG\nA\nT\nG\nG\nA\n\n\nT\nT\nA\nC\nG\nA\nT\nG\nC\nG\nC\nT\nC\nG\nT\n\n\n\n*\n\n\n*\n\n\n*\n\n\n*\n\n*\n\n*\n\n\n\n\nOnce we have a sample of sequences we want to describe the observed variation. At any position the ith allele has sample frequency \\(p_i\\), where the sum of all allele frequencies is 1. For instance, at site 1, \\(p_T=1\\) (and by extension \\(p_A=p_C=p_G=0\\)), and at site 2 \\(p_C=1/4\\) and \\(p_T=3/4\\).\n\n\n\n\nHeterozygosity\n\nThe heterozygosity at a site \\(j\\) is given by\n\\[\nh_j = \\frac{n}{n-1}\\left(1 - \\sum_i p_i^2\\right)\n\\]\nwhere the summation is over all alleles and \\(p_i\\) is the frequency of the \\(i\\)-th allele\n\n\n\n\nExercise: calculate the heterozygosity at sites 1, 2 and 5\n\n\n\n\n\\[\nh_1 = \\frac{4}{3} \\left(1 - p_T^2 \\right) = 0 \\\\\nh_2 = \\frac{4}{3} \\left(1 - \\left(p_C^2 + p_T^2\\right) \\right) = \\frac{4}{3} \\left( 1 - \\left(\\frac{1}{16} + \\frac{9}{16}\\right)\\right) = \\frac{1}{2}\\\\\nh_5 = \\frac{4}{3} \\left(1 - \\left(p_A^2 + p_G^2\\right) \\right) = \\frac{4}{3} \\left( 1 - \\left(\\frac{1}{4} + \\frac{1}{4}\\right)\\right) = \\frac{2}{3}\n\\]\n\n\n\n\n\nIn a randomly mating population, the heterozygosity is equal to the frequency of heterozygotes. Note however that the definition of heterozygosity only relies on allele frequencies, which means it can be applied to populations that are not in Hardy-Weinberg equilibrium. It can also be applied to haploid organisms, like bacteria."
  },
  {
    "objectID": "slides/foundations/index.html#describing-dna-variation---nucleotide-diversity",
    "href": "slides/foundations/index.html#describing-dna-variation---nucleotide-diversity",
    "title": "Population genetics",
    "section": "Describing DNA variation - nucleotide diversity",
    "text": "Describing DNA variation - nucleotide diversity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\nT\nT\nA\nC\nA\nA\nT\nC\nC\nG\nA\nT\nC\nG\nT\n\n\nT\nT\nA\nC\nG\nA\nT\nG\nC\nG\nC\nT\nC\nG\nT\n\n\nT\nC\nA\nC\nA\nA\nT\nG\nC\nG\nA\nT\nG\nG\nA\n\n\nT\nT\nA\nC\nG\nA\nT\nG\nC\nG\nC\nT\nC\nG\nT\n\n\n\n*\n\n\n*\n\n\n*\n\n\n*\n\n*\n\n*\n\n\n\n\n\n\n\n\nNucleotide diversity \\(\\pi\\)\n\nThe nucleotide diversity is the sum of site heterozygosities:\n\\[\n\\pi = \\sum_{j=1}^S h_j\n\\]\nwhere \\(S\\) is the number of segregating sites\n\n\n\n\nCalculate the nucleotide diversity\n\n\n\nObservation: \\(h_i\\) either 1/2 or 2/3 (for sites with \\(p_{major}=p_{minor}\\)).\n\n\n\n\\[\n\\pi = \\frac{1}{2} + \\frac{2}{3} + \\frac{1}{2} + \\frac{2}{3} + \\frac{1}{2} + \\frac{1}{2} = 3\\frac{1}{3}\n\\]\n\n\n\nOften we provide \\(\\pi\\) per site:\n\\[\n\\pi = 3.33/15 = 0.222\n\\]\n\n\n\n\nHahn (2019) implicitly assumes we are looking at DNA polymorphism. The expression actually holds for any genetic variation at a locus, and is sometimes called the gene diversity (Nei & Kumar, 2000, p. 245).\nUnder the infinite sites model, \\(E(\\pi)=\\theta=4N_e\\mu\\), for which reason \\(\\pi\\) sometimes is called \\(\\theta_\\pi\\). The measure gives the average number of pairwise nucleotide differences between two sequences, so an alternative expression is\n\\[\n\\pi = \\frac{\\sum_{i&lt;j}k_{ij}}{n(n-1)/2}\n\\]\nThe latter expression is called the nucleotide diversity (Nei & Kumar, 2000, p. 251)."
  },
  {
    "objectID": "slides/foundations/index.html#alleles-as-algebraic-entities",
    "href": "slides/foundations/index.html#alleles-as-algebraic-entities",
    "title": "Population genetics",
    "section": "Alleles as algebraic entities",
    "text": "Alleles as algebraic entities\n\n\nRecall: alleles refer to different variants of a sequence at a locus (genomic position).\n\nWhatever the underlying molecular nature (gene, chromosome, nucleotide, protein), let’s represent a locus by a letter, e.g., \\(A\\) (\\(B\\) if two loci, and so on)\n\n\nIf locus has many alleles \\(1, 2, ...\\) , could use indexing \\(A_1, A_2, ...\\).\n\n\nWill use combination \\(A\\), \\(a\\) for bi-allelic loci from now on\n\n\n\n\n\n\nExample: gene coding for flower color\n\n\n\n\n \\(A\\) red color\n \\(a\\) white color\n\nPunnett square\n\n\n \\ \n\n\nA\n\n\na\n\n\nA\n\n\n\n\n\n\n\n\na\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenotype\n\n\naa\n\n\nAa\n\n\nAA\n\n\nPhenotype\n\n\n\n\n\n\n\n\n\n\n\nHeterozygote has intermediate color phenotype (pink).\n\n\n\n\n\n\n\n\n\nUntil now the examples have been based on nucleotide sequences. However, much of population genetic theory was developed before the nature of heredity (DNA) was known. In these early days, an allele would refer to variant forms of a gene, observed as differences in phenotypes. Genes, or loci, would be denoted using alphabetic characters, such as \\(A\\), and allelic types could be referenced with indices, e.g., \\(A_1, A_2, ..., A_n\\).\nTo simplify calculations, we often look at one locus and we assume two alleles, whereby we skip the indices and denote the allelic pairs \\(A\\) and \\(a\\) (although note that notations differs from author to author; for instance Gillespie (2004) uses \\(A_1, A_2\\) for bi-allelic loci). For two-locus systems we simply denote the second allele with \\(B, b\\), and so on.\nThe example shows a hypothetical locus having two alleles \\(A\\) and \\(a\\) that have phenotypes red and white flower color, and where heterozygotes are colored pink. The Punnett square shows how gamete combinations form genotypes and their corresponding phenotypes."
  },
  {
    "objectID": "slides/foundations/index.html#alleles-and-frequencies",
    "href": "slides/foundations/index.html#alleles-and-frequencies",
    "title": "Population genetics",
    "section": "Alleles and frequencies",
    "text": "Alleles and frequencies\nWe will be interested in looking at the dynamics of alleles, i.e., how their abundances in the population change over time. Therefore we want to measure the frequencies of alleles \\(A\\) and \\(a\\).\n\n\n\n\n\n\nExample\n\n\nAssume following population (\\(n=10\\), with \\(n_{AA}=5\\), \\(n_{Aa}=4\\), \\(n_{aa}=1\\)):\n         \n\nLet \\(p\\) be frequency of \\(A\\) alleles, \\(q=1-p\\) frequency of \\(a\\) alleles; then\n5 \\(AA\\) individuals, 4 \\(Aa\\) individuals \\(\\Rightarrow p=\\frac{5\\cdot2 + 4\\cdot1}{10\\cdot2}=\\frac{14}{20}=0.7\\)\nand \\(q=1-p=\\frac{6}{20}=0.3\\)\n\n\nInserting frequencies into Punnett square gives expected frequency of offspring genotypes.\n\n\n\n\n\n\n\n\n\n \\ \n\n\n\\(A\\) (\\(p=0.7\\))\n\n\n\\(a\\) (\\(q=0.3\\))\n\n\n\\(A\\) (\\(p=0.7\\))\n\n\n\n\\(p\\cdot p = 0.49\\)\n\n\n\n\\(p\\cdot q = 0.21\\)\n\n\n\\(a\\) (\\(q=0.3\\))\n\n\n\n\\(q\\cdot p = 0.21\\)\n\n\n\n\\(q\\cdot q = 0.09\\)\n\n\n\n\nExpected allele frequencies after mating: \\(p=p^2 + pq=0.7\\), \\(q=1-p=0.3\\)\n\n\n\n\nGiven \\(n\\) diploid individuals, there are \\(2n\\) alleles in the population. The frequency of allele \\(A\\) is then the homozygote \\(AA\\) times two, plus one times the individuals carrying one \\(A\\).\nThe Punnett square shows that the expected homozygote frequencies are \\(0.49\\) and \\(0.09\\) for \\(AA\\) and \\(aa\\), and hence, the frequency of \\(Aa\\) is \\(1 - 0.49 - 0.09 = 0.42 = 0.21 + 0.21 = 2pq\\)"
  },
  {
    "objectID": "slides/foundations/index.html#in-absence-of-evolutionary-forces-alleles-are-in-equilibrium",
    "href": "slides/foundations/index.html#in-absence-of-evolutionary-forces-alleles-are-in-equilibrium",
    "title": "Population genetics",
    "section": "In absence of evolutionary forces alleles are in equilibrium",
    "text": "In absence of evolutionary forces alleles are in equilibrium\nThe Hardy-Weinberg equilibrium\nFor a locus, let \\(A\\) and \\(a\\) be two different alleles and let \\(p\\) be the frequency of the \\(A\\) allele and \\(q=1-p\\) the frequency of the \\(a\\) allele. In the absence of mutation, drift, migration, and other evolutionary processes, the equilibrium state is given by the Hardy-Weinberg equilibrium (HWE).\n\n\n\n\n\n\n\\(A\\) (\\(p\\))\n\\(a\\) (\\(q\\))\n\n\n\n\n\\(A\\) (\\(p\\))\n\\(p^2\\)\n\\(pq\\)\n\n\n\\(a\\) (\\(q\\))\n\\(qp\\)\n\\(q^2\\)\n\n\n\n\n\n\n\n\nGenotype:\n\\(AA\\)\n\\(Aa\\)\n\\(aa\\)\n\n\nFrequency:\n\\(p^2\\)\n\\(2pq\\)\n\\(q^2\\)\n\n\n\n\\(f_{AA}\\)\n\\(f_{Aa}\\)\n\\(f_{aa}\\)\n\n\n\n\n\nUnder HWE assumption, neither allele nor genotype frequencies change over time.\nImportantly, we can calculate allele frequencies from genotype frequencies and vice versa:\n\\[\np = f_{AA} + \\frac{f_{Aa}}{2} = p^2 + pq\\\\\nq = f_{aa} + \\frac{f_{Aa}}{2} = q^2 + pq\\\\\n\\]\n\nSegue: apart from describing the variation via e.g., diversity measures, we want to model how allele frequencies change in time. As (Gillespie, 2004, preface p. xi) points out, “While genotype frequencies are easily measured, their change is not”\nIOW: describing variation fine, but where does it come from and how does it change?\nIf assumptions of HWE hold, we have no change of variation. However, we want to look at change of variation and disentangle the forces that impose change\nHWE assumption gives us a way to calculate allele frequencies from genotype frequencies. How well do these assumptions hold in real data? See next slide."
  },
  {
    "objectID": "slides/foundations/index.html#natural-populations-do-mate-randomly",
    "href": "slides/foundations/index.html#natural-populations-do-mate-randomly",
    "title": "Population genetics",
    "section": "Natural populations do mate randomly?",
    "text": "Natural populations do mate randomly?\n\n\n\n\n\nFigure 1: Hardy-Weinberg proportions in 10,000 SNPs on chromosome 22 from three populations based on 1000 genomes data. For each SNP, genotypes are given as counts (minor/heterozygote/major), converted to frequencies and plotted on the y-axis. Allele frequencies are obtained from genotype frequencies and plotted on the x-axis. Most observations follow HWE proportions. Deviations from HWE can indicate sample QC issues, or that there is population structure. Illustration inspired by cooplab (2011). \n\n\n\n\n\n\n\nSo how do the HWE assumptions hold up in real data? The figure shows three human populations from the 1000 genomes data, for which 10,000 SNPs have been selected. For each SNP, we know the genotype frequencies \\(AA\\), \\(Aa\\), \\(aa\\) and can therefore calculate the allele frequencies for \\(A\\) and \\(a\\) using the equations on the preceding slide (e.g., \\(p=p_{AA}+p_{Aa}/2\\)).\nNote that 1000 genomes data have sorted genotype frequencies, so to produce nice symmetrical plots, half the genotype frequencies have been reversed (minor/het/major -&gt; major/het/minor).\n\nSee https://stackoverflow.com/questions/26587940/ggplot2-different-legend-symbols-for-points-and-lines for legend customization."
  },
  {
    "objectID": "slides/foundations/index.html#the-obsession-of-population-genetics",
    "href": "slides/foundations/index.html#the-obsession-of-population-genetics",
    "title": "Population genetics",
    "section": "The obsession of population genetics",
    "text": "The obsession of population genetics\nPopulation genetics is about (Gillespie, 2004)\n\ndescribing the genetic structure of populations\nconstructing theories on the forces that influence genetic variation\n\n\n\n\nQuestions to ponder:\n\nwhy does variation look the way it does?\nhow is variation maintained?\nhow does variation change over time (\\(\\Delta p\\))?\nwhat forces shape the genetic structure of populations?\n\n\n\n\n         \n\\(p=0.1\\)\n\n\n\\(\\large\\rightarrow\\)\n\n\n         \n\\(p=0.5\\)\n\n\n\\(\\large\\rightarrow\\)\n\n\n         \n\\(p=0.9\\)\n\n\n\n\n\n\nFrom HWE: we want to look a the creation, maintenance and loss of variation and what forces affect it\nGoal: describe theory behind evolving populations. This has been an obsession for a long time, even before DNA was known. We need to get back to basics."
  },
  {
    "objectID": "slides/foundations/index.html#wright-fisher-model",
    "href": "slides/foundations/index.html#wright-fisher-model",
    "title": "Population genetics",
    "section": "Wright-Fisher model",
    "text": "Wright-Fisher model\n\n\nModel of populations that describes genealogical relationships of genes (chromosomes) in a population under the following assumptions (Hein et al., 2005):\n\n\ndiscrete and non-overlapping generations\nhaploid individuals or two subpopulations (males and females)\nconstant population size\nall individuals are equally fit\npopulation has no geographical or social structure\nno recombination\n\n\n\n\n\n\n\nSee Hein et al. (2004) for more assumptions. The second assumption means we can use 2N chromosome interchangeably for haploid (n=2N) and diploid (n=N) populations."
  },
  {
    "objectID": "slides/foundations/index.html#wright-fisher-model-1",
    "href": "slides/foundations/index.html#wright-fisher-model-1",
    "title": "Population genetics",
    "section": "Wright-Fisher model",
    "text": "Wright-Fisher model\n\n\nModel of populations that describes genealogical relationships of genes (chromosomes) in a population under the following assumptions (Hein et al., 2005):\n\ndiscrete and non-overlapping generations\nhaploid individuals or two subpopulations (males and females)\nconstant population size\nall individuals are equally fit\npopulation has no geographical or social structure\nno recombination\n\nAlgorithm\n\nSetup starting population at time zero"
  },
  {
    "objectID": "slides/foundations/index.html#wright-fisher-model-2",
    "href": "slides/foundations/index.html#wright-fisher-model-2",
    "title": "Population genetics",
    "section": "Wright-Fisher model",
    "text": "Wright-Fisher model\n\n\nModel of populations that describes genealogical relationships of genes (chromosomes) in a population under the following assumptions (Hein et al., 2005):\n\ndiscrete and non-overlapping generations\nhaploid individuals or two subpopulations (males and females)\nconstant population size\nall individuals are equally fit\npopulation has no geographical or social structure\nno recombination\n\nAlgorithm\n\nSetup starting population at time zero\nAdd offspring (same size) at time one"
  },
  {
    "objectID": "slides/foundations/index.html#wright-fisher-model-3",
    "href": "slides/foundations/index.html#wright-fisher-model-3",
    "title": "Population genetics",
    "section": "Wright-Fisher model",
    "text": "Wright-Fisher model\n\n\nModel of populations that describes genealogical relationships of genes (chromosomes) in a population under the following assumptions (Hein et al., 2005):\n\ndiscrete and non-overlapping generations\nhaploid individuals or two subpopulations (males and females)\nconstant population size\nall individuals are equally fit\npopulation has no geographical or social structure\nno recombination\n\nAlgorithm\n\nSetup starting population at time zero\nAdd offspring (same size) at time one\nSelect parents to offspring at random"
  },
  {
    "objectID": "slides/foundations/index.html#wright-fisher-model-4",
    "href": "slides/foundations/index.html#wright-fisher-model-4",
    "title": "Population genetics",
    "section": "Wright-Fisher model",
    "text": "Wright-Fisher model\n\n\nModel of populations that describes genealogical relationships of genes (chromosomes) in a population under the following assumptions (Hein et al., 2005):\n\ndiscrete and non-overlapping generations\nhaploid individuals or two subpopulations (males and females)\nconstant population size\nall individuals are equally fit\npopulation has no geographical or social structure\nno recombination\n\nAlgorithm\n\nSetup starting population at time zero\nAdd offspring (same size) at time one\nSelect parents to offspring at random"
  },
  {
    "objectID": "slides/foundations/index.html#wright-fisher-model-5",
    "href": "slides/foundations/index.html#wright-fisher-model-5",
    "title": "Population genetics",
    "section": "Wright-Fisher model",
    "text": "Wright-Fisher model\n\n\nModel of populations that describes genealogical relationships of genes (chromosomes) in a population under the following assumptions (Hein et al., 2005):\n\ndiscrete and non-overlapping generations\nhaploid individuals or two subpopulations (males and females)\nconstant population size\nall individuals are equally fit\npopulation has no geographical or social structure\nno recombination\n\nAlgorithm\n\nSetup starting population at time zero\nAdd offspring (same size) at time one\nSelect parents to offspring at random"
  },
  {
    "objectID": "slides/foundations/index.html#wright-fisher-model-6",
    "href": "slides/foundations/index.html#wright-fisher-model-6",
    "title": "Population genetics",
    "section": "Wright-Fisher model",
    "text": "Wright-Fisher model\n\n\nModel of populations that describes genealogical relationships of genes (chromosomes) in a population under the following assumptions (Hein et al., 2005):\n\ndiscrete and non-overlapping generations\nhaploid individuals or two subpopulations (males and females)\nconstant population size\nall individuals are equally fit\npopulation has no geographical or social structure\nno recombination\n\nAlgorithm\n\nSetup starting population at time zero\nAdd offspring (same size) at time one\nSelect parents to offspring at random"
  },
  {
    "objectID": "slides/foundations/index.html#wright-fisher-model-7",
    "href": "slides/foundations/index.html#wright-fisher-model-7",
    "title": "Population genetics",
    "section": "Wright-Fisher model",
    "text": "Wright-Fisher model\n\n\nModel of populations that describes genealogical relationships of genes (chromosomes) in a population under the following assumptions (Hein et al., 2005):\n\ndiscrete and non-overlapping generations\nhaploid individuals or two subpopulations (males and females)\nconstant population size\nall individuals are equally fit\npopulation has no geographical or social structure\nno recombination\n\nAlgorithm\n\nSetup starting population at time zero\nAdd offspring (same size) at time one\nSelect parents to offspring at random"
  },
  {
    "objectID": "slides/foundations/index.html#wright-fisher-model-8",
    "href": "slides/foundations/index.html#wright-fisher-model-8",
    "title": "Population genetics",
    "section": "Wright-Fisher model",
    "text": "Wright-Fisher model\n\n\nModel of populations that describes genealogical relationships of genes (chromosomes) in a population under the following assumptions (Hein et al., 2005):\n\ndiscrete and non-overlapping generations\nhaploid individuals or two subpopulations (males and females)\nconstant population size\nall individuals are equally fit\npopulation has no geographical or social structure\nno recombination\n\nAlgorithm\n\nSetup starting population at time zero\nAdd offspring (same size) at time one\nSelect parents to offspring at random"
  },
  {
    "objectID": "slides/foundations/index.html#wright-fisher-model-9",
    "href": "slides/foundations/index.html#wright-fisher-model-9",
    "title": "Population genetics",
    "section": "Wright-Fisher model",
    "text": "Wright-Fisher model\n\n\nModel of populations that describes genealogical relationships of genes (chromosomes) in a population under the following assumptions (Hein et al., 2005):\n\ndiscrete and non-overlapping generations\nhaploid individuals or two subpopulations (males and females)\nconstant population size\nall individuals are equally fit\npopulation has no geographical or social structure\nno recombination\n\nAlgorithm\n\nSetup starting population at time zero\nAdd offspring (same size) at time one\nSelect parents to offspring at random"
  },
  {
    "objectID": "slides/foundations/index.html#wright-fisher-model-10",
    "href": "slides/foundations/index.html#wright-fisher-model-10",
    "title": "Population genetics",
    "section": "Wright-Fisher model",
    "text": "Wright-Fisher model\n\nFigure 2: Wright-Fisher model\nSee https://mikeyharper.uk/animated-plots-with-r/"
  },
  {
    "objectID": "slides/foundations/index.html#wright-fisher-model-11",
    "href": "slides/foundations/index.html#wright-fisher-model-11",
    "title": "Population genetics",
    "section": "Wright-Fisher model",
    "text": "Wright-Fisher model\n\n\n\n\n\n\nFigure 3: WF model indicating time direction from past (top) to present (bottom).\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: WF model tracing the genealogies of three extant chromosomes"
  },
  {
    "objectID": "slides/foundations/index.html#the-wright-fisher-sampling-model",
    "href": "slides/foundations/index.html#the-wright-fisher-sampling-model",
    "title": "Population genetics",
    "section": "The Wright-Fisher sampling model",
    "text": "The Wright-Fisher sampling model\nLet’s formalise the sampling process of the Wright-Fisher model1. We assume\n\na single locus in a haploid population of size \\(2N\\) (or diploid of size \\(N\\) when random mating)\nno mutation and selection\ndiscrete generations\n\nEach generation we sample \\(2N\\) new chromosomes from the previous generation. The probability of choosing a chromosome \\(v\\) is \\(1/2N\\) (coin flip with probability of success \\(1/2N\\)). Since the trials are independent, and we perform \\(2N\\) trials, the number of offspring \\(k\\) of a given chromosome \\(v\\) is binomially distributed \\(\\mathrm{Bin}(m, p)\\), with parameters \\(m=2N\\) and probability of success \\(p=\\frac{1}{2N}\\).\n\nWe assume some familiarity with Binomial sampling. For reference, some mathematical formality follows.\nLet \\(p\\) be the probability of heads (=1) of a coin flip, and \\(q=1-p\\) the probability of tails (=0). A coin flip can be modelled by a random variable (r.v.) \\(X\\) that follows a Bernoulli distribution, where \\(\\mathrm{Pr(}X=1\\mathrm{)}=p\\), \\(\\mathrm{Pr(}X=0\\mathrm{)}=1-p=q\\). One can show (e.g., with transforms such as the probability-generating function) that a binomially distributed variable \\(Y\\sim Bin(n, p)\\) is the sum of \\(n\\) independent Bernoulli variables \\(X\\) (“Bernoulli trials”), or \\(Y=\\sum^nX\\). In our case, there are \\(2N\\) trials, each with \\(p=1/2N\\).\n\\[\nP(v=k) = {2N\\choose k}\\left( \\frac{1}{2N} \\right)^k\n\\left(1 - \\frac{1}{2N} \\right)^{(2N - k)}\n\\]\n\nFor a more extensive treatment, see Hermisson (2017) or Hein et al. (2005)"
  },
  {
    "objectID": "slides/foundations/index.html#properties-of-wright-fisher-sampling",
    "href": "slides/foundations/index.html#properties-of-wright-fisher-sampling",
    "title": "Population genetics",
    "section": "Properties of Wright-Fisher sampling",
    "text": "Properties of Wright-Fisher sampling\n\n\n\n\nThe expected number of offspring is one\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson approximation for large \\(N\\)\n\n\n\n\n\n\n\n\n\n\\[\nP(v=k) \\approx \\frac{1}{k!}e^{-k}\n\\]\n\n\n\n\nProb(pick same parent) = 1/2N\n\n\n\n\n\n\n\n\n\n\n\n\nTime for two sequences to coalesce \\(\\sim 1/2N\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMany of the results above follow from standard results in probability theory and are provided here in brevity for reference to the interested reader. The details are not necessary to understand in detail.\nExpected number of offspring\nThe expected value of a \\(\\mathrm{Bin}(m,p)\\) (binomially distributed) variable with parameters \\(m=2N\\) and \\(p=\\frac{1}{2N}\\) is \\(mp\\), hence:\n\\[\nE(v) = mp = 2N\\frac{1}{2N} = 1\n\\]\nPoisson approximation\nWhen \\(2N\\) large it holds that the probability that sequence \\(v\\) has \\(k\\) offspring is\n\\[\nP(v=k) \\approx \\frac{1}{k!}e^{-k}\n\\]\nSince \\(P(v=0) = e^{-1} \\approx 0.37\\), a fraction 0.37 of sequences lack descendants\nProbability that two sequences pick same parent\nLet \\(u\\) and \\(v\\) be two sequences. Pick a parent \\(p_u\\) of \\(u\\). Then the probability that \\(v\\) picks the same parent is (solid lines)\n\\[\nP(p_u=p_v) = \\frac{1}{2N}\n\\]\nThe probability that they pick different parents is\n\\[\nP(p_u \\neq p_v) = 1 - \\frac{1}{2N}\n\\]\nTime for two sequences to coalescent\nTime for two sequences \\(u\\) and \\(v\\) to find common ancestor distributed as \\((1 - \\frac{1}{2N})^{j-1}\\frac{1}{2N}\\) (\\(j-1\\) failures followed by success). This is the geometric distribution \\(Ge(p)\\), with parameter \\(p=\\frac{1}{2N}\\), and expected value \\(\\frac{1}{p}={2N}\\). That is, the expected number of generations for two sequences to find a common ancestor (i.e., coalesce) is \\(2N\\) generations.\nSince a large fraction of genes lack descendants, very quickly (compared to 2N) a population will descend from a small proportion of genes.\nDerivation of average time to having same parent (i.e., coalescence) requires knowledge of geometric distribution. The probability that the genes find common parent \\(j\\) generations ago is\n\\[\n(1-\\frac{1}{2N})^{(j-1)}\\frac{1}{2N}\n\\]\ndue to independence between generations. This is the geometric distribution \\(Ge(p)\\) with \\(p=1/2N\\), which has expected value \\(1/p\\), i.e., 2N in this case."
  },
  {
    "objectID": "slides/foundations/index.html#wright-fisher-model-with-alleles",
    "href": "slides/foundations/index.html#wright-fisher-model-with-alleles",
    "title": "Population genetics",
    "section": "Wright-Fisher model with alleles",
    "text": "Wright-Fisher model with alleles\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlleles can randomly fix or be lost through process called genetic drift\nWright-Fisher model showing the evolution of population of 10 genes over 16 generations. Allele variants are shown in white and black. Starting frequency black variant is 0.3.\n\n\n(To avoid confusion: previously black was used to indicate parent, here black/white will refer to different alleles)\nEnter allelic variants; we are looking at two alleles\nImportant: the fate of any allele under drift is to be lost or fixed, which ultimately means variation is lost (decays) with drift"
  },
  {
    "objectID": "slides/foundations/index.html#binomial-process-models-allele-sampling",
    "href": "slides/foundations/index.html#binomial-process-models-allele-sampling",
    "title": "Population genetics",
    "section": "Binomial process models allele sampling",
    "text": "Binomial process models allele sampling\n\n\n\n\n\n\n\n\n\n\n\nWe assume two alleles \\(A\\), \\(a\\), each with \\(i\\) and \\(j=2N-i\\) copies in generation \\(t\\).\n\n\n\n     \n\n\n\\(i=8\\), \\(j=2\\cdot 6-8=4\\)\n\n\n\n\n\n\nLet \\(p_t=i/2N\\) be the frequency of \\(A\\) in generation \\(t\\), and \\(q_t=1-p_t\\) the frequency of \\(a\\).\n\n\n\n     \n\\(p_t = 8/12\\)\n\n\n     \n\\(p_{t+1} = 4/12\\)\n\n\n\n\n\nProb(\\(k\\) \\(A\\) alleles in next generation) is \\(\\mathsf{Bin}(2N, \\frac{i}{2N})\\)\n\n\nA more formal mathematical description goes as follows:\nThe sampling model for next generation \\(t+1\\), given \\(i\\) \\(A\\) alleles in generation \\(t\\), is\n\\[\np_{t+1} = P(v_A=k) = {2N\\choose k}\\left( \\frac{i}{2N} \\right)^k\n\\left(1 - \\frac{i}{2N} \\right)^{(2N - k)} = \\mathsf{Bin}(2N, \\frac{i}{2N})\n\\]\nNB: we here slightly change notation, with \\(p_{t+1} = P(X=k)\\). Also, we have omitted an index \\(i\\) in the expressions of \\(p\\). The probability of observing \\(k\\) \\(A\\) alleles in generation \\(t+1\\) will of course depend on the number \\(i\\) \\(A\\) alleles in the previous generation."
  },
  {
    "objectID": "slides/foundations/index.html#genetic-drift",
    "href": "slides/foundations/index.html#genetic-drift",
    "title": "Population genetics",
    "section": "Genetic drift",
    "text": "Genetic drift\n\n\nTo capture dynamics, follow allele frequency trajectory (\\(p_t\\)) as function of time.\n\n\n##' Wright Fisher model - follow allele frequency distribution\n##'\n##' @param p0 Starting frequency\n##' @param n Population size\n##' @param generations Number of generations to simulate\n##'\nwright_fisher &lt;- function(p0, n, generations) {\n    x &lt;- vector(mode = \"numeric\", length = generations)\n    x[1] &lt;- p0\n    for (i in seq(2, length(x))) {\n        x[i] &lt;- rbinom(1, size = n, prob = x[i - 1])/n\n    }\n    x\n}\n\n\n# Example simulation and plot\nset.seed(1223)\ngenerations &lt;- 100\nn &lt;- 100  # NB: haploid population size!\nplot(1:generations, wright_fisher(0.5, n, generations), type = \"l\", ylab = \"frequency\",\n    xlab = \"generation\", ylim = c(0, 1))\n\n\n\n\n\n\n\n\nFigure 5: Genetic drift for different haploid(!) population sizes, starting frequency \\(p_0\\)=0.5. Note dependency of variance on population size N.\n\n\n\n\n\n\n\n\n\nMention neutral here as this is how alleles behave under drift: like gas particle diffusing up and down. Allele is eventually either fixed or lost."
  },
  {
    "objectID": "slides/foundations/index.html#genetic-drift-1",
    "href": "slides/foundations/index.html#genetic-drift-1",
    "title": "Population genetics",
    "section": "Genetic drift",
    "text": "Genetic drift\n\n\n\n\n\n\n\nFigure 6: Genetic drift for different combinations of starting frequency and population size for n=50 repetitions per parameter combination. Note how variation and time to fixation depends on population size and starting frequency.\n\n\n\n\n\n\n\n\n\nfate of allele: fixation or loss \\(\\rightarrow\\) eventually loss of variation\nprobability of fixation \\(\\pi(p)=p\\), where \\(p\\) is the current frequency\nrate of drift (loss of variation) \\(\\propto \\frac{1}{2N}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimplifying assumptions -&gt; rate of drift \\(\\propto \\frac{1}{N}\\) (\\(\\frac{1}{2N}\\) in our treatment) (Leffler et al., 2012)\nIn reality population fluctuates and therefore Ne is substituted for N. Larger Ne -&gt; smaller fluctuation in allele frequency (as evidenced in plots) -&gt; maintain larger genetic diversity\nDrift can be thought of as a force acting on a buoyant gas particle floating up and down at random."
  },
  {
    "objectID": "slides/foundations/index.html#allele-frequency-distribution-for-n1",
    "href": "slides/foundations/index.html#allele-frequency-distribution-for-n1",
    "title": "Population genetics",
    "section": "Allele frequency distribution for N=1",
    "text": "Allele frequency distribution for N=1\nInstead of looking at frequencies let’s switch to distributions of alleles for one individual, one locus. Then there are three possible genotypes (states) \\(aa\\), \\(aA\\), and \\(AA\\). Let \\(n=0,1,2\\) be an integer corresponding to each genotype (i.e., it counts the number of \\(A\\) alleles).\nAssume individual mates with itself at random(!) starting in either of the three states. How does distribution evolve?\n\n\nt=0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nt=1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nt=2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample from (Gillespie, 2004, p. 24). We look at a single hermaphroditic individual that mates with itself at random. For each generation, given a genotype distribution, we calculate the outcome for the next generation. For instance, starting out in state 0 (only \\(aa\\) genotypes, hence only \\(a\\) alleles), we can only produce new \\(aa\\) genotypes and will therefore never leave state 0. The same holds for state 2. These states are absorbing states.\nStarting from state 1 (\\(aA\\)) we can get \\(aa\\) genotype with 25% probability, since the probability of picking one \\(a\\) is 50%, and we perform two draws. Similarly, we get \\(AA\\) with 25% probability, leaving 50% to \\(aA\\).\nIn the next generation, the \\(aA\\) genotype frequency is 0.5, to be split in fractions 0.25, 0.5, 0.25 as before, and so on.\nTo study the system we therefore need to enumerate the probabilistic outcomes from each state (\\(aa\\) -&gt; 1, 0, 0, \\(aA\\) -&gt; 0.25, 0.5, 0.25, \\(AA\\) &lt;- 0, 0, 1). To get the state in next generation, we multiply the current distribution with these outcomes. The next slide gives Kimura’s example for the case where we have N=10 chromosomes."
  },
  {
    "objectID": "slides/foundations/index.html#probability-distributions-of-allele-frequencies",
    "href": "slides/foundations/index.html#probability-distributions-of-allele-frequencies",
    "title": "Population genetics",
    "section": "Probability distributions of allele frequencies",
    "text": "Probability distributions of allele frequencies\n\n\n\n\n\n\nFigure 7: Histogram showing the course of change of the allele frequency distribution with time (Kimura, 1983, fig. 3.4). When N large (\\(\\gtrsim 100\\)) histogram can be approximated by continuous distribution (diffusion theory). Try recipe  for different values of N.\n\n\n\n\n\n\n\n\n\n\nFigure 8: Frequency distributions of the brown eye (\\(bw^{75}\\)) allele in replicate experimental populations (\\(n\\sim 100\\)) of Drosophila melanogaster (8 , 8 ) (Buri, 1956)\n\n\n\n\n\n\n\n\nMathematical treatment of drift can become complicated: easier to study dynamics of heterozygosity\n\n\nKimura’s plot illustrates the allelic frequency distribution of replicate populations each consisting of N=10 sequences. There are two allelic types. The x axis corresponds to the proportion of populations in a given state (e.g., the y value for x=3/10 corresponds to the proportion of populations with 3 alleles of one type and 7 of the other). At \\(t=0\\) all populations are in state 5/10.\nKimura’s plot is very instructive and students are encouraged to test the recipe code, increasing the number of states incrementally. For large enough N, the histograms can be approximated by continuous distributions. This observation led Kimura (even though diffusion equations were originally introduced to genetics by Fisher in 1922) to apply diffusion theory to obtain probability densities of allele frequencies, leading in turn to compact expressions of fixation probabilities, expected ages of alleles, and more. A treatment of diffusion theory is outside the scope of this course; the interested reader can consult e.g., (Ewens, 2004).\nThe Buri experiment is an empirical demonstration of Kimura’s plot.\nOn the sampling model, (Charlesworth & Charlesworth, 2010, p. 231) says:\n\nIt is, however, impossible to write down a simple algebraic expression for P, even without selection and mutation. [The equation] is useful for obtaining numerical results for relatively small populations, but becomes computationally demanding when N becomes very large."
  },
  {
    "objectID": "slides/foundations/index.html#heterozygosity-dynamics",
    "href": "slides/foundations/index.html#heterozygosity-dynamics",
    "title": "Population genetics",
    "section": "Heterozygosity dynamics",
    "text": "Heterozygosity dynamics\n\n\n\n\n\n\nFigure 9: Illustration of identity by descent (IBD) and state (IBS). Alleles in generation \\(n\\) are IBD but not IBS.\n\n\n\n\n\n\nLet \\(\\mathcal{H}_t\\) be the probability that two alleles are different by state. One can show that the time course evolution of \\(\\mathcal{H}_t\\) in a randomly mating population consisting of \\(N\\) diploid hermaphroditic individuals is\n\\[\n\\mathcal{H}_t = \\mathcal{H}_0 \\left( 1 - \\frac{1}{2N} \\right)^t\n\\]\nImportant consequence: heterozygosity in WF population lost at rate \\(1/2N\\).\n\n\n\nAlleles in generation \\(n\\) are IDB but not IBS\nMotivation: mathematical description of genetic drift complicated for populations with more than one individual. Easier to study the evolution of heterozygosity.\nEquation presented without details. Derivation in (Gillespie, 2004, pp. 25–27) starts from G=probability that two alleles are IBS"
  },
  {
    "objectID": "slides/foundations/index.html#heterozygosity-dynamics-1",
    "href": "slides/foundations/index.html#heterozygosity-dynamics-1",
    "title": "Population genetics",
    "section": "Heterozygosity dynamics",
    "text": "Heterozygosity dynamics\n\n\n\n\n\n\nFigure 10: Plot of \\(\\mathcal{H}_t\\) illustrating dependency on population size\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 11: Heterozygosity in black-footed ferret (Wisely et al., 2002). Example from Graham Coop (2020), Fig. 4.5\n\n\n\n\n\n\n\nExample of how rapid decline in population size can affect heterozygosity.\n\nPopulation size influences genetic diversity!\n\n\nHowever, census population size not (always) the correct measure.\n\n\n\n\n\n\n\nDependency on population size: for large enough populations the decline will be very slow (drift speed ~ 1/2N)\nPractical example shows loss of heterozygosity tell-tale signature of population decline; conversely, not easy to show population decline in large populations (e.g., marine species with large \\(N_e\\)) using heterozygosity as measure\n(Barton et al., 2007, p. 369) “The relation between genetic diversity and population size is difficult to discern, in part, because it is extremely hard to estimate the numbers of most species and because the number that matters is an average back into the distant past”(!)\nFrom (Graham Coop, 2020, p. 64)\n\nTo see how a decline in population size can affect levels of het- erozygosity, let’s consider the case of black-footed ferrets (Mustela nigripes). The black-footed ferret population has declined dramatically through the twentieth century due to destruction of their habitat and sylvatic plague. In 1979, when the last known black-footed ferret died in captivity, they were thought to be extinct. In 1981, a very small wild population was rediscovered (40 individuals), but in 1985 this population suffered a number of disease outbreaks. At that point of the 18 remaining wild individuals were brought into captivity, 7 of which reproduced. Thanks to intense captive breeding efforts and conservation work, a wild population of over 300 individuals has been established since. However, because all of these individuals are descended from those 7 individuals who survived the bottleneck, diversity levels remain low. Wisely et al. measured heterozygosity at a number of microsatellites in individuals from museum collections, showing the sharp drop in diversity as population sizes crashed (see Figure 4.5).\n\nSegue: population size important; however, census population size is not always the measure we want when relating to genetic diversity"
  },
  {
    "objectID": "slides/foundations/index.html#effective-population-size",
    "href": "slides/foundations/index.html#effective-population-size",
    "title": "Population genetics",
    "section": "Effective population size",
    "text": "Effective population size\nAssumptions underlying Wright-Fisher model seldom fulfilled for natural populations. In particular\n\nnon-random mating (population structure)\nfluctuations of population census size\n\nTherefore, magnitude of drift experienced by a population different from that predicted by population size\nTechnically correct definition (but see Waples (2022)):\n\n\\(N_e\\) is the size of an ideal population that would experience the same rate of genetic drift as the population in question.\n\n\nideal population: discrete generations with random mating, no evolutionary forces besides drift, no selective advantages"
  },
  {
    "objectID": "slides/foundations/index.html#mutation",
    "href": "slides/foundations/index.html#mutation",
    "title": "Population genetics",
    "section": "Mutation",
    "text": "Mutation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTwo-allele\n\nDerive popgen stats\n\nFinite sites\n\nRecurrent mutations\n\nInfinite alleles\n\nProtein electrophoresis\n\nInifinite sites\n\nDNA sequences\n\n\n\n\n\n\nMutations are generated randomly as changes in DNA. In WF model will be highlighted in black. We assume mutations are described by a Poisson process with rate \\(\\mu\\) (per generation).\nThe mutation models are:\n\ntwo-allele model: used to derive popgen statistics\nfinite sites model: recurrent mutations may occur, an assumption that is often omitted to facilitate calculations (e.g., coalescent)\ninifinite alleles model: every mutation leads to new allele (e.g., protein electrophoresis)\ninfinite sites model: model commonly used for long DNA sequences\n\nAdditional model not presented here is the stepwise mutation model (mainly used to model repeats):"
  },
  {
    "objectID": "slides/foundations/index.html#mutation-and-drift",
    "href": "slides/foundations/index.html#mutation-and-drift",
    "title": "Population genetics",
    "section": "Mutation and drift",
    "text": "Mutation and drift\n\n\nGenetic drift “moves” frequencies to the point that variation is lost via allele fixation or loss. New variation is introduced through mutation. We typically assume mutations are described by a Poisson process with rate \\(\\mu\\) (per generation).\n\nThe mutation rate is denoted \\(\\mu\\), and the population scaled mutation rate is \\(2N_e\\mu\\) for haploid populations, \\(4N_e\\mu\\) for diploid, where \\(N_e\\) is the effective population size.\n\n\nThe mutation - drift balance is when the diversity lost due to drift equals the diversity gained due to mutation.\n\n\n\n\n\n\n\nFigure 12: Variation is introduced by mutations (black) at rate \\(\\mu=1e^{-4}\\) and is occasionally lost through genetic drift.\n\n\n\n\n\n\n\n\n\nSegue: so if drift removes variation, what introduces it? Mutation!\nNote that the mutation rate in the WF model is not meaningful; the value is simply chosen such that enough mutations show up in plot."
  },
  {
    "objectID": "slides/foundations/index.html#tracing-the-evolution-of-mutations",
    "href": "slides/foundations/index.html#tracing-the-evolution-of-mutations",
    "title": "Population genetics",
    "section": "Tracing the evolution of mutations",
    "text": "Tracing the evolution of mutations\n\n\n\n\n\n\nFigure 13: Different mutations suffer different fates. Most mutations are lost in a couple of generations. Mutant alleles are colored black and their genealogies are highlighted with thicker edges.\n\n\n\n\n\n\n\nObservation: most mutations are in fact lost\n\n\nRecall: fixation probability \\(\\pi(p)=p\\)\n\n\n\n\nDifference to previous figure: here we highlight the genealogies"
  },
  {
    "objectID": "slides/foundations/index.html#mutation-drift-balance",
    "href": "slides/foundations/index.html#mutation-drift-balance",
    "title": "Population genetics",
    "section": "Mutation drift balance",
    "text": "Mutation drift balance\nDrift removes variation. Mutation reintroduces it. At equilibrium the change in variation by definition is 0. In terms of \\(\\mathcal{H}_t\\) (the probability that two alleles are not identical by state), \\(\\Delta\\mathcal{H}=0\\).\nOne can show1 the classical formula that the equilibrium heterozygosity value is\n\\[\n\\hat{\\mathcal{H}} = \\frac{4N_e\\mu}{1 + 4N_e\\mu}\n\\]\n\n\\(\\mu\\) is often assumed known, and heterozygosity is easily calculated from data, which provides a way of estimating \\(N_e\\).\n\n\nThe compound parameter \\(4N_e\\mu\\) is called the population scaled mutation rate and is commonly named \\(\\theta\\) such that\n\\[\n\\hat{\\mathcal{H}} = \\frac{\\theta}{1 + \\theta}\n\\]\n\n\nGillespie (2004), pp. 30–31 uses a difference equation approach to derive \\(\\mathcal{H}\\). Briefly, he studies the time evolution of \\(\\mathcal{G}\\), the probability that two alleles drawn at random without replacement from the population are identical by state. Mutations are assumed unique, i.e., the infinite-alleles model. It holds\n\\[\n\\mathcal{G}^\\prime = (1-\\mu)^2\\left[ \\frac{1}{2N} +\n\\left( 1 - \\frac{1}{2N} \\right) \\mathcal{G} \\right]\n\\]\nwhere \\((1-\\mu)^2\\) is the probability that no mutation occur in either of the two sampled alleles. Since \\(\\mu\\) is small, \\((1-\\mu)^2 \\approx 1-2\\mu\\), which after some manipulation gives the desired expression for \\(\\mathcal{H} = 1 - \\mathcal{G}\\).\nOn pages 46–47, he shows that the expression for can be derived in a much simpler fashion using coalescent theory. Tracing two lineages backwards in time, the probability of coalescence is 1/2N, whereas the probability of a mutation is \\(1-(1-\\mu)^2\\approx 2\\mu\\); \\(\\mathcal{H}\\) is then simply the relative probability of the two events\n\\[\n\\mathcal{H} = \\frac{2\\mu}{2\\mu + 1/2N} = \\frac{4N\\mu}{4N\\mu + 1}\n\\]\n\nsee (Gillespie, 2004, p. 29 – 31) for a concise treatement"
  },
  {
    "objectID": "slides/foundations/index.html#the-neutral-theory-of-evolution",
    "href": "slides/foundations/index.html#the-neutral-theory-of-evolution",
    "title": "Population genetics",
    "section": "The neutral theory of evolution",
    "text": "The neutral theory of evolution\n\n\nMutation drift balance, together with the observation during 50’s-60’s that polymorphism was more common than expected, is the foundation of the neutral theory of evolution (Kimura, 1983): allele frequencies may change and fix due to chance alone and not selection; most mutations behave as if they are neutral.\n\nNearly neutral theory (Ohta, 1973) was later developed to explain failure to predict scaling of polymorphism with population size: most mutations are not neutral but slightly deleterious and purged from population by natural selection.\n\n\n\n\n\n\nFigure 14: Heterozygosity H= predicted by the neutral theory. Shaded region shows typical heterozygosities in animals (y-axis). The observed \\(N_e\\mu\\) range is higher than predicted from plot. From Hurst (2009), Fig 1.\n\n\n\n\n\n\n\n\nRelated to rate of substitution and molecular evolution is the work of Kimura that lead to the development of the neutral theory.\nMotivation: if polymorphic sites deleterious, should not expect much polymorphism.\nLow levels of polymorphism expected assuming little balancing selection (Hurst, 2009, p. 87); however electrophoretic studies showed polymorphism common. Would lead to detrimental load (Kimura & Ohta, 1971) -&gt; therefore majority of polymorphism must evolve neutrally (dynamics). Also: rate of evolution (on protein level) too high (Haldane’s dilemma)\nOn the shaded region: the observed range of \\(N_e\\mu\\) is larger than that which is predicted by the plot, and since \\(\\mu\\) is constrained within a couple of orders of magnitude, \\(N_e\\) must vary more than predicted by the (strictly) neutral theory.\nConversely: given a constrained \\(\\mu\\), we observe a range of \\(N_e\\mu\\) that predicts a heterozygosity range H, which is much larger than that which we observe. In other words, the heterozygosity range is much lower than predicted by the neutral, given the observed \\(N_e\\mu\\) range, so some other process must reduce variation somehow.\nThe general idea of nearly neutral theory is that most mutations are slightly deleterious and therefore purged by natural selection, thereby reducing observed variation. The efficacy of purging depends in turn on the effective population size, such that species with small \\(N_e\\) will have a harder time getting rid of potentially damaging variants."
  },
  {
    "objectID": "slides/foundations/index.html#mutation-rate-can-be-estimated-from-substitution-rate",
    "href": "slides/foundations/index.html#mutation-rate-can-be-estimated-from-substitution-rate",
    "title": "Population genetics",
    "section": "Mutation rate can be estimated from substitution rate",
    "text": "Mutation rate can be estimated from substitution rate\nMutation enters populations and may be fixed by drift. Therefore, with time there will be fixed differences, or substitions (typically in the evolution of species) between populations, or species. In molecular evolution, the substition rate, \\(\\rho\\), is the most interesting quantity.\n\nThe total number of new mutations in every generation is \\(2N\\mu\\) (total number of gametes times mutation rate)\n\n\nNew mutations fix at a rate \\(1/2N\\)\n\n\nTherefore, the average rate of substitution, \\(\\rho\\), is \\(2N\\mu\\times1/2N\\), or\n\\[\n\\rho=\\mu\n\\]\nwhich is independent of population size!\n\n\nPractical implication: we can estimate mutation rate from the substitution rate at neutrally evolving sites (e.g., Kumar & Subramanian (2002))\n\n\nWhat happens when sufficient amount of time passes? Mutations fix and generate substitutions between species. This slide presents Kimura’s remarkable result regarding mutation rate and substitution rate!\nOn \\(2N\\mu\\): the larger the population, the larger the number of mutations that can fix\nIf \\(4N\\mu&gt;&gt;0\\) no new mutations can fix. Issue here is there is no explicit mention of DNA sequence -&gt; introduction of infinite sites model\nFor practical note on estimation of mutation rate see e.g., (Hubisz & Siepel, 2020, p. 247)\n(Kumar & Subramanian, 2002, first paragraph):\n\nRates of point mutation can be determined indirectly by estimating the rate at which the neutral substitutions accumulate in protein-coding genes"
  },
  {
    "objectID": "slides/foundations/index.html#selection-and-fitness",
    "href": "slides/foundations/index.html#selection-and-fitness",
    "title": "Population genetics",
    "section": "Selection and fitness",
    "text": "Selection and fitness\n\nFigure 15: The life cycle used in the fundamental model of selection (Gillespie, 2004, fig. 3.2)\n\nMuch confusion exists in the literature regarding how various types of selection are defined, in particular because some of the terminology is used slightly differently within different scientific communities (Nielsen, 2005)\n\n\n\n\n\\[\n\\begin{matrix}\n\\mathrm{Genotype} & AA & Aa & aa \\\\\n\\mathrm{Frequency\\ in\\ newborns} & p^2 & 2pq & q^2\\\\\n\\mathrm{Viability} & w_{AA} & w_{Aa} & w_{aa}\\\\\n\\mathrm{Frequency\\ after\\ selection} & p^2w_{AA} / \\bar{w} &\n    2pqw_{Aa} / \\bar{w} & q^2w_{aa} / \\bar{w} \\\\\n\\mathrm{Relative\\ fitness} & 1 & 1-hs & 1-s\\\\\n\\end{matrix}\n\\]\nwhere \\(\\bar{w} = p^2w_{AA} + 2pqw_{Aa} + q^2w_{aa}\\) is the mean fitness.\n\n\n\n\n\\(h=0\\)\n\\(A\\) dominant, \\(a\\) recessive\n\n\n\\(h=1\\)\n\\(a\\) dominant, \\(A\\) recessive\n\n\n\\(0&lt;h&lt;1\\)\nincomplete dominance\n\n\n\\(h&lt;0\\)\noverdominance (heterozygote advantage)\n\n\n\\(h&gt;1\\)\nunderdominance\n\n\n\n\nNotation follows Gillespie (2004), pp. 61–64.\n\n\n\n\nThe life cycle figure starts with newborns carrying the \\(A\\) allele at frequency \\(p\\), like parents. To reproduce they must reach adulthood, but due to selection, the allele frequency of \\(A\\) may shift to \\(p^\\prime\\) because different genotypes affect survival probabilities. This is typically summarized in genotype viabilities.\nThe Nielsen quote is a reminder that many different notations and parametrizations exist in the literature."
  },
  {
    "objectID": "slides/foundations/index.html#the-most-important-equation-in-population-genetics",
    "href": "slides/foundations/index.html#the-most-important-equation-in-population-genetics",
    "title": "Population genetics",
    "section": "The most important equation in population genetics",
    "text": "The most important equation in population genetics\n\\[\np^\\prime - p = \\Delta_sp = \\frac{pq[p(w_{AA} - w_{Aa}) + q(w_{Aa} -\nw_{aa})]}{p^2w_{AA} + 2pqw_{Aa} + q^2w_{aa}}\n\\]\n\n\n\n\n\n\nFigure 16: Allele frequency change over time for directional, balancing, and disruptive selection, for different values of \\(p_0\\).\n\n\n\n\n\n\n\n\n\n\nFigure 17: Rate of allele frequency change as a function of allele frequency for directional, balancing, and disruptive selection.\n\n\n\n\n\n\n\n\nGiven the genotype fitnesses/viabilities, we can work out the difference in allele frequency \\(p-p^\\prime\\) between successive generations as a function of viabilities (or relative fitnesses). Equation relates allele frequency change to viabilities for different genotypes. It is instructive to study the equation and plot trajectories to gain an intuition for how allele frequencies evolve given the different selection regimes.\nThe left panel shows that the three modes of selection have different equilibrium points: for directional selection the favored homozygote will eventually attain 100%, balancing selection has a stable equilibrium point (attractor) for a given allelic ratio (here 25:75), and disruptive selection has an unstable equilibrium point (repeller) for a given allelic ratio.\nThe right panel shows the rate of change as a function of allele frequency. Note how the directionality changes at the equilibrium point for balancing and directional selection."
  },
  {
    "objectID": "slides/foundations/index.html#selection-and-drift---population-size-matters",
    "href": "slides/foundations/index.html#selection-and-drift---population-size-matters",
    "title": "Population genetics",
    "section": "Selection and drift - population size matters",
    "text": "Selection and drift - population size matters\n\n\n\n\n\n\nFigure 18: The fixation probability relative to the neutral probability of fixation (\\(p=1/2N\\)) under the assumption \\(s&lt;0.1\\). Red highlights region where \\(|N_es|&lt;0.05\\). Adapted from Lynch (2007), Fig. 4.2.\n\n\n\n\n\n\nIn red region (\\(|N_es|&lt;0.05\\)) the probability of fixation is within 10% of neutral fixation.\nConsequence: for any population size there exists range of selection coefficients where mutant alleles \\(\\approx\\) neutral (effective neutrality).\n\n\n\nSegue: note on the strength of s and the relation to \\(N_e\\). For small \\(N_e\\) the relation will hold for higher \\(s\\), meaning small populations will have difficulties purging deleterious mutations.\nEven if a new mutation has, say, \\(s=0.01\\), it still needs to overcome effects of drift. Only has 2% change of fixation.\nIn figure, we assume \\(s&lt;0.1\\), which is almost always the case (Lynch, 2007, p. 74).\n(Hahn, 2019, p. 133)"
  },
  {
    "objectID": "slides/foundations/index.html#direct-selection-can-be-inferred-from-protein-substitutions",
    "href": "slides/foundations/index.html#direct-selection-can-be-inferred-from-protein-substitutions",
    "title": "Population genetics",
    "section": "Direct selection can be inferred from protein substitutions",
    "text": "Direct selection can be inferred from protein substitutions\n\n\nFor genes, the ratio of nonsynonymous to synonymous substitutions can tell us about protein evolution:\n\n\nSynonymous substitution\n\nProtein          L\nDNA         --- CTT ---\n                  *\nDNA         --- CTC ---\nProtein          L\n\nNonsynonymous substitution\n\nProtein          L\nDNA         --- CTT ---\n                 *\nDNA         --- CHT ---\nProtein          H\n\n\n\n\n\\(\\mathbf{d_N/d_S &lt;&lt; 1}\\)\n\nnegative (purifying) selection\n\n\\(\\mathbf{d_N/d_S &lt; 1}\\)\n\nmajority nonsynonymous deleterious, some advantageous\n\n\\(\\mathbf{d_N/d_S = 1}\\)\n\nneutral or mix neutral / advantageous / deleterious mutations\n\n\\(\\mathbf{d_N/d_S &gt; 1}\\)\n\npositive selection\n\n\n\n\n\n\n\n\nFigure 19: \\(d_n/d_s\\) comparisons for human-rat orthologs. For most genes, \\(d_n/d_s &lt;&lt; 1\\) indicating purifying selection. A handful of genes (n=9) have \\(d_n/d_s &gt; 1.0\\) which could indicate positive selection. \n\n\n\n\n\n\n\n\n\nNot all mutations fall in genes. Methods for detecting direct selection not applicable to studying selection on single mutation, or e.g., balancing. This requires looking for specific patterns of diversity surrounding locus under selection.\n\n\n\nSegue: how do we detect selection?\nEarly approach: look at protein-coding sequence where nucleotide substitutions can change the amino acid (non-synonymous, and presumably non-neutral) or be silent (synonymous, assumed neutral).\nNot all mutations in genes. Also want to look at single advantageous mutations, or balanced polymorphisms. Must therefore look at tell-tale signs of linked neutral variants."
  },
  {
    "objectID": "slides/foundations/index.html#linked-selection-reduces-diversity-at-neighbour-loci",
    "href": "slides/foundations/index.html#linked-selection-reduces-diversity-at-neighbour-loci",
    "title": "Population genetics",
    "section": "Linked selection reduces diversity at neighbour loci",
    "text": "Linked selection reduces diversity at neighbour loci\n\n\n\n\nFigure 20: A selective sweep of an advantageous mutation (gray dot). Adapted from Charlesworth & Charlesworth (2010), Fig. 8.13\n\n\n\n\n\nExample of a selective sweep. If a sweep completes at a locus, it will become monomorphic, as will the neighbouring sites. Mutation could reintroduce variation. Recombination could increase diversity in neighbourhood, but in a manner that depends on the distance from the locus under selection.\n\nAlternatives to direct selection tests are those that look at linked selection. In essence, we look for characteristic patterns in the vicinity of a selected locus. A sweep leads to the selected site and neigbouring sites being monomorphic (and therefore invisible to tests based on direct selection). Without recombination, mutation could reintroduce variation. In the presence of recombination, the effect of reduced diversity will be dependent on distance from the locus under selection.\nNote here that every sequence can be treated as an allele, such that we in essence are looking multi- and not a bi-allelic locus."
  },
  {
    "objectID": "slides/foundations/index.html#recombination-breaks-association-between-loci",
    "href": "slides/foundations/index.html#recombination-breaks-association-between-loci",
    "title": "Population genetics",
    "section": "Recombination breaks association between loci",
    "text": "Recombination breaks association between loci\n\n\n\n\n\n\n\n\n\n\nMiller (2020), Fig. 5.12.3\n\nOnce per chromosome! But: rates vary between loci (hotspots), sex chromosomes vs autosomes, and in some species, recombination only occurs in one sex (e.g., D.melanogaster).\n\n\nMain effect: association between loci breaks up.\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe mechanism that breaks up association between loci is recombination. Cartoon to right shows the possible (haploid) outcomes of meiosis. \\(r\\) (the recombination rate) denotes the probability that there is a recombination event between the two loci.\nThe farther apart two loci on the same chromosome, the larger the probability that a recombination event occurs between them. Note that this can be applied to loci on different chromosomes as well; they segregate independently."
  },
  {
    "objectID": "slides/foundations/index.html#linkage-disequilibrium-and-its-decay",
    "href": "slides/foundations/index.html#linkage-disequilibrium-and-its-decay",
    "title": "Population genetics",
    "section": "Linkage disequilibrium and its decay",
    "text": "Linkage disequilibrium and its decay\n\n\nAssociation between loci can be written as:\n\\[\nD_{AB} = p_{AB} - p_Ap_B\n\\]\nSimilar expressions hold for other pairs; only need to know one \\(D_{ij}\\) (e.g., \\(D_{AB}\\)) so drop subscript and rewrite:\n\\[\np_{AB}= p_Ap_B + D\n\\]\nIf \\(D\\neq0\\) the loci are in linkage disequilibrium.\n\nCan show that decay over time is\n\\[\nD_t = (1-r)^tD_0\n\\]\nRecombination decreases D (linkage)\n\n\n\n\nLD between pairs of autosomal SNPs for human and mouse. From (Laurie et al., 2007, fig. 2)\n\n\n\n\n\n\nHandwavy introduction of LD as quantity. There are other equations, but the main point here is to point out that D measures the degree of linkage (disequilibrium); the higher D, the stronger linkage is.\nThe figure shows the difference in LD decay among wild populations compared to inbred mouse strains, where LD extends over several megabases. Therefore, LD decay informs about demographic history, and as we will see, evolutionary processes (sweeps -&gt; longer LD blocks)."
  },
  {
    "objectID": "slides/foundations/index.html#the-effect-of-a-selective-sweep-on-diversity",
    "href": "slides/foundations/index.html#the-effect-of-a-selective-sweep-on-diversity",
    "title": "Population genetics",
    "section": "The effect of a selective sweep on diversity",
    "text": "The effect of a selective sweep on diversity\n\n\n\nCode\npgip-slim --seed 42 -n 1000 -r 1e-6 -m 1e-7 --threads 12 recipes/slim/selective_sweep.slim -l 1000000 --outdir results/slim\npgip-tsstat results/slim/slim*.trees -n 10 --seed 31 -s pi -s S -s TajD -w 500 --threads 10 | gzip -v - &gt; results/slim/selective_sweep.w500.csv.gz\n\n\n\n\n\n\nFigure 21: The effect of a selective sweep on diversity. The arrow points to the site under selection. The y-axis shows Tajima’s D which is proportional to the difference between two measures of diversity, nucleotide diversity \\(\\pi\\) and Watterson’s \\(\\theta_W\\). \nSimulation: N=1e4, mu=5e-8, pi=4Nmu=0.004, seek S=a*pi=0.01, so a=S/pi which gives n. One needs to ramp up recombination rate to see the dip in TajD clearly."
  },
  {
    "objectID": "slides/foundations/index.html#the-effect-of-a-selective-sweep-on-diversity-1",
    "href": "slides/foundations/index.html#the-effect-of-a-selective-sweep-on-diversity-1",
    "title": "Population genetics",
    "section": "The effect of a selective sweep on diversity",
    "text": "The effect of a selective sweep on diversity\n\n\n\nCode\npgip-slim --seed 42 -n 1000 -r 1e-6 -m 1e-7 --threads 12 recipes/slim/selective_sweep.slim -l 1000000 --outdir results/slim\npgip-tsstat results/slim/slim*.trees -n 10 --seed 31 -s pi -s S -s TajD -w 500 --threads 10 | gzip -v - &gt; results/slim/selective_sweep.w500.csv.gz\n\n\n\n\nFigure 22: The effect of a selective sweep on diversity. The arrow points to the site under selection. The y-axis shows Tajima’s D which is proportional to the difference between two measures of diversity, nucleotide diversity \\(\\pi\\) and Watterson’s \\(\\theta_W\\). \nImportant: individual runs show a lot of stochasticity, but the signal is clear for the mean."
  },
  {
    "objectID": "slides/foundations/index.html#the-effect-of-a-selective-sweep-on-diversity-2",
    "href": "slides/foundations/index.html#the-effect-of-a-selective-sweep-on-diversity-2",
    "title": "Population genetics",
    "section": "The effect of a selective sweep on diversity",
    "text": "The effect of a selective sweep on diversity\n\nFigure 23: The effect of a selective sweep on diversity. The figure shows the mean of 1000 simulations with the selected locus indicated with an arrow.\ncf Nielsen (2005). Not clear how scaling of statistics to have mean=1 is done."
  },
  {
    "objectID": "slides/foundations/index.html#the-phases-of-a-selective-sweep",
    "href": "slides/foundations/index.html#the-phases-of-a-selective-sweep",
    "title": "Population genetics",
    "section": "The phases of a selective sweep",
    "text": "The phases of a selective sweep\n\n\n\n\n\n\nFigure 24: Time goes from left to right. As sweep progresses, tree topology changes. Adapted from Hahn (2019), Figure 8.1\n\n\n\n\n\n\nAmount of diversity depends on fixation time. A neutral locus fixes in \\(4N_e\\) generations; for \\(s=0.0001\\), it takes approximately \\(0.29N_e\\) generations.\nSelections changes the genealogy (different topology, shorter branches), an aspect used in many linkage-based tests for selection.\n\n\n\nA selective sweep changes the genealogy (shorter branches, different topology) compared to the neutral case, a fact that can be utilised in linkage-based tests for selection.\nNote that the amount of variation surrounding a sweep depends heavily on the rate of the sweep. (Hahn, 2019, p. 167) points out that an advantageous allele with \\(s=0.0001\\) will take approximately \\(0.29N_e\\) generations to fix (compared to \\(4N_e\\) generations for a neutral locus)"
  },
  {
    "objectID": "slides/foundations/index.html#linked-selection-may-constrain-levels-of-diversity",
    "href": "slides/foundations/index.html#linked-selection-may-constrain-levels-of-diversity",
    "title": "Population genetics",
    "section": "Linked selection may constrain levels of diversity",
    "text": "Linked selection may constrain levels of diversity\n\n\n\n\n\nFigure 25: Hitchhiking (left) versus background selection (right).\n\n\n\n\n\n\n\n\nHitchhiking\n\nalleles linked to locus under selection “hitchhike” to high frequencies (Smith & Haigh, 1974)\nevidence: positive correlation between putative neutral diversity and recombination (Corbett-Detig et al., 2015)\n\n\nBackground selection\n\nloci linked to a deleterious locus will be purged from population and thus reduce diversity (Charlesworth et al., 1993)\nsimilar patterns to hitchhiking\n\n\n\n\nLinked selection has been proposed as solution to the low range of diversity seen between species with orders of magnitude ranges in census population sizes."
  },
  {
    "objectID": "slides/foundations/index.html#summary",
    "href": "slides/foundations/index.html#summary",
    "title": "Population genetics",
    "section": "Summary",
    "text": "Summary\nWe have looked at the Wright-Fisher model as a model of populations and genealogies*\nGenetic drift moves allele frequencies up and down at random and removes variation at rate \\(\\propto 1/2N\\)\nMutation reintroduces variation. The Neutral theory posits most mutations are neutral and dynamics follow mutation drift equilibrium.\nMethods to detect selection are based on direct selection or studying patterns of variation caused by linked selection."
  },
  {
    "objectID": "slides/foundations/index.html#bibliography",
    "href": "slides/foundations/index.html#bibliography",
    "title": "Population genetics",
    "section": "Bibliography",
    "text": "Bibliography\n\n\nBarton, N. H., Briggs, D. E. G., Eisen, J. A., Goldstein, D. B., & Patel, N. H. (2007). Evolution. Cold Spring Harbor Laboratory Press.\n\n\nBuri, P. (1956). Gene Frequency in Small Populations of Mutant Drosophila. Evolution, 10(4), 367–402. https://doi.org/10.1111/j.1558-5646.1956.tb02864.x\n\n\nCasillas, S., & Barbadilla, A. (2017). Molecular Population Genetics. Genetics, 205(3), 1003–1035. https://doi.org/10.1534/genetics.116.196493\n\n\nCharlesworth, B., & Charlesworth, D. (2010). Elements of Evolutionary Genetics. Roberts and Company Publishers.\n\n\nCharlesworth, B., Morgan, M. T., & Charlesworth, D. (1993). The Effect of Deleterious Mutations on Neutral Molecular Variation. Genetics, 134(4), 1289–1303.\n\n\ncooplab. (2011). Population genetics course resources: Hardy-Weinberg Eq. In gcbias. https://gcbias.org/2011/10/13/population-genetics-course-resources-hardy-weinberg-eq/\n\n\nCorbett-Detig, R. B., Hartl, D. L., & Sackton, T. B. (2015). Natural Selection Constrains Neutral Diversity across A Wide Range of Species. PLOS Biology, 13(4), e1002112. https://doi.org/10.1371/journal.pbio.1002112\n\n\nEwens, W. J. (2004). Mathematical Population Genetics (S. S. Antman, J. E. Marsden, L. Sirovich, & S. Wiggins, Eds.; Vol. 27). Springer. https://doi.org/10.1007/978-0-387-21822-9\n\n\nGillespie, J. H. (2004). Population Genetics: A Concise Guide (2nd edition). Johns Hopkins University Press.\n\n\nGraham Coop. (2020). Notes on Population Genetics. https://github.com/cooplab/popgen-notes\n\n\nHahn, M. (2019). Molecular Population Genetics (First). Oxford University Press.\n\n\nHein, J., Schierup, M. H., & Wiuf, C. (2005). Gene genealogies, variation and evolution: A primer in coalescent theory. Oxford University Press. https://books.google.se/books?id=CCmLNAEACAAJ\n\n\nHein, J., Schierup, M., & Wiuf, C. (2004). Gene genealogies, variation and evolution. A primer in coalescent theory. In Systematic Biology - SYST BIOL (Vol. 54).\n\n\nHermisson, J. (2017). Mathematical population genetics. https://www.mabs.at/fileadmin/user_upload/p_mabs/Lecture_Notes_2017\n\n\nHubisz, M., & Siepel, A. (2020). Inference of Ancestral Recombination Graphs Using ARGweaver. In J. Y. Dutheil (Ed.), Statistical Population Genomics (pp. 231–266). Springer US. https://doi.org/10.1007/978-1-0716-0199-0_10\n\n\nHurst, L. D. (2009). Genetics and the understanding of selection. Nature Reviews Genetics, 10(2), 83–93. https://doi.org/10.1038/nrg2506\n\n\nKimura, M. (1983). The neutral theory of molecular evolution. Cambridge University Press. https://doi.org/10.1017/CBO9780511623486\n\n\nKimura, M., & Ohta, T. (1971). Protein Polymorphism as a Phase of Molecular Evolution. Nature, 229(5285), 467–469. https://doi.org/10.1038/229467a0\n\n\nKumar, S., & Subramanian, S. (2002). Mutation rates in mammalian genomes. Proceedings of the National Academy of Sciences, 99(2), 803–808. https://doi.org/10.1073/pnas.022629899\n\n\nLaurie, C. C., Nickerson, D. A., Anderson, A. D., Weir, B. S., Livingston, R. J., Dean, M. D., Smith, K. L., Schadt, E. E., & Nachman, M. W. (2007). Linkage Disequilibrium in Wild Mice. PLOS Genetics, 3(8), e144. https://doi.org/10.1371/journal.pgen.0030144\n\n\nLeffler, E. M., Bullaughey, K., Matute, D. R., Meyer, W. K., Ségurel, L., Venkat, A., Andolfatto, P., & Przeworski, M. (2012). Revisiting an Old Riddle: What Determines Genetic Diversity Levels within Species? PLOS Biology, 10(9), e1001388. https://doi.org/10.1371/journal.pbio.1001388\n\n\nLynch, M. (2007). The origins of genome architecture. Sinauer Associates.\n\n\nMiller, C. (2020). Human Biology. Thompson Rivers University.\n\n\nNei, M., & Kumar, S. (2000). Molecular Evolution and Phylogenetics. Oxford University Press.\n\n\nNielsen, R. (2005). Molecular Signatures of Natural Selection. Annual Review of Genetics, 39(1), 197–218. https://doi.org/10.1146/annurev.genet.39.073003.112420\n\n\nOhta, T. (1973). Slightly Deleterious Mutant Substitutions in Evolution. Nature, 246(5428), 96. https://doi.org/10.1038/246096a0\n\n\nSmith, J. M., & Haigh, J. (1974). The hitch-hiking effect of a favourable gene. Genetics Research, 23(1), 23–35. https://doi.org/10.1017/S0016672300014634\n\n\nWaples, R. S. (2022). What Is Ne, Anyway? Journal of Heredity, 113(4), 371–379. https://doi.org/10.1093/jhered/esac023\n\n\nWisely, S. M., Buskirk, S. W., Fleming, M. A., McDonald, D. B., & Ostrander, E. A. (2002). Genetic Diversity and Fitness in Black-Footed Ferrets Before and During a Bottleneck. Journal of Heredity, 93(4), 231–237. https://doi.org/10.1093/jhered/93.4.231\n\n\n\n\nPopulation genetics foundations"
  },
  {
    "objectID": "slides/introduction/index.html#who-are-we",
    "href": "slides/introduction/index.html#who-are-we",
    "title": "Population genomics in practice",
    "section": "Who are we?",
    "text": "Who are we?\n\n\n\nPer Unneberg\n\n\n\nNikolay Oskolkov\n\n\n\nJason Hill\n\n\n\nAndré Soares"
  },
  {
    "objectID": "slides/introduction/index.html#who-are-you",
    "href": "slides/introduction/index.html#who-are-you",
    "title": "Population genomics in practice",
    "section": "Who are you?",
    "text": "Who are you?"
  },
  {
    "objectID": "slides/introduction/index.html#who-are-you-1",
    "href": "slides/introduction/index.html#who-are-you-1",
    "title": "Population genomics in practice",
    "section": "Who are you?",
    "text": "Who are you?"
  },
  {
    "objectID": "slides/introduction/index.html#who-are-you-2",
    "href": "slides/introduction/index.html#who-are-you-2",
    "title": "Population genomics in practice",
    "section": "Who are you?",
    "text": "Who are you?"
  },
  {
    "objectID": "slides/introduction/index.html#who-are-you-3",
    "href": "slides/introduction/index.html#who-are-you-3",
    "title": "Population genomics in practice",
    "section": "Who are you?",
    "text": "Who are you?"
  },
  {
    "objectID": "slides/introduction/index.html#who-are-you-4",
    "href": "slides/introduction/index.html#who-are-you-4",
    "title": "Population genomics in practice",
    "section": "Who are you?",
    "text": "Who are you?"
  },
  {
    "objectID": "slides/introduction/index.html#who-are-you-5",
    "href": "slides/introduction/index.html#who-are-you-5",
    "title": "Population genomics in practice",
    "section": "Who are you?",
    "text": "Who are you?"
  },
  {
    "objectID": "slides/introduction/index.html#who-are-you-6",
    "href": "slides/introduction/index.html#who-are-you-6",
    "title": "Population genomics in practice",
    "section": "Who are you?",
    "text": "Who are you?"
  },
  {
    "objectID": "slides/introduction/index.html#information",
    "href": "slides/introduction/index.html#information",
    "title": "Population genomics in practice",
    "section": "Information",
    "text": "Information\nWhere are we?\n\nhttps://www.bmc.uu.se/scilifelab-navet-inglish/\n\nCourse dinner\n\nWednesday?"
  },
  {
    "objectID": "slides/introduction/index.html#course-website",
    "href": "slides/introduction/index.html#course-website",
    "title": "Population genomics in practice",
    "section": "Course website",
    "text": "Course website\n\nhttps://uppsala.instructure.com/courses/86976\n\n\nhttps://nbisweden.github.io/workshop-pgip/\n\n\n\nWelcome"
  },
  {
    "objectID": "exercises/selection/index.html",
    "href": "exercises/selection/index.html",
    "title": "Selection",
    "section": "",
    "text": "Compute environment setup\n\n\n\n\n\nIf you haven’t already done so, please read Compute environment for information on how to prepare your working directory.\n\n\n\n\n\n\n\n\n\nLearning objectives\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData setup\n\n\n\n\n\n\nUPPMAXLocal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTools\n\n\n\n\n\n\nListingUPPMAX modulesConda\n\n\n\nR\n\n\n\nExecute the following command to load modules:\n#| label: uppmax-load-modules\n#| echo: true\n#| eval: false\nmodule load uppmax bioinfo-tools \\\n    R_packages/4.3.1\n\n\nCopy the contents to a file environment.yml and install packages with mamba env update -f environment.yml.\nchannels:\n  - conda-forge\n  - bioconda\n  - default\ndependencies:\n  - r-base"
  },
  {
    "objectID": "exercises/demography/index.html",
    "href": "exercises/demography/index.html",
    "title": "Demographic inference",
    "section": "",
    "text": "Compute environment setup\n\n\n\n\n\nIf you haven’t already done so, please read Compute environment for information on how to prepare your working directory."
  },
  {
    "objectID": "exercises/demography/index.html#practical-information",
    "href": "exercises/demography/index.html#practical-information",
    "title": "Demographic inference",
    "section": "Practical information",
    "text": "Practical information\nThis exercise is divided into two parts. The first part will happen on Rackham. All the files you need are located here: /proj/naiss2023-22-1084/private/demography. The second part will happen inside R Studio locally.\nWe will be using ANGSD (https://github.com/ANGSD/angsd).\nWhat has been prepared for you:\n\nDataset. Data from 3 human populations (TSI, PEL and LWK).\nYou are also being provided with files with the extension *.filelist. These files contain a list with all the BAM files needed for this exercise.\n\nYou have two options now:\n\nCreate a bash script and submit to SLURM;\nStart an Interactive session on Rackham and run manually each step. I recommend this option for today.\n\nHow to start interactive mode on Rackham:\n\ninteractive -A {{&lt; var uppmaxproject &gt;}} -n 4 \\\n   --partition core --time 08:00:00 \\\n   --reservation={{&lt; var uppmaxproject &gt;}}_4```\n\nYou need to load all modules on Rackham so you don't have to worry about\ninstalling each program that we will need in this exercise.\n\n\nmodule load bioinfo-tools samtools PCAngsd ANGSD bcftools plink htslib"
  },
  {
    "objectID": "exercises/demography/index.html#first-steps",
    "href": "exercises/demography/index.html#first-steps",
    "title": "Demographic inference",
    "section": "First steps",
    "text": "First steps\nCalculate allele frequencies\nYou will need your file that has a list with all BAM files from all individuals from all populations (/proj/naiss2023-22-1084/private/demography/dataset/ALL.bamlist).\nJust run:\n\nangsd -b ALL.bamlist -GL 2 -doMajorMinor 1 -doMaf 2 -minMapQ 30 -minQ 20 -nThreads 4\n\n-b = your file with your BAM files list\n-GL 2 = This will calculate the genotype likelihood for you. \"2\" means it\n    will use the same method as GATK. If you use -GL 1 it will use the\n    same method as Samtools.\n-doMajorMinor 1 = Many methods assume that each site is diallelic, so\n    this option will use the genotype likelihood to infer the major and\n    minor alleles.\n-doMaf 2 = It will use the inferred major alleles, but it does not assume\n    known minor alleles.\n-minMapQ 30 = mapping quality filter\n-minQ 20 = base quality filter\n-nThreads 4 = will use 4 threads (cores) to perform all calculations.\nThe output will be angsdput.mafs.gz.\nTake a look inside the results file. This file is formatted such as:\nchromo  position        major   minor   unknownEM       nInd\n11      61005493        C       A       0.000006        1\n11      61005494        A       C       0.000006        1\n11      61005495        C       A       0.000006        1\n11      61005496        G       A       0.000006        1\n11      61005497        G       A       0.000006        1\n11      61005498        T       A       0.000006        1\n11      61005499        A       C       0.000006        1\n11      61005500        C       A       0.000006        1\n11      61005501        A       C       0.000006        1\nchromo = chromosome name\nposition = position…\nmajor = major allele\nminor = minor allele\nknownEM = frequency using -doMaf1\nunknownEM = frequency using -doMaf2\npK-EM = p-value for the frequency of the minor allele\nnInd = Number of individuals with data\nGenerate the genotype likelihood files\nYou will need your file that has a list with all BAM files from all individuals from all populations (/proj/naiss2023-22-1084/private/demography/dataset/ALL.bamlist).\nJust run:\n\nangsd -GL 2 -doGlf 2 -b ALL.bamlist -doMajorMinor 1 -SNP_pval 1e-6 -doMaf 1 -nThreads 4\n\n-doGlf 2 = will create the beagle likelihood file\n-SNP_pval = it will use 10^-6 as a p-value for the LRT to calculate which sites are polymorphic.\nThe output will be angsdput.mafs.gz and angsdput.beagle.gz\nYou already know what’s inside the mafs.gz file, but let’s take a look inside the Beagle format:\n\nmarker  allele1 allele2 Ind0    Ind0    Ind0    Ind1    Ind1    Ind1    Ind2    Ind2    Ind2    Ind3    Ind3    Ind3    Ind4    Ind4    Ind4    Ind5    Ind5    Ind5    Ind6    Ind6    Ind6    Ind7    Ind7    Ind7    Ind8    Ind8    Ind8    Ind9    Ind9    Ind9\n1_14000202      2       0       0.000532        0.999468        0.000000        0.333333        0.333333        0.333333        0.333333        0.333333        0.333333        0.666490        0.333333        0.000177        0.333333        0.333333        0.333333        0.002660        0.997340        0.000001        0.799744        0.200255        0.000000        0.000842        0.999157        0.000001        0.888820        0.111180        0.000000        0.799988        0.200012        0.000000\n1_14000873      2       0       0.000000        0.030324        0.969676        0.663107        0.333333        0.003560        0.888698        0.111302        0.000000        0.992114        0.007886        0.000000        0.999013        0.000987        0.000000        0.000009        0.991658        0.008334        0.888726        0.111274        0.000000        0.799696        0.200303        0.000001        0.000000        0.030330        0.969670        0.666490        0.333333        0.000177\n1_14001018      3       1       0.000000        0.015429        0.984571        0.799823        0.200177        0.000000        0.050636        0.949364        0.000000        0.941120        0.058880        0.000000        0.888842        0.111158        0.000000        0.799970        0.200030        0.000000        0.333333        0.333333        0.333333        0.992231        0.007769        0.000000        0.000140        0.333333        0.666526        0.666622        0.333333        0.000044\n\nYou will see that each individual has three columns in the file.\nmarker = chromosome and position (chr_position)\nallele1 = major allele as: 0=A, 1=C, 2=G, 3=T\nallele2 = minor allele as: 0=A, 1=C, 2=G, 3=T\nInd0 = 1st column is the genotype likelihood for major/major genotype\nInd0 = 2nd column is the genotype likelihood for major/minor genotype\nInd0 = 3rd column is the genotype likelihood for minor/minor genotype\nSFS estimation\nLet’s look into the Site Frequency Spectrum (SFS) for these populations. As you saw in the theoretical part earlier today, the SFS will show you the proportions of sites at different allele frequencies. And to calculate the unfolded SFS we will need an outgroup species to be used as the ancestral state. One important caveat to remember is that during out exercises we are using only a portion of one chromosome, but for real world data usage it is important to use the whole genome so you have enough information.\nWe usually run SFS per population, but let’s try running it for all individuals in our dataset first, just out of curiosity.\n\nYou will need your file that has a list with all BAM files from all individuals from all populations (naiss2023-22-1084/demography/dataset/ALL.bamlist). You will also need /proj/naiss2023-22-1084/private/demography/dataset/anc.fa.gz, which has the ancestral state for your individuals. Let’s calculate the unfolded SFS.\n\nFirst we need the allele frequencies.\nJust run:\n\nangsd -bam ALL.bamlist -anc anc.fa.gz -doSaf 1 -GL 2 -nThreads 4\n\n-doSaf 1 = it will calculate allele frequency likelihood based on\n    individual genotype likelihoods assuming Hardy-Weinberg.\nThe output will be angsdput.saf.idx, angsdput.saf.pos.gz, angsdput.saf.gz. If you want to know more about these files, read https://github.com/ANGSD/angsd/blob/newsaf/doc/formats.pdf.\nBut now that we have calculated allele frequencies, let’s calculate the genotype likelihood:\nJust run:\n\n\nangsd -bam ALL.bamlist -doSaf 1 -out output_gl -anc anc.fa.gz -GL 2 -P 4 -minMapQ 1 -minQ 20\n\n\n-doSaf 1 = it will calculate allele frequency likelihood based on\n    individual genotypoe likelihoods assuming Hardy-Weinberg.\n-out = choose a name for your output files\n-anc chimpHg19.fa.gz = we have to supply a file with the ancestral state\n    if we want to find unfolded SFS\n-P = just another way to use \"nThreads\"\nNow that all calculations have been done, let’s output the SFS based on them. Just run:\n\nrealSFS angsdput.saf.idx -maxIter 100 -P 4 &gt;results.sfs\n\nOne you have done it, repeat it with our populations: PEL, TSI and LWK. Do not forget to add the option -out name to name your output files so you can identify each population results."
  },
  {
    "objectID": "exercises/demography/index.html#switching-to-your-local-computer",
    "href": "exercises/demography/index.html#switching-to-your-local-computer",
    "title": "Demographic inference",
    "section": "Switching to your local computer",
    "text": "Switching to your local computer\nAlright, now you need to have this .Rmd file and all outputs in the same directory. You can copy to your machine. Or you can remote access it somewhere. It’s up to you. But if you followed the instructions at the top of the page you’ll have all you need already in your local machine."
  },
  {
    "objectID": "exercises/demography/index.html#plotting-sfs",
    "href": "exercises/demography/index.html#plotting-sfs",
    "title": "Demographic inference",
    "section": "Plotting SFS",
    "text": "Plotting SFS\nYou can run the code below in R to see how the SFS plots look like. Does it look like the plot we’ve seen during the theoretical session?\nLet’s look population by population.\nFirst, PEL:\n\n# function to normalize\nnorm &lt;- function(x) x/sum(x)\n# read data\nsfs &lt;- (scan(\"pel_results.sfs\"))\n# the variability as percentile\npvar &lt;- (1 - sfs[1] - sfs[length(sfs)]) * 100\n# the variable categories of the sfs\nsfs &lt;- norm(sfs[-c(1, length(sfs))])\nbarplot(sfs, xlab = \"Derived allele frequency\", names = 1:length(sfs), ylab = \"Proportions\",\n    main = \"SFS plot\", col = \"blue\")\n\nthen LWK:\n\n# function to normalize\nnorm &lt;- function(x) x/sum(x)\n# read data\nsfs &lt;- (scan(\"lwk_results.sfs\"))\n# the variability as percentile\npvar &lt;- (1 - sfs[1] - sfs[length(sfs)]) * 100\n# the variable categories of the sfs\nsfs &lt;- norm(sfs[-c(1, length(sfs))])\nbarplot(sfs, xlab = \"Derived allele frequency\", names = 1:length(sfs), ylab = \"Proportions\",\n    main = \"SFS plot\", col = \"blue\")\n\nAnd TSI:\n\n# function to normalize\nnorm &lt;- function(x) x/sum(x)\n# read data\nsfs &lt;- (scan(\"tsi_results.sfs\"))\n# the variability as percentile\npvar &lt;- (1 - sfs[1] - sfs[length(sfs)]) * 100\n# the variable categories of the sfs\nsfs &lt;- norm(sfs[-c(1, length(sfs))])\nbarplot(sfs, xlab = \"Derived allele frequency\", names = 1:length(sfs), ylab = \"Proportions\",\n    main = \"SFS plot\", col = \"blue\")\n\nThey are all a bit different, why do you think is that?\nLet’s see them all together:\n\n# function to normalize\nnnorm &lt;- function(x) x/sum(x)\n# expected number of sites with 1:20 derived alleles\nres &lt;- rbind(PEL = scan(\"pel_results.sfs\")[-1], LWK = scan(\"LWK_results.sfs\")[-1],\n    TSI = scan(\"TSI_results.sfs\")[-1])\ncolnames(res) &lt;- 1:20\n\n# density instead of expected counts\nres &lt;- t(apply(res, 1, nnorm))\n\n# plot the polymorphic sites.\nresPoly &lt;- t(apply(res[, -20], 1, nnorm))\nbarplot(resPoly, beside = T, legend = c(\"PEL\", \"LWK\", \"TSI\"), names = 1:19, main = \"Derived allele frequencies\")"
  },
  {
    "objectID": "exercises/demography/index.html#references",
    "href": "exercises/demography/index.html#references",
    "title": "Demographic inference",
    "section": "References",
    "text": "References\n\nYou can learn a lot by browsing the ANGSD website: http://www.popgen.dk/angsd/index.php/ANGSD\n\nAll data comes from the 1000 Genomes Project https://www.nature.com/articles/nature15393\n\nYou can check Matteo Fumagalli’s ngsTools Tutorial page for more exercises using the same dataset. It will show you how to do other things we didn’t have time to do today, like FST, PCAs, etc, using ANGSD/ngsTools: https://github.com/mfumagalli/ngsTools/blob/master/TUTORIAL.md\n\nThis exercise just scratched the surface of what you can do with this type of data. If you are interested in running more interesting analyses, I recommend that you take a look at dadi: https://dadi.readthedocs.io/en/latest/ They have a nice Jupyterlab notebook (like you have been using in the previous days) which will help you a lot.\nI also recommend Fastsimcoal2: http://cmpg.unibe.ch/software/fastsimcoal2/"
  },
  {
    "objectID": "exercises/demography/index.html#footnotes",
    "href": "exercises/demography/index.html#footnotes",
    "title": "Demographic inference",
    "section": "Footnotes",
    "text": "Footnotes\n\nThe password is provided by the course instructor↩︎"
  },
  {
    "objectID": "exercises/genetic_diversity/index.html",
    "href": "exercises/genetic_diversity/index.html",
    "title": "Genetic diversity landscapes",
    "section": "",
    "text": "Compute environment setup\n\n\n\n\n\nIf you haven’t already done so, please read Compute environment for information on how to prepare your working directory.\nIn this exercise we will look at measures that describe variation and compile statistics along a sequence. By scanning variation in windows along the sequence (a.k.a. genomic scan) we can identify outlier regions whose pattern of variation could potentially be attributed to causes other than neutral processes, such as adaptation or migration. We will use the Monkeyflower system to generate a diversity landscape."
  },
  {
    "objectID": "exercises/genetic_diversity/index.html#preparation",
    "href": "exercises/genetic_diversity/index.html#preparation",
    "title": "Genetic diversity landscapes",
    "section": "Preparation",
    "text": "Preparation\nIn this exercise, we will be analysing the full data set for linkage group 4 (LG4), consisting of all 37 samples.\n\n\n\n\nTable 1: Summary of VCF files\n\nFilename\nrecords\nsamples\n\n\nallsites.vcf.gz\n1e+05\n37\n\n\n\n\n\nSome of the programs require we prepare population files. For pixy, this is a headerless, tab-separated file with sample and population columns. The sampleinfo.csv file contains the information we need; the sample names have been prefixed with a three-letter code to indicate population (apart from ssp. puniceus which also comes with a single letter R or Y indicating ecotype). Table 2 summarizes the populations and samples.\n\nCode# R code to generate sample population summary\ndata &lt;- tibble(read.csv(\"sampleinfo.csv\"))\ndata &lt;- data %&gt;%\n    mutate(Population = SampleAlias) %&gt;%\n    mutate(across(\"Population\", str_replace, \"(.+)-.+$\", \"\\\\1\")) %&gt;%\n    mutate(across(\"Population\", str_replace, \"(CLV)_.+\", \"\\\\1\"))\ndata %&gt;%\n    group_by(Population, ScientificName) %&gt;%\n    summarise(n = n(), samples = paste(SampleAlias, collapse = \", \")) %&gt;%\n    kable()\n\n\n\nTable 2: Summary of populations and samples.\n\n\n\n\n\n\n\nPopulation\nScientificName\nn\nsamples\n\n\n\nARI\nDiplacus aridus\n4\nARI-159_83, ARI-159_84, ARI-195_1, ARI-T84\n\n\nAUR\nDiplacus aurantiacus\n4\nAUR-T102, AUR-T104, AUR-T50, AUR-T92\n\n\nCAL\nDiplacus calycinus\n4\nCAL-T90, CAL-T91, CAL-T144, CAL-T150\n\n\nCLV\nDiplacus clevelandii\n3\nCLV_GH, CLV_11, CLV_4\n\n\nGRA\nDiplacus grandiflorus\n4\nGRA-T96, GRA-T101, GRA-T61, GRA-T99\n\n\nLON\nDiplacus longiflorus\n4\nLON-T33, LON-T8, LON-DPR, LON-SS\n\n\nPAR\nErythranthe parviflora\n4\nPAR-KK161, PAR-KK168, PAR-KK180, PAR-KK182\n\n\nPUN-R\nDiplacus puniceus\n5\nPUN-R-ELF, PUN-R-JMC, PUN-R-LH, PUN-R-MT, PUN-R-UCSD\n\n\nPUN-Y\nDiplacus puniceus\n5\nPUN-Y-BCRD, PUN-Y-INJ, PUN-Y-LO, PUN-Y-PCT, PUN-Y-POTR\n\n\n\n\n\n\n\n\n\n\nFigure 1: Evolutionary relationships across the radiation\n\n\n\nFigure 2: Monkeyflower sampling locations\n\nWe convert the sample information with csvtk. We also add a populations file with all samples belonging to the same population:\n\ncsvtk mutate --name Population --fields SampleAlias sampleinfo.csv |\n csvtk cut --fields SampleAlias,Population |\n csvtk replace --fields Population --pattern \"(.+)-.+$\" --replacement \"\\$1\" |\n csvtk replace --fields Population --pattern \"(CLV)_.+\" --replacement \"\\$1\" |\n csvtk del-header --out-tabs &gt; populations.txt\ncsvtk cut --fields SampleAlias sampleinfo.csv |\n csvtk mutate --name Population --fields SampleAlias |\n csvtk replace --fields Population --pattern \".+\" --replacement \"ALL\" |\n csvtk del-header --out-tabs &gt; populations.ALL.txt\n\nvcftools, on the other hand, requires that populations are specified as separate files, containing the individuals of each population. We can use the populations.txt file to quickly generate population-specific files, and we add an ALL population, treating all samples as coming from the same population:\n\nfor pop in ARI AUR CAL CLV GRA LON PAR PUN-R PUN-Y; do\n csvtk --no-header-row grep --tabs --fields 2 --pattern \"$pop\" populations.txt | \\\n  csvtk cut --tabs --fields 1 &gt; $pop.txt;\ndone\ncsvtk cut --tabs --no-header-row --fields 1 populations.txt &gt; ALL.txt\n\nWe define environment variables to make the downstream commands easier to type:\n\nVCF=allsites.vcf.gz\nPOPS=populations.txt"
  },
  {
    "objectID": "exercises/genetic_diversity/index.html#generating-and-visualising-diversity-statistics",
    "href": "exercises/genetic_diversity/index.html#generating-and-visualising-diversity-statistics",
    "title": "Genetic diversity landscapes",
    "section": "Generating and visualising diversity statistics",
    "text": "Generating and visualising diversity statistics\nCompiling statistics with vcftools\nCreate an output directory for the results and define some environment variables:\n\nmkdir -p 01-vcftools\nOUT=01-vcftools/allsites\n\nNucleotide diversity (\\(\\pi\\))\nNucleotide diversity can be calculated by site (--site-pi) or in windows (--window-pi)2.\n\nvcftools --gzvcf $VCF --site-pi --out $OUT 2&gt; /dev/null\ncsvtk summary $OUT.sites.pi --ignore-non-numbers --tabs \\\n   --fields PI:mean,PI:stdev\n\nPI:mean PI:stdev\n0.04    0.10\n\n\n\n# Set your window size higher, e.g., 10kb\nvcftools --gzvcf $VCF --window-pi 1000 --out $OUT 2&gt; /dev/null\n\n\n\n\n\n\n\nOn genome scans and window sizes\n\n\n\n\n\nGenetic diversity estimates can be noisy, so we often want to compute values in sliding windows across a sequence. Choosing window size can be as simple as trying out different values, often ranging from single to several hundred kilobases. As always, the appropriate size depends on the analyses.\nOne rule of thumb that can be applied is that the window size should be larger than the genomic background of linkage disequilibrium (LD). Recall, LD is the non-random co-segregation of alleles at two or more loci. Linked loci will induce correlations in window-based statistics, so by choosing a window size larger than the LD background, we ensure that our windows are, in some sense, independent.\nFor this reason, a common approach is to calculate some measure of LD between marker pairs, and generate a plot of LD decay. This is outside the scope of this exercise, but the interested reader can consult the plink documentation for ways to do this. See also Figure 3 for an example plot.\n\n\n\n\n\n\n\n\nFigure 3: Properties of genetic variation and inferred demographic history in sampled A. millepora. Fuller et al. (2020), Figure 2. Upper left plot illustrates LD as a function of physical distance. Here, choosing a window size 20-30kb would ensure that most windows are independent.\n\n\nEven though single point summary statistics can be informative, we can get an overview of the distribution over the chromosome by plotting:\n\ncsvtk plot line --tabs $OUT.windowed.pi -x BIN_START -y PI \\\n   --point-size 0.01 --xlab \"Position (bp)\" \\\n   --ylab \"Diversity\" --title LG4 --width 9.0 --height 3.5 \\\n   &gt; $OUT.png\n\n\n\n\n\n\nFigure 4: Nucleotide diversity across LG4 for all populations.\n\nFigure 4 shows the diversity for all populations. We would also be interested in comparing the diversity for different populations. This can be achieved by passing a population file to bcftools view and piping (|) the output to vcftools:\n\nbcftools view -S PAR.txt $VCF |\\\n vcftools --vcf - --window-pi 1000 --out $OUT.PAR 2&gt; /dev/null\nbcftools view -S ARI.txt $VCF |\\\n vcftools --vcf - --window-pi 1000 --out $OUT.ARI 2&gt; /dev/null\n\nWith some csvtk magic we can combine the measures and plot:\n\n# When assigning a constant must enclose it in single quotes within double quotes\ncsvtk mutate2 --tabs --name Population --expression \" 'ARI' \" \\\n   $OUT.ARI.windowed.pi &gt; $OUT.ARI.wpi\ncsvtk mutate2 --tabs --name Population --expression \" 'PAR' \" \\\n   $OUT.PAR.windowed.pi &gt; $OUT.PAR.wpi\ncsvtk concat --tabs $OUT.ARI.wpi $OUT.PAR.wpi |\\\n csvtk plot --tabs line - -x BIN_START -y PI \\\n    --group-field Population \\\n    --point-size 0.01 --xlab \"Position (bp)\" \\\n    --ylab \"Diversity\" --title \"LG4:PAR and ARI\" \\\n    --width 9.0 --height 3.5 \\\n    &gt; $OUT.ARI.PAR.png 2&gt;/dev/null\n\n\n\n\n\n\nFigure 5: Nucleotide diversity across LG4 comparing populations ARI and PAR.\n\n\\(F_{ST}\\)\nSince \\(F_{ST}\\) is a statistic that compares populations, we must supply two or more of the population files we defined above. A population file name is passed to the --weir-fst-pop option. Calculations are done by site per default, but let’s calculate \\(F_{ST}\\) for a comparison of two populations in 100kb windows:\n\n# Set your window size higher, e.g., 100000\nvcftools --gzvcf $VCF --weir-fst-pop ARI.txt \\\n   --weir-fst-pop PAR.txt \\\n   --fst-window-size 1000 \\\n   --out $OUT.ARI-PAR\n\n\ncsvtk plot line --tabs $OUT.ARI-PAR.windowed.weir.fst \\\n   -x BIN_START -y MEAN_FST \\\n   --point-size 0.01 --xlab \"Position (bp)\" \\\n   --ylab \"Fst\" --title \"LG4:ARI vs PAR\" \\\n   --width 9.0 --height 3.5 \\\n   &gt; $OUT.ARI-PAR.windowed.weir.fst.mean.png\n\n\n\n\n\n\nFigure 6: Mean \\(F_{ST}\\) across LG4, comparing ARI and PAR populations.\n\nCompiling statistics with pixy\nThe vcftools statistics that we just calculated have a couple of issues:\n\nthey have been calculated on unfiltered data; this can be somewhat remediated by applying a depth-based filter\na more concerning problem is that even if we did apply a filter, all missing sites would be treated as invariant sites, when in reality the windows would need to be adjusted to the number of accessible sites within a window. This number could be calculated from a mask file, but adds some complexity to the calculations.\n\nInstead of applying filters, let’s first try out an alternative solution. pixy is a program that facilitates the calculation of nucleotide diversity within \\(\\pi\\) and between \\(d_{XY}\\) populations from a VCF, as well as differentiation (\\(F_{ST}\\)). It also takes invariant sites and missing data into consideration. Another nice feature is that by providing a population file with all samples, every population comparison is done on the fly, so only one run is needed!\nCalculating per-site statistics takes too long time, so we will only generate windowed output here. This may still take a couple of minutes though.\n\nmkdir -p 02-pixy\n# Set your window size higher, e.g., 100kb\npixy --stats pi fst dxy \\\n  --vcf $VCF \\\n  --populations populations.txt \\\n  --window_size 1000 \\\n  --output_folder 02-pixy \\\n  --n_cores 4\n\n\nhead -n 3 02-pixy/pixy_pi.txt\n\npop chromosome  window_pos_1    window_pos_2    avg_pi  no_sites    count_diffs count_comparisons   count_missing\nLON LG4 1   1000    0.0019674355495251  616 29  14740   3544\nPAR LG4 1   1000    0.0008201763379126  625 12  14631   3653\n\n\nFor windowed output, the pixy output files contain information on the windows, the number of missing sites, number of snps, and more. The first column corresponds to the population, which means we can easily select lines matching population(s) of interest. For a full description, consult the documentation. Note that because we provided a population file defining two populations, diversity is calculated per population.\nWe conclude by plotting diversity for ARI and PAR\n\n# Possibly remove NA values that otherwise would throw error\ncsvtk filter2 --tabs \\\n   --filter '$avg_pi != \"NA\" && ($pop == \"ARI\" || $pop == \"PAR\") ' \\\n   02-pixy/pixy_pi.txt | \\\n csvtk plot line --tabs - -x window_pos_1 -y avg_pi \\\n    --group-field pop \\\n    --point-size 0.01 --xlab \"Position (bp)\" \\\n    --ylab \"Diversity\" --title \"LG4:ARI and PAR\" \\\n --width 9.0 --height 3.5 \\\n    &gt; 02-pixy/pixy_pi.ARI-PAR.txt.png\n\n\n\n\n\n\nFigure 7: Mean diversity across LG4 for ARI and PAR.\n\nand \\(F_{ST}\\) comparing ARI and PAR\n\ncsvtk filter2 --tabs \\\n   --filter '$avg_wc_fst != \"NA\" && $pop1 == \"PAR\" && $pop2 == \"ARI\" ' \\\n   02-pixy/pixy_fst.txt | \\\n csvtk plot line -t - -x window_pos_1 -y avg_wc_fst \\\n    --point-size 0.01 --xlab \"Position (bp)\" \\\n    --ylab \"Fst\" --title \"LG4:ARI vs PAR\" --width 9.0 --height 3.5 \\\n    &gt; 02-pixy/pixy_fst.ARI-PAR.txt.png\n\n\n\n\n\n\nFigure 8: Mean \\(F_{ST}\\) across LG4 for ARI vs PAR.\n\nComparing Figure 8 to Figure 6 shows a stark contrast, so clearly, how you filter and handle invariant/missing data will strongly affect the outcome.\n\n\n\n\n\n\nOPTIONAL: Apply filters to pixy and vcftools output and compare\n\n\n\n\n\n\n\nGenerate depth filters, utilizing the knowledge from the variant filtering lab, and apply them to the VCF file. Rerun a couple of pixy and vcftools stats to see how it affects the outcome. Provided you use identical window sizes, you could make a scatter plot of a statistic of the two tools against oneanother."
  },
  {
    "objectID": "exercises/genetic_diversity/index.html#genome-scans-and-genomic-features",
    "href": "exercises/genetic_diversity/index.html#genome-scans-and-genomic-features",
    "title": "Genetic diversity landscapes",
    "section": "Genome scans and genomic features",
    "text": "Genome scans and genomic features\n\n Working with Z-transformed data\nTransforming raw data to Z-scores can facilitate the scan for outlier regions. However, there is no easy way to do this with csvtk, so here is some template R code to do this from pixy data.\n\npi &lt;- read.table(\"pixy_pi.txt\", header = TRUE)\n# Select population PAR\ndata &lt;- data[data$pop == \"PAR\", ]\nx &lt;- data$avg_pi\nz &lt;- (x - mean(x, na.rm = TRUE))/sd(x, na.rm = TRUE)\n# Plot data along chromosome and identify region by eye plot(x =\n# data$window_pos_1, y = z, xlab = 'Position (bp)')\n\nStratifying by genomic feature\npixy accepts as input a BED file that defines coordinates of genome features. Here is an example of how to extract CDS regions and then compile results with pixy:\n\ncsvtk filter2 --tabs annotation.gff --filter ' $3 == \"CDS\" ' |\\\n csvtk cut --tabs --fields 1,10,11 | bedtools sort | bedtools merge \\\n    &gt; CDS.bed 2&gt;/dev/null\n\n\npixy --vcf allsites.vcf.gz --stats pi \\\n --populations populations.txt \\\n --output_prefix cds --bed_file CDS.bed"
  },
  {
    "objectID": "exercises/genetic_diversity/index.html#monkeyflower-diversity-landscape",
    "href": "exercises/genetic_diversity/index.html#monkeyflower-diversity-landscape",
    "title": "Genetic diversity landscapes",
    "section": "Monkeyflower diversity landscape",
    "text": "Monkeyflower diversity landscape\nDrawing on what you learned earlier today about filtering, and with the help of the command examples above, you can now start exploring the Monkeyflower diversity landscape. Try different population comparisons, perform outlier analyses, and see if you can find candidate regions of interest. If you want inspiration, take a look at the methods section of Stankowski et al. (2019).\nHere are some suggested actions that you can take, but feel free to look at the data in any way you want.\n\n\n\n\n\n\nApply depth filter to VCF\n\n\n\n\n\n\n\nCreate a VCF subset of all samples and generate a depth filter, following the guidelines in the filtering exercise.\n\n\n\n\n\n\n\n\n\n\n\nRun an outlier analysis and investigate significant loci\n\n\n\n\n\n\n\nZ-transform a statistic and try to identify outliers. You can compare the coordinates of any significant locus with those in the provided annotation file MAUR_annotation_functional_submission.gff.\n\n\n\n\n\n\n\n\n\n\n\nCompile data by genome feature\n\n\n\n\n\n\n\nUse the annotation file MAUR_annotation_functional_submission.gff to generate BED files that define the regions of some features of interest, e.g., genes, introns, or UTRs. Do the results make sense?\n\n\n\n\n\n\n\n\n\n\n\nReproduce distributions of diversity statistics for different population comparisons\n\n\n\n\n\n\n\n\nSee if you can reproduce some of the results in Stankowski et al. (2019), Fig. 2\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigate a known adaptive locus on LG4\n\n\n\n\n\n\n\n\nInvestigate more closely the known adaptive locus on LG4, as illustrated in Stankowski et al. (2019), Fig. 4"
  },
  {
    "objectID": "exercises/genetic_diversity/index.html#footnotes",
    "href": "exercises/genetic_diversity/index.html#footnotes",
    "title": "Genetic diversity landscapes",
    "section": "Footnotes",
    "text": "Footnotes\n\nThe password is provided by the course instructor↩︎\nRecall; the dataset used to render these pages is much smaller, which is why we use a smaller window size below. Consequently, your plot will look different.↩︎"
  },
  {
    "objectID": "exercises/variant_calling/index.html",
    "href": "exercises/variant_calling/index.html",
    "title": "Variant calling",
    "section": "",
    "text": "Compute environment setup\n\n\n\n\n\nIf you haven’t already done so, please read Compute environment for information on how to prepare your working directory.\nIn this exercise we will produce a variant call set, going through the basic steps from quality control through read mapping to variant calling. We will be working on the Monkeyflowers dataset. Make sure to read the dataset document before running any commands as it will give you the biological background and general information about where to find and how to setup the data. We will focus on the red and yellow ecotypes in what follows."
  },
  {
    "objectID": "exercises/variant_calling/index.html#variant-calling-overview",
    "href": "exercises/variant_calling/index.html#variant-calling-overview",
    "title": "Variant calling",
    "section": "Variant calling overview",
    "text": "Variant calling overview\nA generic variant calling workflow consists of the following basic steps:\n\nread quality control and filtering\nread mapping\nremoval / marking of duplicate reads\njoint / sample-based variant calling and genotyping\n\nThere are different tweaks and additions to each of these steps, depending on application and method.\n1. Read quality control\n\n\n\n \nFigure 1: Per base quality scores, read 1 (upper) and read 2 (lower panel), obtained from the FastQC program. Quality values are on the \\(y\\)-axis, base position in sequence read on \\(x\\)-axis.\n\nDNA sequencers score the quality of each sequenced base as phred quality scores, which is equivalent to the probability \\(P\\) that the call is incorrect. The base quality scores, denoted \\(Q\\), are defined as\n\\[\nQ = -10 \\log_{10} P\n\\]\nwhich for \\(P=0.01\\) gives \\(Q=20\\). Converting from quality to probability is done by solving for \\(P\\):\n\\[\nP = 10^{-Q/10}\n\\]\nHence, a base quality score \\(Q=20\\) (somtimes written Q20) corresponds to a 1% probability that the call is incorrect, Q30 a 0.1% probability, and so on, where the higher the quality score, the better. Bases with low quality scores are usually discarded from downstream analyses, but what is a good threshold? The human genome has approximately 1 SNP per 1,000 bp, which means sequencing errors will be ten times as probable in a single read for Q20 base calls. A reasonable threshold is therefore around Q20-Q30 for many purposes.\nThe base qualities typically drop towards the end of the reads (Figure 1). Prior to mapping it may therefore be prudent to remove reads that display too high drop in quality, too low mean quality, or on some other quality metric reported by the qc software.\nThe quality scores are encoded using ASCII codes. An example of a FASTQ sequence is given below. The code snippet shows an example of shell commands2 that are separated by a so-called pipe (|) character which takes the output from one process and sends it as input to the next3.\nNote that we use the long option names to clarify commands, and we aim to do so consistently when a new command is introduced. Once you feel confident you know what a command does, you will probably want to switch to short option names, and we may do so in the instructions for some commonly used commands (e.g., head -n) without warning. Remember to use --help to examine command options.\n\n# Command using long (-- prefix) option names\nzcat PUN-Y-INJ_R1.fastq.gz | head --lines 4 | cut --characters -30\n# Equivalent command using short (single -, single character) option names\n# zcat PUN-Y-INJ_R1.fastq.gz | head -n 4 | cut -c -30\n\n@SRR9309790.10003134\nTAAATCGATTCGTTTTTGCTATCTTCGTCT\n+\nAAFFFJJJJJJJFJJJJJJJJJJJJJJJJJ\n\n\nA FASTQ entry consists of four lines:\n\nsequence id (prefixed by @)\nDNA sequence\nseparator (+)\nphred base quality scores\n\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\n\n Use the command wc to determine how many sequences are in PUN-Y-INJ_R1.fastq.gz.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\n\nThe wc help page (wc --help) shows wc prints newline, word and byte counts for a file, where newline is what we’re after. We can restrict the output to newline characters with the --lines option. Use zcat to print the contents of PUN-Y-INJ_R1.fastq.gz to the screen, piping (|) the output to wc --lines.\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\nzcat PUN-Y-INJ_R1.fastq.gz | wc --lines\n\nSince there are four lines per sequence (id, sequence, + separator, qualities) you need to divide the final number by four (622744 / 4).\n\n\n\n\n\n\n\n\n\n\n2. Read mapping\nRead mapping consists of aligning sequence reads, typically from individuals in a population (a.k.a. resequencing) to a reference sequence. The choice of read mapper depends, partly on preference, but mostly on the sequencing read length and application. For short reads, a common choice is bwa-mem, and for longer reads minimap2.\nIn what follows, we will assume that the sequencing protocol generates paired-end short reads (e.g., from Illumina). In practice, this means a DNA fragment has been sequenced from both ends, where fragment sizes have been selected such that reads do not overlap (i.e., there is unsequenced DNA between the reads of a given insert size).\nThe final output of read mapping is an alignment file in binary alignment map (BAM) format or variants thereof.\n3. Removal / marking of duplicate reads\nDuring sample preparation or DNA amplification with PCR, it may happen that a single DNA fragment is present in multiple copies and therefore produces redundant sequencing reads. This shows up as alignments with identical start and stop coordinates. These so-called duplicate reads should be marked prior to any downstream analyses. The most commonly used tools for this purpose are samtools markdup and picard MarkDuplicates.\n4. Variant calling and genotyping\nOnce BAM files have been produced, it is time for variant calling, which is the process of identifying sites where there sequence variation. There are many different variant callers, of which we will mention four.\nbcftools is a toolkit to process variant call files, but also has a variant caller command. We will use bcftools to look at and summarize the variant files.\nfreebayes uses a Bayesian model to call variants. It may be time-consuming in high-coverage regions, and one therefore may have to mask repetitive and other low-complexity regions.\nANGSD is optimized for low-coverage data. Genotypes aren’t called directly; rather, genotype likelihoods form the basis for all downstream analyses, such as calculation of diversity or other statistics.\nFinally, GATK HaplotypeCaller performs local realignment around variant candidates, which avoids the need to run the legacy GATK IndelRealigner. Realignment improves results but requires more time to run. GATK is optimized for human data. For instance, performance drops dramatically if the reference sequence consists of many short scaffolds/contigs, and there is a size limit to how large the chromosomes can be. It also requires some parameter optimization and has a fairly complicated workflow (Hansen, 2016).\nGATK best practice variant calling\nWe will base our work on the GATK Germline short variant discovery workflow. In addition to the steps outlined above, there is a step where quality scores are recalibrated in an attempt to correct errors produced by the base calling procedure itself.\nGATK comes with a large set of tools. For a complete list and documentation, see the “Tool Documentation Index” (2023)."
  },
  {
    "objectID": "exercises/variant_calling/index.html#preparation-reference-sequence-index-and-read-qc",
    "href": "exercises/variant_calling/index.html#preparation-reference-sequence-index-and-read-qc",
    "title": "Variant calling",
    "section": "Preparation: reference sequence index and read QC",
    "text": "Preparation: reference sequence index and read QC\nPrior to mapping we need to create a database index. We also generate a fasta index and a sequence dictionary for use with the picard toolkit.\n\n\n\n\n\n\nImportant\n\n\n\nOn UPPMAX, the command to run picard is java -jar $PICARD_HOME/picard.jar. The UPPMAX command version is included as a comment whenever there is a command running picard. Make sure to uncomment when copying the code. If you have problems running the command, it may be because an incompatible java version is loaded as a module. To remedy this situation, run\n\nmodule unload java\n\n\n\n\nsamtools faidx M_aurantiacus_v1.fasta\n# java -jar $PICARD_HOME/picard.jar CreateSequenceDictionary --REFERENCE M_aurantiacus_v1.fasta\npicard CreateSequenceDictionary --REFERENCE M_aurantiacus_v1.fasta\nbwa index M_aurantiacus_v1.fasta\n\nWith the program fastqc we can generate quality control reports for all input FASTQ files simultaneously, setting the output directory with the -o flag:\n\n# Make fastqc output directory; --parents makes parent directories as\n# needed\nmkdir --parents fastqc\nfastqc --outdir fastqc *fastq.gz\n\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\n\ncd to the output directory and look at the html reports. Do you notice any difference between read 1 (R1) and read 2 (R2)?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\ncd fastqc\nopen PUN-Y-INJ_R1_fastqc.html\nopen PUN-Y-INJ_R2_fastqc.html\n\nThe traffic light summary indicates whether a given quality metric has passed or not. Typically, read 2 has slightly lower quality and more quality metrics with warnings. Since these reads have been deposited in the Sequence Read Archive (SRA), it is likely they were filtered prior to upload, and we will not take any further action here.\n\n\n\n\n\n\n\n\n\n\nWe will use MultiQC later on to combine the results from several output reports."
  },
  {
    "objectID": "exercises/variant_calling/index.html#read-mapping-1",
    "href": "exercises/variant_calling/index.html#read-mapping-1",
    "title": "Variant calling",
    "section": "Read mapping",
    "text": "Read mapping\nWe will start by mapping FASTQ read pairs to the reference. We will use the bwa read mapper together with samtools to process the resulting output.\nRead group information identifies sequence sets\nSome of the downstream processes require that reads have been assigned read groups (“Read Groups,” 2023), which is a compact string representation of a set of reads that originate from a sequencing unit and sample. Assigning read groups becomes particularly important for multiplexing protocols, or when a sample has been sequenced on different lanes or platform units, as it allows for the identification of sequence batch issues (e.g., poor sequence quality). Here, we want to assign a unique ID, the sample id (SM), and the sequencing platform (PL), where the latter informs the algorithms on what error model to apply. The read group is formatted as @RG\\tID:uniqueid\\tSM:sampleid\\tPU:platform, where \\t is the tab character. More fields can be added; see the SAM specification, section 1.3 (HTS Format Specifications, 2023) for a complete list.\nSample information is available in the sampleinfo.csv file:\n\nhead -n 3 sampleinfo.csv\n\nSample,Run,ScientificName,SampleName,AuthorSample,SampleAlias,Taxon,Latitude,Longitude,% Reads aligned,Seq. Depth\nSRS4979271,SRR9309782,Diplacus longiflorus,LON-T33_1,T33,LON-T33,ssp. longiflorus,34.3438,-118.5099,94.6,18.87\nSRS4979267,SRR9309785,Diplacus longiflorus,LON-T8_8,T8,LON-T8,ssp. longiflorus,34.1347,-118.6452,82.6,25.11\n\n\nThe sample information is a combination of the run information obtained from the SRA (BioProject PRJNA549183) and the sample sheet provided with the article. An additional column SampleAlias has been added that names samples using a three-letter abbreviation for population hyphenated with the sample identifier. For the ssp. puniceus, an additional one-letter character denoting the color ecotype is inserted between population and sample id. PUN-Y-BCRD then is a sample from the puniceus subspecies with the yellow ecotype. We will use the Run column as unique ID, SampleAlias as the sample id SM, and ILLUMINA as the platform PL.\nRead mapping with bwa and conversion to BAM format with samtools\nLet’s map the FASTQ files corresponding to sample PUN-Y-BCRD:\n\nbwa mem -R \"@RG\\tID:SRR9309788\\tSM:PUN-Y-BCRD\\tPL:ILLUMINA\" -t 4 \\\n -M M_aurantiacus_v1.fasta PUN-Y-BCRD_R1.fastq.gz PUN-Y-BCRD_R2.fastq.gz | \\\n samtools sort - | samtools view --with-header --output PUN-Y-BCRD.sort.bam\n\nThere’s a lot to unpack here. First, the -R flag to bwa mem passes the read group information to the mapper. -t sets the number of threads, and -M marks shorter split hits as secondary, which is for Picard compatibility4. The first positional argument is the reference sequence, followed by the FASTQ files for read 1 and 2, respectively.\nThe output would be printed on the screen (try running the bwa mem command alone!), but we pipe the output to samtools sort to sort the mappings (by default by coordinate). The - simply means “read from the pipe”.\nFinally, samtools view converts the text output to binary format (default), including the header information (short option -h). You can use the same command to view the resulting output on your screen:\n\nsamtools view PUN-Y-BCRD.sort.bam | head -n 2\n\nSRR9309788.7313829  129 LG4 29  60  103M2I46M   =   83824   83796   GTCAATTTCATGTTTGACTTTTAGATTTTTAATTAATTATATATTTTTTGCAATTTGTAACCTCTTTAACCTTTATTTAATTTTTTGAATTTCTTTTTTATTTTATTTTCAAATACAATTCACCCCAATTAATTATTTTAATTATAACAAT AAFFFJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJFJJJJJJJJJJJJJAFJJFJJJF&lt;JJJJJJJJ&lt;AJJJJJJJJJ-FFJJAJJJJA-7-7----&lt;A---7&lt;-)7AAA-AA7-&lt;-7--&lt;A---7---7 NM:i:6  MD:Z:107T25A1C6A6   MC:Z:88M8D63M   AS:i:121    XS:i:80 RG:Z:SRR9309788\nSRR9309788.9554822  99  LG4 58  60  74M2I75M    =   256 321 TAATTAATTATATATTTTTTGCAATTTGTAACCTCTTTAACCTTTATTTAATTTTTTGAATTTCTTTTTTATTTTATTTTCAAATACAATTCACCCCAATTAATTAATCTAATTAAAACAATTAAATAATCAACCCGAATGATTAACCAAT AAFFFJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJFAAJJJJJJJJFJJJFJJ&lt;FJJAJJJFJJJJ&lt; NM:i:5  MD:Z:78T54G0C14 MC:Z:21S82M2I9M5I32M    AS:i:126    XS:i:81 RG:Z:SRR9309788\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\n\nLook at the header information of the output BAM file. What does the @SQ tag stand for, and what does the information on that line tell you?\n\n\n\n\n\n\nHint\n\n\n\n\n\n\n\nTo get a list of options, type samtools view. The -H or --header-only option views the header only.\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\nsamtools view -H PUN-Y-BCRD.sort.bam\n\n@HD VN:1.6  SO:coordinate\n@SQ SN:LG4  LN:100000\n@RG ID:SRR9309788   SM:PUN-Y-BCRD   PL:ILLUMINA\n@PG ID:bwa  PN:bwa  VN:0.7.17-r1188 CL:bwa mem -R @RG\\tID:SRR9309788\\tSM:PUN-Y-BCRD\\tPL:ILLUMINA -t 4 -M M_aurantiacus_v1.fasta PUN-Y-BCRD_R1.fastq.gz PUN-Y-BCRD_R2.fastq.gz\n@PG ID:samtools PN:samtools PP:bwa  VN:1.15.1   CL:samtools sort -\n@PG ID:samtools.1   PN:samtools PP:samtools VN:1.15.1   CL:samtools view --with-header --output PUN-Y-BCRD.sort.bam\n@PG ID:samtools.2   PN:samtools PP:samtools.1   VN:1.15.1   CL:samtools view -H PUN-Y-BCRD.sort.bam\n\n\nAlthough you can probably figure it out by looking at the data, do have a glance at the SAM format specification mentioned above. The @SQ tag corresponds to the reference sequence dictionary and tells you what region you are looking at (chromosome LG4, which has a length LN 100000 bases; the example reference sequence was created by extracting the region on LG4 from position 12000000 to 12100000).\n\n\n\n\n\n\n\n\n\n\nMapping from uBAM file\nThere is an alternative storage format for the FASTQ files called uBAM (unmapped BAM format). The GATK developers promote its use in lieu of FASTQ files since BAM files can store more metadata associated with sequencing runs. The workflow is slightly more complex, but the files have been prepared for you so you don’t need to worry about generating the uBAM files.\nTo facilitate downstream processing, we will from now on make use of environment variables5 to refer to a sample and the reference sequence. Retrieve the SRR id from the sampleinfo file.\n\nexport SRR=SRR9309790\nexport SAMPLE=PUN-Y-INJ\nexport REF=M_aurantiacus_v1.fasta\nsamtools fastq ${SAMPLE}.unmapped.bam | \\\n bwa mem -R \"@RG\\tID:${SRR}\\tSM:${SAMPLE}\\tPL:ILLUMINA\" -t 4 -p -M ${REF} - | \\\n samtools sort - | samtools view -h -o ${SAMPLE}.sort.bam\n\nNote that we here need to use the command samtools fastq to read the contents of ${SAMPLE}.unmapped.bam and pipe the output to bwa mem.\nMark duplicate reads with Picard MarkDuplicates\nOnce mapping is completed, we must find and mark duplicate reads as these can distort the results of downstream analyses, such as variant calling. We here use Picard MarkDuplicates6:\n\n#java -jar $PICARD_HOME/picard.jar MarkDuplicates --INPUT ${SAMPLE}.sort.bam \\\n#    --METRICS_FILE ${SAMPLE}.sort.dup_metrics.txt \\\n#    --OUTPUT ${SAMPLE}.sort.dup.bam\npicard MarkDuplicates --INPUT ${SAMPLE}.sort.bam \\\n    --METRICS_FILE ${SAMPLE}.sort.dup_metrics.txt \\\n    --OUTPUT ${SAMPLE}.sort.dup.bam\n\nThe metrics output file contains information on the rate of duplication. We will include the output in the final MultiQC report.\nAn additional mapping quality metric of interest is percentage mapped reads and average read depth. We can use qualimap bamqc to collect mapping statistics from a BAM file:\n\nqualimap bamqc -bam ${SAMPLE}.sort.bam\n\nA summary of the results is exported to ${SAMPLE}.sort_stats/genome_results.txt; we show percent mapping and average coverage below as examples:\n\ngrep \"number of mapped reads\" ${SAMPLE}.sort_stats/genome_results.txt\ngrep \"mean coverageData\" ${SAMPLE}.sort_stats/genome_results.txt\n\n     number of mapped reads = 7,643 (96.94%)\n     mean coverageData = 11.0246X\n\n\n\n\n\n\n\n\nWhy does the sample have such low coverage?\n\n\n\n\n\nIf you look at the coverage reported in sampleinfo.csv, column Seq. Depth, you will note that the observed coverage here is much lower. This has to do with how the exercise data set was prepared; only read pairs where both reads mapped within the example region were retained.\n\n\n\nThese statistics will also be picked up by MultiQC.\nGenerate high quality known sites for BQSR\nOnce we have a duplicate marked BAM file, we can proceed with Base Quality Score Recalibration (BQSR). The purpose here is to correct any systematic errors made by the sequencing machine. This is done by applying a machine learning model. Before we do so, however, we need to generate a list of known sites that should not be recalibrated7 Therefore, we will first perform a preliminary round of variant calling and filtering to generate a known sites callset.\n\ngatk HaplotypeCaller -OVI true \\\n  --emit-ref-confidence GVCF \\\n  --annotation FisherStrand -A QualByDepth -A MappingQuality -G StandardAnnotation \\\n  --input ${SAMPLE}.sort.dup.bam --output ${SAMPLE}.sort.dup.raw.hc.g.vcf.gz \\\n  --reference ${REF}\ngatk VariantFiltration -OVI true \\\n  --variant ${SAMPLE}.sort.dup.raw.hc.g.vcf.gz \\\n  --output ${SAMPLE}.sort.dup.raw.hc.filtered.g.vcf.gz \\\n     --filter-name FisherStrand --filter 'FS &gt; 50.0' \\\n  --filter-name QualByDepth --filter 'QD &lt; 4.0' \\\n  --filter-name MappingQuality --filter 'MQ &lt; 50.0'\n\nHaplotypeCaller is GATK’s variant caller that calls both SNPs and indels by realigning sequences in the vicinity of sites that harbor variation. We apply the --emit-ref-confidence (-ERC) option to generate GVCF output format, a condensed VCF format that includes non-variant sites as well as variant sites. The --annotation (-A) option adds annotations to the output that are used in the subsequent filtering step.\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\n\n What does the -OVI parameter do?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\nEither go to the HaplotypeCaller documentation page or type8\n\ngatk HaplotypeCaller --help 2&gt;&1 | less\n\nand look for -OVI. This option is shorthand for --create-output-variant-index and makes HaplotypeCaller create a VCF index.\n\n\n\n\n\n\n\n\n\n\nVariantFiltration does what its name suggests. The --filter-name / --filter option pairs apply named filters to the input data. For instance, we here remove variants whose mapping quality is below 50.0.\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\n\nGo to the Tool Documentation Index and look up the documentation for the FisherStrand and QualByDepth variant annotations. What do they do and why do you think the filters are applied as they are?\n\n\n\n\n\nNow we have per-sample known sites callsets that can be used as input to BQSR.\nBase quality score recalibration\nBase quality score recalibration consists of two commands:\n\ngatk BaseRecalibrator --input ${SAMPLE}.sort.dup.bam \\\n  --reference ${REF} --known-sites ${SAMPLE}.sort.dup.raw.hc.filtered.g.vcf.gz \\\n  --output ${SAMPLE}.sort.dup.recal.table\ngatk ApplyBQSR --bqsr-recal-file ${SAMPLE}.sort.dup.recal.table \\\n  --input ${SAMPLE}.sort.dup.bam --output ${SAMPLE}.sort.dup.recal.bam\n\nBaseRecalibrator compiles empirical data for all non-variant sites for an input BAM file for a number of covariates (e.g., nucleotide context). The basic idea is to fit a probability of error (i.e., a quality score of sorts), to observed covariate combinations, which is recorded in a recalibration table file. The probability is then used correct the quality scores reported by the sequencing machine in ApplyBQSR.\nOPTIONAL: Examine the output of BQSR\nWe can investigate how well BQSR has performed by applying two more commands. First, we generate a calibration table for the recalibrated BAM file:\n\ngatk BaseRecalibrator --input ${SAMPLE}.sort.dup.recal.bam \\\n  --reference ${REF} --known-sites ${SAMPLE}.sort.dup.raw.hc.filtered.g.vcf.gz \\\n  --output ${SAMPLE}.sort.dup.recal.after.table\n\nThen we use the two calibration tables as input to AnalyzeCovariates to generate a pdf output (and a csv file that we will use in the next code block):\n\ngatk AnalyzeCovariates --before-report-file ${SAMPLE}.sort.dup.recal.table \\\n  --after-report-file ${SAMPLE}.sort.dup.recal.after.table \\\n  --plots-report-file ${SAMPLE}.sort.dup.recal.after.pdf \\\n  --intermediate-csv-file ${SAMPLE}.sort.dup.recal.after.csv\n\nFigure 2 shows an example plot of quality values for base substitutions. There are more plots and summaries in the pdf output file.\n\n\n\n\n\nFigure 2: Plot of base substitution empirical and recalibrated quality scores. Note how the empirical quality scores after recalibration follow the reported qualities.\n\n\nSeveral rounds of generating known sites followed by BQSR can be applied until convergence. This means that running BQSR can be time-consuming, and one side effect is that the resulting BAM output files can become very large, which may or not be a problem. Also, sequencing technologies keep improving, potentially eliminating concerns of biased quality scores. This begs the question: is it worth running BQSR? For the time being, the GATK developers do recommend that BQSR always be run. Keep in mind though, that for non-model organisms, one issue is that there seldom is a catalogue of known sites, which means the user has to bootstrap such a call set, like we did above. For a more complete discussion, see the technical documentation on BQSR."
  },
  {
    "objectID": "exercises/variant_calling/index.html#variant-calling-and-genotyping-1",
    "href": "exercises/variant_calling/index.html#variant-calling-and-genotyping-1",
    "title": "Variant calling",
    "section": "Variant calling and genotyping",
    "text": "Variant calling and genotyping\nAfter we have generated the recalibrated BAM files, we can proceed with the “real” variant calling. We once again run GATK HaplotypeCaller and VariantFiltration.\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\n\nUsing the code in section Generate high quality known sites for BQSR as a template, run GATK HaplotypeCaller on the recalibrated BAM file, followed by VariantFiltration. For the latter, modify the filters to\n\nfilterName: FisherStrand, filter: FS &gt; 60.0\nfilterName: QualByDepth, filter: QD &lt; 2.0\nfilterName: MappingQuality, filter: MQ &lt; 40.0\n\nChange the output file label from raw to recal (i.e., .sort.dup.raw becomes .sort.dup.recal).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\ngatk HaplotypeCaller --create-output-variant-index true \\\n  --emit-ref-confidence GVCF \\\n  --annotation FisherStrand --annotation QualByDepth --annotation MappingQuality \\\n  --annotation-group StandardAnnotation \\\n  --input ${SAMPLE}.sort.dup.recal.bam --output ${SAMPLE}.sort.dup.recal.hc.g.vcf.gz \\\n  --reference ${REF}\ngatk VariantFiltration -OVI true \\\n  --variant ${SAMPLE}.sort.dup.recal.hc.g.vcf.gz \\\n  --output ${SAMPLE}.sort.dup.recal.hc.filtered.g.vcf.gz \\\n     --filter-name FisherStrand --filter 'FS &gt; 60.0' \\\n  --filter-name QualByDepth --filter 'QD &lt; 2.0' \\\n  --filter-name MappingQuality --filter 'MQ &lt; 40.0'\n\n\n\n\n\n\n\n\n\n\n\nThat concludes the sample-specific part of the variant calling workflow! Now we need to combine the samples and perform genotyping. To do so, we need to run the same commands, from mapping to variant calling and filtering on recalibrated files, for all samples.\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\n\nIf time permits, run the workflow on some more samples (e.g., PUN-R-ELF).\n\n\n\n\n\n\nImportant\n\n\n\nThere are prepared gVCF files for download so there’s no need to run the workflow on all samples.\n\n\n\n\n\n\n\nCompile QC metrics\nIdentifying sample quality issues is crucial for downstream processing. Quality metrics that indicate problems with a sample could potentially lead to its removal entirely from subsequent analyses. Many programs generate QC metrics, but as it is difficult to get an overview by sifting through all separate QC reports, it is recommended that you compile them with MultiQC. Running MultiQC is as simple as\n\nmultiqc .\n\nOpen the report multiqc_report.html to quickly QC your data. There are lots of ways you can interactively modify the report to make more logical groupings (e.g., grouping reports by sample9) , but we won’t go into this topic in more detail here.\nCombine genomic VCF files and genotype\nWe are now at the stage where we can do genotyping of our samples. This done by first combining individual sample gVCF files with GATK CombineGVCFs, followed by genotyping with GenotypeGVCFs. We use the label subset to indicate that we are looking at a sample subset.\n\n# -OVI = --create-output-variant-index\n# -R = --reference\ngatk CombineGVCFs -OVI true --output combine.subset.g.vcf.gz --reference ${REF} \\\n  --variant PUN-Y-INJ.sort.dup.recal.hc.g.vcf.gz \\\n  --variant PUN-R-ELF.sort.dup.recal.hc.g.vcf.gz\ngatk GenotypeGVCFs -OVI true -R ${REF} -V combine.subset.g.vcf.gz \\\n  --output variantsites.subset.vcf.gz\ngatk GenotypeGVCFs -OVI true -R ${REF} -V combine.subset.g.vcf.gz \\\n  --output allsites.subset.vcf.gz --all-sites\n\nHere, the option --all-sites tells gatk GenotypeGVCFs to include variant as well as invariant sites in the output. Many software packages that are based on genetic diversity statistics implicitly assume that invariant sites are all homozygous reference (Korunes & Samuk, 2021). However, if invariant sites lack sequencing coverage, they should preferably be treated as missing data, which theoretically could harbour (unobserved) variant sites. Therefore, the inclusion of invariant sites provides a way to generate estimates of missing data, based on, e.g., sequencing depth profiles.\nInclusion of invariant sites comes at a cost however; the VCF file size may increase dramatically, to the point that it becomes impractical or even impossible to process. We generate both types of files for future analyses.\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\n\nCreate variant call sets allsites.vcf.gz and variantsites.vcf.gz but for all the red and yellow samples.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\n\nYou need to specify all gVCF input files via the --variants (-V) option. To get the sample names, look at the first column of sampleinfo.csv:\n\ncat sampleinfo.csv | grep yellow | cut --fields 6 --delimiter \",\"\n\nPUN-Y-BCRD\nPUN-Y-INJ\nPUN-Y-LO\nPUN-Y-PCT\nPUN-Y-POTR\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\ngatk CombineGVCFs -OVI true --output combine.subset.g.vcf.gz --reference ${REF} \\\n     -V PUN-R-ELF.sort.dup.recal.hc.g.vcf.gz \\\n     -V PUN-R-JMC.sort.dup.recal.hc.g.vcf.gz \\\n     -V PUN-R-LH.sort.dup.recal.hc.g.vcf.gz \\\n     -V PUN-R-MT.sort.dup.recal.hc.g.vcf.gz \\\n     -V PUN-R-UCSD.sort.dup.recal.hc.g.vcf.gz \\\n     -V PUN-Y-BCRD.sort.dup.recal.hc.g.vcf.gz \\\n     -V PUN-Y-INJ.sort.dup.recal.hc.g.vcf.gz \\\n     -V PUN-Y-LO.sort.dup.recal.hc.g.vcf.gz \\\n     -V PUN-Y-PCT.sort.dup.recal.hc.g.vcf.gz \\\n     -V PUN-Y-POTR.sort.dup.recal.hc.g.vcf.gz\ngatk GenotypeGVCFs -OVI true -R ${REF} -V combine.g.vcf.gz \\\n  -O allsites.vcf.gz --all-sites\ngatk GenotypeGVCFs -OVI true -R ${REF} -V combine.g.vcf.gz \\\n  -O variantsites.vcf.gz"
  },
  {
    "objectID": "exercises/variant_calling/index.html#looking-closer-at-variants-with-bcftools",
    "href": "exercises/variant_calling/index.html#looking-closer-at-variants-with-bcftools",
    "title": "Variant calling",
    "section": "Looking closer at variants with bcftools",
    "text": "Looking closer at variants with bcftools\nAs a final step, let’s run a couple of commands to view variants and summarize variant statistics.\nCompiling statistics\nFirst out is bcftools stats, which compiles a summary of statistics, such as number of variants, quality distribution over variants, indel distributions and more.\n\nbcftools stats allsites.vcf.gz &gt; allsites.vcf.gz.stats\n\nThe output text file consists of report sections that can be easily extracted with the grep command by virtue of the fact that the first column corresponds to a shortcode of the statistic. For instance, SN corresponds to Summary numbers:\n\ngrep \"^SN\" allsites.vcf.gz.stats\n\nSN  0   number of samples:  10\nSN  0   number of records:  100000\nSN  0   number of no-ALTs:  91890\nSN  0   number of SNPs: 3980\nSN  0   number of MNPs: 0\nSN  0   number of indels:   1197\nSN  0   number of others:   0\nSN  0   number of multiallelic sites:   541\nSN  0   number of multiallelic SNP sites:   69\n\n\nHere, we can see that we have included non-variant sites (no-ALTs), that there are indels, and that a number of sites are multiallelic (more than two alleles).\nRerunning MultiQC will automatically add this report.\n\n# Use --force (-f) to overwrite old report\nmultiqc --force .\n\nWe will use bcftools stats in the next exercise to look more closely at variant quality metrics.\nLooking inside the VCF\nA Variant Call Format (VCF) file consists of three sections: meta-information lines (prefixed with ##), a header line (prefixed with #), followed by the data. The meta-information contains provenance information detailing how the file was generated, FILTER specification, INFO fields that provide additional information to genotypes, FORMAT specification fields that define genotype entries, and more. You can print the header10 with the command bcftools view -h. An example of each is given below:\n\nbcftools view --header-only allsites.vcf.gz | grep \"##FILTER\" | head -n 1\nbcftools view -h allsites.vcf.gz | grep \"##INFO\" | head -n 1\nbcftools view -h allsites.vcf.gz | grep \"##FORMAT\" | head -n 1\n\n##FILTER=&lt;ID=PASS,Description=\"All filters passed\"&gt;\n##INFO=&lt;ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes, for each ALT allele, in the same order as listed\"&gt;\n##FORMAT=&lt;ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\"&gt;\n\n\nThe header field consists of eight mandatory columns CHROM, POS, ID, REF, ALT, QUAL, FILTER and INFO, followed by FORMAT and sample columns that contain the called genotypes:\n\nbcftools view -h allsites.vcf.gz | grep CHROM\n\n#CHROM  POS ID  REF ALT QUAL    FILTER  INFO    FORMAT  PUN-R-ELF   PUN-R-JMC   PUN-R-LH    PUN-R-MT    PUN-R-UCSD  PUN-Y-BCRD  PUN-Y-INJ   PUN-Y-LO    PUN-Y-PCT   PUN-Y-POTR\n\n\nLet’s look at the first SNP entry (here, the first line extracts the position of the SNP):\n\npos=$(bcftools view --types snps --samples PUN-R-JMC allsites.vcf.gz \\\n               --no-header | head -n 1 | cut -f 2)\nbcftools view -v snps -s PUN-R-JMC allsites.vcf.gz LG4:$pos | tail -n 2\n\n#CHROM  POS ID  REF ALT QUAL    FILTER  INFO    FORMAT  PUN-R-JMC\nLG4 17  .   C   T   368.55  .   AC=0;AF=0.429;AN=0;DP=22;ExcessHet=0;FS=0;InbreedingCoeff=0.5794;MLEAC=7;MLEAF=0.5;MQ=55.94;QD=33.5;SOR=0.859   GT:AD:DP:GQ:PGT:PID:PL:PS   ./.:1,0:1:0:.:.:0,0,0:.\n\n\nThe most important columns are CHROM, which indicates the sequence (LG4), the genome position POS, the reference allele REF (i.e., the nucleotide in the reference sequence), and the alternate allele ALT, which is the called variant. QUAL is a Phred-scaled quality of the call and can be used to filter low-quality calls. The FILTER column can be used to set filter flags. The INFO column contains metadata concerning the site; for instance, DP is the approximate read depth, the definition of which is included in the meta-information:\n\nbcftools view -h allsites.vcf.gz | grep INFO | grep \"ID=DP\"\n\n##INFO=&lt;ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth; some reads may have been filtered\"&gt;\n\n\nFinally, the columns following FORMAT pertain to the samples and contain the genotype calls, formatted according to the - you guessed it - FORMAT column. The example above contains a number of fields, where GT is the genotype:\n\nbcftools view -h allsites.vcf.gz | grep FORMAT | grep \"ID=GT\"\n\n##FORMAT=&lt;ID=GT,Number=1,Type=String,Description=\"Genotype\"&gt;\n\n\nFor diploid samples, the genotype format is #/#, or #|# for phased data, where the hash marks are numbers that refer to the reference (0) and alternate (1 or higher) alleles. A . indicates a missing call.\nViewing variants and regions\nThe bcftools view command allows for quick access and viewing of file contents. A prerequisite is that we first index the file:\n\nbcftools index allsites.vcf.gz\n\nafter which we can view, say, the first three indel variants in the region 12,010,000-12,010,100, corresponding to VCF coordinates 10,000-10,10011:\n\nbcftools view -v indels -H allsites.vcf.gz LG4:10000-10100\n\nLG4 10048   .   T   TC  723.24  .   AC=5;AF=0.278;AN=18;BaseQRankSum=2.17;DP=79;ExcessHet=0.3476;FS=9.691;InbreedingCoeff=0.1176;MLEAC=6;MLEAF=0.333;MQ=60;MQRankSum=0;QD=18.08;ReadPosRankSum=1.1;SOR=1.502    GT:AD:DP:GQ:PGT:PID:PL:PS   0|1:6,4:10:99:0|1:10048_T_TC:104,0,240:10048    0/0:5,0:5:15:.:.:0,15,149:. 0/0:11,0:11:33:.:.:0,33,299:.   0/1:6,6:12:99:.:.:166,0,167:.   1/1:0,8:8:24:.:.:269,24,0:. 0/1:3,7:10:99:.:.:203,0,105:.   0/0:6,0:6:18:.:.:0,18,173:. ./.:0,0:0:0:.:.:0,0,0:. 0/0:7,0:7:0:.:.:0,0,144:.   0/0:10,0:10:30:.:.:0,30,288:.\n\n\nbcftools view has many options for subsetting and filtering variants. Remember to consult the help pages!\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\n\n How many SNPs are there in region LG4:12010000-12000100?\n\n\n\n\n\n\nHint\n\n\n\n\n\n\n\nLook in the help page for option -v.\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n# Option -H omits the header information\nbcftools view -H -v snps allsites.vcf.gz LG4:10000-10100\n# Could also use wc -l to count the number of lines\nbcftools view -H -v snps allsites.vcf.gz LG4:10000-10100 | wc -l\n\n\n\n\n\n\n\n\n\n\n\nSelecting samples\nFinally, we look at how we can select samples from a variant file. To list the samples in a file, we can run bcftools query:\n\nbcftools query --list-samples allsites.vcf.gz\n\nPUN-R-ELF\nPUN-R-JMC\nPUN-R-LH\nPUN-R-MT\nPUN-R-UCSD\nPUN-Y-BCRD\nPUN-Y-INJ\nPUN-Y-LO\nPUN-Y-PCT\nPUN-Y-POTR\n\n\nSelecting indel variants for a given sample, say PUN-Y-BCRD, and region LG4:12001000-12001100 can then be done as follows:\n\nbcftools view -H -s PUN-Y-BCRD -v indels allsites.vcf.gz LG4:1000-1100\n\nLG4 1000    .   A   AC  2143.22 .   AC=2;AF=0.778;AN=2;DP=60;ExcessHet=0;FS=0;InbreedingCoeff=0.5649;MLEAC=16;MLEAF=0.889;MQ=60;QD=27.65;SOR=1.524  GT:AD:DP:GQ:PL  1/1:0,8:8:24:323,24,0\nLG4 1023    .   AAT A   2337.16 .   AC=2;AF=1;AN=2;DP=59;ExcessHet=0;FS=0;InbreedingCoeff=0.588;MLEAC=17;MLEAF=1;MQ=60;QD=29.48;SOR=1.094   GT:AD:DP:GQ:PGT:PID:PL:PS   1|1:0,7:7:21:1|1:1023_AAT_A:315,21,0:1023\nLG4 1040    .   TG  T   2337.04 .   AC=2;AF=1;AN=2;DP=56;ExcessHet=0;FS=0;InbreedingCoeff=0.5807;MLEAC=17;MLEAF=1;MQ=60;QD=30.56;SOR=1.094  GT:AD:DP:GQ:PGT:PID:PL:PS   1/1:0,7:7:21:.:.:315,21,0:.\nLG4 1047    .   AG  A   2246.22 .   AC=2;AF=1;AN=2;DP=54;ExcessHet=0;FS=0;InbreedingCoeff=0.5664;MLEAC=17;MLEAF=1;MQ=60;QD=30.55;SOR=1.007  GT:AD:DP:GQ:PGT:PID:PL:PS   1|1:0,7:7:21:1|1:1023_AAT_A:315,21,0:1023\nLG4 1053    .   AG  A   2201.19 .   AC=2;AF=1;AN=2;DP=53;ExcessHet=0;FS=0;InbreedingCoeff=0.5659;MLEAC=17;MLEAF=1;MQ=60;QD=32.62;SOR=0.963  GT:AD:DP:GQ:PGT:PID:PL:PS   1|1:0,7:7:21:1|1:1023_AAT_A:315,21,0:1023"
  },
  {
    "objectID": "exercises/variant_calling/index.html#footnotes",
    "href": "exercises/variant_calling/index.html#footnotes",
    "title": "Variant calling",
    "section": "Footnotes",
    "text": "Footnotes\n\nThe password is provided by the course instructor↩︎\nFor any shell command, use the option --help to print information about the commands and its options. zcat is a variant of the cat command that prints the contents of a file on the terminal; the z prefix shows the command works on compressed files, a common naming convention. head views the first lines of a file, and cut can be used to cut out columns from a tab-delimited file, or in this case, cut the longest strings to 30 characters width.↩︎\nFor more information, see unix pipelines↩︎\nbwa consistently uses short option names. Also, there is no --help option. To get a list of options, at the command line simply type bwa mem, or man bwa mem for general help and a complete list of options.↩︎\nBriefly, environment variables are a great way to generalise commands. To reuse the command, one only needs to modify the value of the variable.↩︎\nThe actual command call will depend on how Picard was installed. The conda installation provides access via the picard wrapper, whereas on UPPMAX you must point java to the actual jar file (java -jar $PICARD_ROOT/picard.jar)↩︎\nIf we don’t supply a list of known sites, the variants will be treated as errors and therefore recalibrated to the reference state.↩︎\nSome programs, such as GATK, print their help output to stderr, one of two so-called standard output streams (the other being stdout). The 2&gt;&1 is a construct that redirects (&gt;) the output from stderr (2) to stdout (1) and does so in the background (&). By piping to less we can scroll through the documentation.↩︎\nMultiQC does a fairly good job at this as it is, but it does so by guessing sample names from file names. You may need to help it along the way by using the rename tab.↩︎\nWhich in this context means both the metadata information and header line↩︎\nAlthough the reference sequence corresponds to region LG4:12000000-12100000, the coordinates in allsites.vcf.gz start from 1↩︎"
  },
  {
    "objectID": "exercises/datasets/monkeyflowers.html#sec-monkeyflower-model-system",
    "href": "exercises/datasets/monkeyflowers.html#sec-monkeyflower-model-system",
    "title": "Monkeyflowers dataset",
    "section": "The monkeyflower model system",
    "text": "The monkeyflower model system\nMonkeyflowers (Mimulus) have recently become a key model in evolution and plant biology (Pennisi, 2019). The monkeyflower system consists of 160–200 species that display an amazing phenotypic variation. The genome is small, only 207Mbp, which makes it an ideal candidate for genomics - and for computer exercises!"
  },
  {
    "objectID": "exercises/datasets/monkeyflowers.html#the-monkeyflower-genomic-landscape",
    "href": "exercises/datasets/monkeyflowers.html#the-monkeyflower-genomic-landscape",
    "title": "Monkeyflowers dataset",
    "section": "The monkeyflower genomic landscape",
    "text": "The monkeyflower genomic landscape\nRecently, Stankowski et al. (2019) used the monkeyflower system to investigate what forces affect the genomic landscape. Burri (2017) has suggested that background selection (BGS) is one of the main causes for correlations between genomic landscapes, and that one way to study this phenomenon is to look at closely related taxa. This is one of the objectives of the Stankowski et al. (2019) paper.\nThey performed whole-genome resequencing of 37 individuals from 7 subspecies and 2 ecotypes of Mimulus aurantiacus and its sister taxon M. clevelandii (Figure 1), all sampled in California (Figure 2).\n\n\nFigure 1: Evolutionary relationships across the radiation\n\n\n\n\n\nFigure 2: Sampling locations\n\nGenomewide statistics, such as diversity (\\(\\pi\\)), divergence (\\(d_{XY}\\)) and differentiation \\(F_{ST}\\), were calculated within and between taxa to generate genomic diversity landscapes. The landscapes were highly similar across taxa, and local variation in genomic features, such as gene density and recombination rate, was predictive of variation in landscape patterns. These features suggest the influence of selection, in particular BGS.\nAlthough many characteristics were predicted by a model where BGS is one of the main causes, there were deviations. Therefore, the authors performed simulations in SLiM (Haller & Messer, 2019) with alternative models to see whether other factors could explain the observed patterns.\nIn all, six scenarios were studied:\n\nneutral evolution\nBGS (non-neutral mutations are deleterious)\nBateson-Dobzhansky-Muller incompatibility (BDMI); after split, a fraction variants deleterious in one population, neutral in other\npositive selection\nBGS and positive selection\nlocal adaptation; as 4 but also after split some variants are beneficial in one population, neutral in other\n\nFigure 3 shows typical results of the simulations.\n\n\nFigure 3: Genomic landscapes simulated under different divergence histories.\n\nIn conclusion, the authors found that although BGS plays a role, it does not sufficiently explain all observations, and that other aspects of natural selection (such as rapid adaptation) are responsible for the similarities between genomic landscapes.\nA locus that previously had been associated with differentiation of red and yellow ecotypes was investigated in more detail. The locus is located on linkage group 4 (LG4), and we will be using both a 3Mbp region of interest (ROI) surronding the locus, and the whole linkage group, for different exercises."
  },
  {
    "objectID": "exercises/datasets/monkeyflowers.html#data",
    "href": "exercises/datasets/monkeyflowers.html#data",
    "title": "Monkeyflowers dataset",
    "section": "Data",
    "text": "Data\nThe dataset consists of 37 samples (see Table 1 for example information). Raw sequence reads were downloaded from Sequence Read Archive (SRA), bioproject PRJNA549183 and mapped to the reference sequence M_aurantiacus_v1_splitline_ordered.fasta. Reads that mapped to the ROI were extracted and constitute the sequence data that will be used during the exercises.\n\n\n\n\n\nTable 1: Example of monkeyflower samples. See file sampleinfo.csv in data repository for full listing.\n\nSample\nRun\nScientificName\nSampleName\nTaxon\nLatitude\nLongitude\n\n\n\nSRS4979271\nSRR9309782\nDiplacus longiflorus\nLON-T33_1\nssp. longiflorus\n34.3438\n-118.5099\n\n\nSRS4979267\nSRR9309785\nDiplacus longiflorus\nLON-T8_8\nssp. longiflorus\n34.1347\n-118.6452\n\n\nSRS4979269\nSRR9309784\nErythranthe parviflora\nPAR-KK161\nssp. parviflorus\n34.0180\n-119.6730\n\n\nSRS4979266\nSRR9309787\nErythranthe parviflora\nPAR-KK168\nssp. parviflorus\n34.0180\n-119.6730\n\n\nSRS4979268\nSRR9309786\nErythranthe parviflora\nPAR-KK180\nssp. parviflorus\n34.0180\n-119.6730\n\n\nSRS4979265\nSRR9309789\nErythranthe parviflora\nPAR-KK182\nssp. parviflorus\n34.0193\n-119.6802\n\n\n\n\n\n\n\n\n\nUPPMAX data storage\nThe monkeyflower dataset is located in UPPMAX project naiss2023-22-1084 at /proj/naiss2023-22-1084/webexport/monkeyflower. In addition to local access, data can be accessed remotely through https://export.uppmax.uu.se/naiss2023-22-1084.\nGithub\nThe github repository pgip-data contains reference sequence and read data for 37 monkeyflower individuals for the region LG4:12,000,000-12,100,000. The data resides in the data/monkeyflower/tiny subdirectory. This data set is used as input data to render the website.\nThe repository hosts a Snakemake workflow to generate all data needed for the exercises."
  },
  {
    "objectID": "exercises/index.html",
    "href": "exercises/index.html",
    "title": "Exercises",
    "section": "",
    "text": "All exercise pages start with a callout block that provides information on how to setup the relevant Compute environment. The callout blocks are labelled with icons that indicate the type of environment ( UPPMAX resource;  local compute environment;  online browser-based resource). Make sure to read these instructions before proceeding with the exercise itself. Some of the documents include a link to an external URL that hosts the actual exercise instructions."
  },
  {
    "objectID": "exercises/index.html#information",
    "href": "exercises/index.html#information",
    "title": "Exercises",
    "section": "",
    "text": "All exercise pages start with a callout block that provides information on how to setup the relevant Compute environment. The callout blocks are labelled with icons that indicate the type of environment ( UPPMAX resource;  local compute environment;  online browser-based resource). Make sure to read these instructions before proceeding with the exercise itself. Some of the documents include a link to an external URL that hosts the actual exercise instructions."
  },
  {
    "objectID": "exercises/index.html#on-self-assessment-exercise-blocks",
    "href": "exercises/index.html#on-self-assessment-exercise-blocks",
    "title": "Exercises",
    "section": "On self-assessment exercise blocks",
    "text": "On self-assessment exercise blocks\nScattered throughout the documents are exercise blocks, with hidden answers, and, in some cases, hints. The exercises are for self-assessment of your understanding, but they are not mandatory.\nSome of the exercises (labelled with the Linux penguin ) are related to the usage of the command line interfaces (CLI), and how to obtain information about what a program does. This is an essential skill when working in Linux/UNIX environments! These exercises can be skipped if you are an experienced Linux/UNIX user.\nAn example exercise is provided here:\n\n\n\n\n\n\nExample exercise block\n\n\n\n\n\n\n\n The ls command is used to list the contents of a directory. What option provides a so-called long listing format?\n\n\n\n\n\n\nHint\n\n\n\n\n\n\n\nType ls --help to show the options to ls.\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\nThe -l option uses the long listing format, i.e., the command to use is ls -l."
  },
  {
    "objectID": "exercises/index.html#exercises",
    "href": "exercises/index.html#exercises",
    "title": "Exercises",
    "section": "Exercises",
    "text": "Exercises"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Note\n\n\n\nCoffee breaks are planned for approximately 10:00 and 14:30 every day.\n\n\n\n\n 06-Nov-2023 Mon  Uppsala\n\n\n\n\n\n\n\n\n\n\nTime\nTopic\nTeacher\nAssistant\n\n\n\n08:30 - 09:30\nCoffee and registration\n\n\n\n\n09:00 - 09:30\nWelcome and general introduction\nPer Unneberg\nAS, JH, NO\n\n\n09:30 - 10:30\n\nPopulation genomics in practice \n\nPer Unneberg\n\n\n\n10:30 - 12:00\n\nPopulation genetics foundations \n\nPer Unneberg\n\n\n\n12:00 - 13:00\nLunch\n\n\n\n\n13:00 - 14:45\n\nIntroduction to the coalescent  \n\nPer Unneberg\nAS, JH, NO\n\n\n14:45 - 16:30\n\nIntroduction to msprime  \n\nPer Unneberg\nAS, JH, NO\n\n\n16:30 - 17:00\n\nOverview of SLiM, general applications \n\nPer Unneberg\nAS, JH, NO\n\n\n\n\n 07-Nov-2023 Tue  Uppsala\n\n\n\n\n\n\n\n\n\n\nTime\nTopic\nTeacher\nAssistant\n\n\n\n09:00 - 09:30\nRecap day 1\nPer Unneberg\n\n\n\n09:30 - 11:00\n\nVariant calling  \n\nPer Unneberg\nAS, JH, NO\n\n\n11:00 - 12:00\n\nVariant filtering  \n\nPer Unneberg\nAS, JH, NO\n\n\n12:00 - 13:00\nLunch\n\n\n\n\n13:00 - 17:00\n\nGenetic diversity, summarizing variation data  \n\nPer Unneberg\nAS, JH, NO\n\n\n\n\n 08-Nov-2023 Wed  Uppsala\n\n\n\n\n\n\n\n\n\n\nTime\nTopic\nTeacher\nAssistant\n\n\n\n09:00 - 09:30\nRecap day 2\nPer Unneberg\n\n\n\n09:30 - 12:00\n\nPopulation structure  \n\nNikolay Oskolkov\nAS, JH, PU\n\n\n12:00 - 13:00\nLunch\n\n\n\n\n13:00 - 17:00\n\nPopulation structure  \n\nNikolay Oskolkov\nAS, JH, PU\n\n\n\n\n 09-Nov-2023 Thu  Uppsala\n\n\n\n\n\n\n\n\n\n\nTime\nTopic\nTeacher\nAssistant\n\n\n\n09:00 - 09:30\nRecap day 3\nNikolay Oskolkov\n\n\n\n09:30 - 12:00\n\nDemography  \n\nAndré Soares\nJH, NO, PU\n\n\n12:00 - 13:00\nLunch\n\n\n\n\n13:00 - 17:00\n\nSelection  \n\nJason Hill\nAS, NO, PU\n\n\n\n\n 10-Nov-2023 Fri  Uppsala\n\n\n\n\n\n\n\n\n\n\nTime\nTopic\nTeacher\nAssistant\n\n\n\n09:00 - 09:15\nNBIS introduction\nPer Unneberg\n\n\n\n09:15 - 11:00\nRecap\nAndré Soares / Jason Hill / Nikolay Oskolkov / Per Unneberg\n\n\n\n11:00 - 12:00\nPopulation genomics of arctic and mountain bumblebees\nMatt Webster\n\n\n\n12:00 - 13:00\nLunch\n\n\n\n\n13:00 - 17:00\nProject discussion / networking / own time\n\n\n\n\n\n\n\n\n   Date    Venue    Slides    Exercises  \n\n\n  AS: André Soares, JH: Jason Hill, NO: Nikolay Oskolkov, PU: Per Unneberg\n\n\n\n\nLast updated on  08-Nov-2023"
  },
  {
    "objectID": "precourse.html",
    "href": "precourse.html",
    "title": "Precourse",
    "section": "",
    "text": "The first sessions consist of lectures that aim to introduce concepts and theory from population genetics\nPopulation genomics in practice provides a quick overview of population genomics. Although not required, it is recommended to briefly go through the following papers that will be discussed in the lecture:\n\n\nFuller et al. (2020) (most important)\nJohri et al. (2022)\n\nPopulation genetics introduces the foundations of population genetics. This lecture contains a lot of material and we strongly recommend you review the slides to be fully prepared for the lecture. See notes on usage for instructions how to view slides."
  },
  {
    "objectID": "precourse.html#suggested-readings",
    "href": "precourse.html#suggested-readings",
    "title": "Precourse",
    "section": "",
    "text": "The first sessions consist of lectures that aim to introduce concepts and theory from population genetics\nPopulation genomics in practice provides a quick overview of population genomics. Although not required, it is recommended to briefly go through the following papers that will be discussed in the lecture:\n\n\nFuller et al. (2020) (most important)\nJohri et al. (2022)\n\nPopulation genetics introduces the foundations of population genetics. This lecture contains a lot of material and we strongly recommend you review the slides to be fully prepared for the lecture. See notes on usage for instructions how to view slides."
  },
  {
    "objectID": "precourse.html#uppmax-account",
    "href": "precourse.html#uppmax-account",
    "title": "Precourse",
    "section": "UPPMAX account",
    "text": "UPPMAX account\nYou will need an uppmax account to run some of the exercises. You can apply for an account here.\nTutorials\nLook at https://www.uppmax.uu.se/support/user-guides/, in particular https://www.uppmax.uu.se/support/user-guides/guide--first-login-to-uppmax/ for information on how to connect to and work on uppmax."
  },
  {
    "objectID": "precourse.html#sec-software-installation",
    "href": "precourse.html#sec-software-installation",
    "title": "Precourse",
    "section": "Software installation",
    "text": "Software installation\nAlthough we will mainly work on UPPMAX, some exercises, notably the ones that utilise Jupyter notebooks benefit from working in a local compute environment on your computer. We will use the conda package manager to install necessary requirements from the package repositories bioconda and conda-forge.\n1. Install conda\nTo start using conda, follow the quick command line install instructions to install the minimal conda installer miniconda.\n2. Configure conda\nConfigure conda to access the package repositories (see also bioconda usage). This will modify your ~/.condarc file:\n\nconda config --add channels defaults\nconda config --add channels bioconda\nconda config --add channels conda-forge\nconda config --set channel_priority strict\n\n\n\n\n\n\n\nImportant\n\n\n\nPlease note that the order of these commands is important! When conda config --add is run it adds the channel to the top of the list in your configuration, so your ~/.condarc will end up looking like this:\ncat ~/.condarc\nchannels:\n  - conda-forge\n  - bioconda\n  - defaults\nchannel_priority: strict\n\n\n3. Create an isolated course environment\nIt is suggested you create and change to a isolated environment pgip dedicated to the course. The command below will create an environment named pgip and install the packages python version 3.10, an R base installation (r-base), the jupyter package that provides support for Jupyter Notebooks, and the mamba package manager.\n\nconda create -n pgip python=3.10 r-base mamba jupyter\nconda activate pgip\n\nThe activate command is required to access the isolated environment named pgip. Once you have activated the environment, you gain access to whatever programs are installed. To deactivate an environment you issue the command conda deactivate.\n4. Install packages\nInstallation of packages is done with the install command, but we recommend you use the mamba package manager as it is faster (mamba is a rewrite of conda in C++). An example of how to install packages bcftools, angsd, mosdepth follows (remember to activate pgip!):\n\n\n\n\n\n\n03-Nov-2023: Package errors\n\n\n\nSome users have reported errors in that bcftools and angsd cannot be found, despite setting the proper channels. We are looking into the issue, but unless there are issues with UPPMAX, we will not need to install any additional packages apart from those that went into the creation of the pgip environment above. You can therefore treat the code below as examples only.\n\n\n#| eval: false\nconda activate pgip\nmamba install bcftools angsd mosdepth\nor if you have packages listed in an environment file\n#| label: conda-install-packages-from-environment-file\n#| echo: true\n#| eval: false\nmamba env update -f environment.yml"
  },
  {
    "objectID": "precourse.html#resources",
    "href": "precourse.html#resources",
    "title": "Precourse",
    "section": "Resources",
    "text": "Resources\nLiterature\nLecture notes have been prepared based on the literature listed below.\nOnline\n\nGraham Coop’s notes on population genetics\n\nComprehensive introduction to population genetics. Contains many biological examples and code snippets. (Graham Coop, 2020).\n\nJoachim Hermisson’s notes on mathematical population genetics\n\nIntroduction to mathematical population genetics (Hermisson, 2017, 2018).\n\nBooks\n\nPopulation Genetics: A Concise Guide\n\nJohn Gillespie’s short but excellent introduction to population genetics (Gillespie, 2004).\n\nMolecular Population Genetics\n\nA more recent introduction to population genetics with more focus on the analyses of sequencing data (Hahn, 2019).\n\nMolecular Evolution and Phylogenetics\n\nOver view of molecular evolution and population genetics, and also phylogenetics (Nei & Kumar, 2000).\n\nMathematical Population Genetics I\n\nA great reference when it comes to the mathematical treatment of population genetics (Ewens, 2004).\n\nPrinciples of Population Genetics\n\nA comprehensive textbook covering most topics of population genetics (Hartl & Clark, 1997).\n\nElements of Evolutionary Genetics\n\nIntroduction to evolutionary genetics (Charlesworth & Charlesworth, 2010).\n\nEvolution\n\nGreat comprehensive textbook covering evolution (Barton et al., 2007).\n\nCoalescent Theory: An Introduction\n\nA great introduction to coalescent theory (Wakeley, 2008).\n\nGene Genealogies, Variation and Evolution: A Primer in Coalescent Theory\n\nAlternative introduction to coalescent with more focus on the Wright-Fisher model (Hein et al., 2005)."
  },
  {
    "objectID": "contents.html",
    "href": "contents.html",
    "title": "Course Materials",
    "section": "",
    "text": "As the focus of the course is on hands-on work, the topics have been designed to cover the fundamental analyses that are common in many population genomics studies. The course consists of lectures and exercises, with a focus on the practical aspects of analyses. Whereas lectures introduce some background theory, their primary aim is to set the stage for accompanying exercises."
  },
  {
    "objectID": "contents.html#sec-manuscript-route",
    "href": "contents.html#sec-manuscript-route",
    "title": "Course Materials",
    "section": "The manuscript route",
    "text": "The manuscript route\nIn principle, you could imagine the course structure to follow that of a manuscript (Fuller et al., 2020)\nHigh-throughput DNA sequencing has now made it possible to generate whole-genome resequencing data for multiple individuals and populations, and a first step is to map sequence data to a reference, perform variant calling and variant filtering.\nOnce a high-quality variant set has been obtained, a common task is to describe variation, either in terms of summary statistics such as nucleotide diversity (\\(\\pi\\)) or site-frequency spectra (sfs), or as descriptions of population structure in terms of admixture or pca plots.\nGenetic diversity is also affected by population history and demographic processes such as population expansion, bottlenecks, migration events and hybridizations.\nFinally, it is often of interest to identify adaptive traits, to which end selection tests and scans can be performed. The tests are designed to detect signals of selection, either via direct selection on loci, or by looking at haplotype structures to detect linked selection."
  },
  {
    "objectID": "contents.html#the-baseline-model",
    "href": "contents.html#the-baseline-model",
    "title": "Course Materials",
    "section": "The baseline model",
    "text": "The baseline model\nMuch of what has been described in The manuscript route has recently been treated in an article on recommendations for improving statistical inference in population genomics (Johri et al., 2022). In it, the authors point out that whereas historically theoretical advances outpaced data production, that is no longer true due to the advent of next-generation sequencing. In particular, they caution researchers to attach too much faith to a test that explains the data well, as there are many alternative hypotheses with equal explanatory power, but with drastically different conclusions. At the very least, a population genomics study should aim at first generating a baseline model consisting of all or several of the following components:\n\nmutation\nrecombination\ngene conversion\npurifying selection acting on functional regions and its effects on linked variants (background selection)\ngenetic drift with demographic history and geographic structure\n\nThe exercises are designed to address many of the points above, and to highlight cases where competing hypotheses may actually explain data to equal degrees."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DDLS Population genomics in practice",
    "section": "",
    "text": "NBIS • Workshop\nDDLS Population genomics in practice\nWelcome to the DDLS Population Genomics in Practice homepage!\nImportant dates and information\nSee the canvas home page for the current course NBIS_POPGENIP_H23 for more information on how to apply.\n\n\n\n\n\nNext round\n06-Nov-2023 - 10-Nov-2023\n\n\nApplication opens\n15-Aug-2023\n\n\nApplication deadline\n30-Sep-2023\n\n\n\n\nBrief contents\n\n\nThis workshop includes the following moments:\n\nVariant calling and filtering\nDescribing and summarising variation data\nPopulation structure\nDemographic analysis\nSelection scans\nCoalescent simulation\n\nSee syllabus for a more complete description of course contents and info for practical information on venue and hotels.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLast updated on  08-Nov-2023"
  },
  {
    "objectID": "info.html",
    "href": "info.html",
    "title": "Practical info",
    "section": "",
    "text": "This workshop is organised by the National Bioinformatics Infrastructure, Sweden (NBIS) and sponsored by the Science for Life Laboratory (SciLifeLab) & Wallenberg National Program for Data-Driven Life Science (DDLS). NBIS is a platform of the Science for Life Laboratory (SciLifeLab).\nIf you would like to get in touch with us regarding this workshop, please contact us at edu.population-genomics-in-practice [at] nbis.se or edu.pgip [at] nbis.se."
  },
  {
    "objectID": "info.html#organizers",
    "href": "info.html#organizers",
    "title": "Practical info",
    "section": "Organizers",
    "text": "Organizers\n\n\n\n\n\n\nPer Unneberg\n\n\n\n\n\n\nNikolay Oskolkov\n\n\n\n\n\n\nJason Hill\n\n\n\n\n\n\nAndré Soares"
  },
  {
    "objectID": "info.html#venue",
    "href": "info.html#venue",
    "title": "Practical info",
    "section": "Venue",
    "text": "Venue\nThe workshop is held onsite in Trippelrummet in Navet at the Uppsala Biomedical Centre, Uppsala.\n\nLocation\n\n\nUppsala\n\n\n\n\nRoom E10:1309 Entrance C11 Biomedicinskt centrum Uppsala University / ScilifeLab Husargatan 3 75237 Uppsala Sweden\nSome selected hotels are listed below ranked by distance from the venue.\n\n\nHotel von Kraemer (900 m, 11 min walk)\n\nAkademihotellet (1.7 Km, 21 min walk)\n\nCityStay Hotell (1.8 Km, 21 min walk)\n\nGrand Hotel Hörnan (1.9 Km, 23 min walk)\n\nHotell Centralstation (2.1 Km, 25 min walk)\n\nBest Western Svava (2.2 Km, 26 min walk)\n\nThe venue and hotels are also marked on the map.\nUse the UL website or the UL app for bus and train services around Uppsala. For buses from the Centralstation (Train/Bus), take Bus 4 (towards Gottsunda Centrum) or 8 (towards Sunnersta) and get off at the stop Uppsala Science Park. Bus tickets can be purchased in the app or directly from the driver using a credit card."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "References\n\n\nA genome atlas of european biodiversity. (n.d.). https://www.erga-biodiversity.eu. Retrieved November 3, 2022, from https://www.erga-biodiversity.eu\n\n\nAdrion, J. R., Galloway, J. G., & Kern, A. D. (2020). Predicting the Landscape of Recombination Using Deep Learning. Molecular Biology and Evolution, 37(6), 1790–1808. https://doi.org/10.1093/molbev/msaa038\n\n\nAllendorf, F. W., Funk, W. C., Aitken, S. N., Byrne, M., & Luikart, G. (2022). Population Genomics. In F. W. Allendorf, W. C. Funk, S. N. Aitken, M. Byrne, G. Luikart, & A. Antunes (Eds.), Conservation and the Genomics of Populations (p. 0). Oxford University Press. https://doi.org/10.1093/oso/9780198856566.003.0004\n\n\nAllendorf, F. W., Hohenlohe, P. A., & Luikart, G. (2010). Genomics and the future of conservation genetics. Nature Reviews Genetics, 11(10), 697–709. https://doi.org/10.1038/nrg2844\n\n\nBaird, N. A., Etter, P. D., Atwood, T. S., Currey, M. C., Shiver, A. L., Lewis, Z. A., Selker, E. U., Cresko, W. A., & Johnson, E. A. (2008). Rapid SNP Discovery and Genetic Mapping Using Sequenced RAD Markers. PLOS ONE, 3(10), e3376. https://doi.org/10.1371/journal.pone.0003376\n\n\nBarrera-Redondo, J., Piñero, D., & Eguiarte, L. E. (2020). Genomic, Transcriptomic and Epigenomic Tools to Study the Domestication of Plants and Animals: A Field Guide for Beginners. Frontiers in Genetics, 11.\n\n\nBarton, N. H., Briggs, D. E. G., Eisen, J. A., Goldstein, D. B., & Patel, N. H. (2007). Evolution. Cold Spring Harbor Laboratory Press.\n\n\nBaumdicker, F., Bisschop, G., Goldstein, D., Gower, G., Ragsdale, A. P., Tsambos, G., Zhu, S., Eldon, B., Ellerman, E. C., Galloway, J. G., Gladstein, A. L., Gorjanc, G., Guo, B., Jeffery, B., Kretzschumar, W. W., Lohse, K., Matschiner, M., Nelson, D., Pope, N. S., … Kelleher, J. (2022). Efficient ancestry and mutation simulation with msprime 1.0. Genetics, 220(3), iyab229. https://doi.org/10.1093/genetics/iyab229\n\n\nBegun, D. J., Holloway, A. K., Stevens, K., Hillier, L. W., Poh, Y.-P., Hahn, M. W., Nista, P. M., Jones, C. D., Kern, A. D., Dewey, C. N., Pachter, L., Myers, E., & Langley, C. H. (2007). Population Genomics: Whole-Genome Analysis of Polymorphism and Divergence in Drosophila simulans. PLOS Biology, 5(11), e310. https://doi.org/10.1371/journal.pbio.0050310\n\n\nBergeron, L. A., Besenbacher, S., Zheng, J., Li, P., Bertelsen, M. F., Quintard, B., Hoffman, J. I., Li, Z., St. Leger, J., Shao, C., Stiller, J., Gilbert, M. T. P., Schierup, M. H., & Zhang, G. (2023). Evolution of the germline mutation rate across vertebrates. Nature, 615(7951), 285–291. https://doi.org/10.1038/s41586-023-05752-y\n\n\nBerner, D. (2019). Allele Frequency Difference AFD to FST for Quantifying Genetic Population Differentiation. Genes, 10(4), 308. https://doi.org/10.3390/genes10040308\n\n\nBhatia, G., Patterson, N., Sankararaman, S., & Price, A. L. (2013). Estimating and interpreting FST: The impact of rare variants. Genome Research, 23(9), 1514–1521. https://doi.org/10.1101/gr.154831.113\n\n\nBuri, P. (1956). Gene Frequency in Small Populations of Mutant Drosophila. Evolution, 10(4), 367–402. https://doi.org/10.1111/j.1558-5646.1956.tb02864.x\n\n\nBurri, R. (2017a). Dissecting differentiation landscapes: A linked selection’s perspective. Journal of Evolutionary Biology, 30(8), 1501–1505. https://doi.org/10.1111/jeb.13108\n\n\nBurri, R. (2017b). Interpreting differentiation landscapes in the light of long-term linked selection. Evolution Letters, 1(3), 118–131. https://doi.org/10.1002/evl3.14\n\n\nCasillas, S., & Barbadilla, A. (2017). Molecular Population Genetics. Genetics, 205(3), 1003–1035. https://doi.org/10.1534/genetics.116.196493\n\n\nChan, A. H., Jenkins, P. A., & Song, Y. S. (2012). Genome-Wide Fine-Scale Recombination Rate Variation in Drosophila melanogaster. PLOS Genetics, 8(12), e1003090. https://doi.org/10.1371/journal.pgen.1003090\n\n\nChang, C. C. (2020). Data Management and Summary Statistics with PLINK. In J. Y. Dutheil (Ed.), Statistical Population Genomics (pp. 49–65). Springer US. https://doi.org/10.1007/978-1-0716-0199-0_3\n\n\nCharlesworth, B., & Charlesworth, D. (2010). Elements of Evolutionary Genetics. Roberts and Company Publishers.\n\n\nCharlesworth, B., & Jensen, J. D. (2021). Effects of selection at linked sites on patterns of genetic variability. Annual Review of Ecology, Evolution, and Systematics, 52(1), 177–197. https://doi.org/10.1146/annurev-ecolsys-010621-044528\n\n\nCharlesworth, B., & Jensen, J. D. (2022). How Can We Resolve Lewontin’s Paradox? Genome Biology and Evolution, 14(7), evac096. https://doi.org/10.1093/gbe/evac096\n\n\nCharlesworth, B., Morgan, M. T., & Charlesworth, D. (1993). The Effect of Deleterious Mutations on Neutral Molecular Variation. Genetics, 134(4), 1289–1303.\n\n\ncooplab. (2011). Population genetics course resources: Hardy-Weinberg Eq. In gcbias. https://gcbias.org/2011/10/13/population-genetics-course-resources-hardy-weinberg-eq/\n\n\nCorbett-Detig, R. B., Hartl, D. L., & Sackton, T. B. (2015). Natural Selection Constrains Neutral Diversity across A Wide Range of Species. PLOS Biology, 13(4), e1002112. https://doi.org/10.1371/journal.pbio.1002112\n\n\nD. Lawson, S. M., G. Hellenthal. (2012). Inference of population structure using dense haplotype data. PLoS Genet. 8(1):e1002453. https://doi.org/doi: 10.1371/journal.pgen.1002453\n\n\nDanecek, P., Auton, A., Abecasis, G., Albers, C. A., Banks, E., DePristo, M. A., Handsaker, R. E., Lunter, G., Marth, G. T., Sherry, S. T., McVean, G., & Durbin, R. (2011). The variant call format and VCFtools. Bioinformatics (Oxford, England), 27(15), 2156–2158. https://doi.org/10.1093/bioinformatics/btr330\n\n\nDanecek, P., Bonfield, J. K., Liddle, J., Marshall, J., Ohan, V., Pollard, M. O., Whitwham, A., Keane, T., McCarthy, S. A., Davies, R. M., & Li, H. (2021). Twelve years of SAMtools and BCFtools. GigaScience, 10(2), giab008. https://doi.org/10.1093/gigascience/giab008\n\n\nDavey, J. W., & Blaxter, M. L. (2010). RADSeq: Next-generation population genetics. Briefings in Functional Genomics, 9(5-6), 416–423. https://doi.org/10.1093/bfgp/elq031\n\n\nDavydov, E. V., Goode, D. L., Sirota, M., Cooper, G. M., Sidow, A., & Batzoglou, S. (2010). Identifying a High Fraction of the Human Genome to be under Selective Constraint Using GERP++. PLOS Computational Biology, 6(12), e1001025. https://doi.org/10.1371/journal.pcbi.1001025\n\n\nDeGiorgio, M., Huber, C. D., Hubisz, M. J., Hellmann, I., & Nielsen, R. (2016). SweepFinder2: Increased sensitivity, robustness and flexibility. Bioinformatics, 32(12), 1895–1897. https://doi.org/10.1093/bioinformatics/btw051\n\n\nDePristo, M. A., Banks, E., Poplin, R., Garimella, K. V., Maguire, J. R., Hartl, C., Philippakis, A. A., del Angel, G., Rivas, M. A., Hanna, M., McKenna, A., Fennell, T. J., Kernytsky, A. M., Sivachenko, A. Y., Cibulskis, K., Gabriel, S. B., Altshuler, D., & Daly, M. J. (2011). A framework for variation discovery and genotyping using next-generation DNA sequencing data. Nature Genetics, 43(5), 491–498. https://doi.org/10.1038/ng.806\n\n\nDes Roches, S., Pendleton, L. H., Shapiro, B., & Palkovacs, E. P. (2021). Conserving intraspecific variation for nature’s contributions to people. Nature Ecology & Evolution, 5(5), 574–582. https://doi.org/10.1038/s41559-021-01403-5\n\n\nDonato, L., Scimone, C., Rinaldi, C., D’Angelo, R., & Sidoti, A. (2021). New evaluation methods of read mapping by 17 aligners on simulated and empirical NGS data: An updated comparison of DNA- and RNA-Seq data from Illumina and Ion Torrent technologies. Neural Computing and Applications, 33(22), 15669–15692. https://doi.org/10.1007/s00521-021-06188-z\n\n\nDutheil, Julien (Ed.). (2020). Statistical Population Genomics.\n\n\nEllegren, H., & Galtier, N. (2016). Determinants of genetic diversity. Nature Reviews Genetics, 17(7), 422–433. https://doi.org/10.1038/nrg.2016.58\n\n\nEwels, P., Magnusson, M., Lundin, S., & Käller, M. (2016). MultiQC: Summarize analysis results for multiple tools and samples in a single report. Bioinformatics, 32(19), 3047–3048. https://doi.org/10.1093/bioinformatics/btw354\n\n\nEwens, W. J. (2004). Mathematical Population Genetics (S. S. Antman, J. E. Marsden, L. Sirovich, & S. Wiggins, Eds.; Vol. 27). Springer. https://doi.org/10.1007/978-0-387-21822-9\n\n\nExcoffier, L. (2004). Analysis of Population Subdivision. In Handbook of Statistical Genetics. John Wiley & Sons, Ltd. https://doi.org/10.1002/0470022620.bbc25\n\n\nFerretti, L., Ledda, A., Wiehe, T., Achaz, G., & Ramos-Onsins, S. E. (2017). Decomposing the Site Frequency Spectrum: The Impact of Tree Topology on Neutrality Tests. Genetics, 207(1), 229–240. https://doi.org/10.1534/genetics.116.188763\n\n\nFitzpatrick, M. C., & Keller, S. R. (2015). Ecological genomics meets community-level modelling of biodiversity: Mapping the genomic landscape of current and future environmental adaptation. Ecology Letters, 18(1), 1–16. https://doi.org/10.1111/ele.12376\n\n\nFoll, M., & Gaggiotti, O. (2008). A Genome-Scan Method to Identify Selected Loci Appropriate for Both Dominant and Codominant Markers: A Bayesian Perspective. Genetics, 180(2), 977–993. https://doi.org/10.1534/genetics.108.092221\n\n\nFormenti, G., Theissinger, K., Fernandes, C., Bista, I., Bombarely, A., Bleidorn, C., Ciofi, C., Crottini, A., Godoy, J. A., Höglund, J., Malukiewicz, J., Mouton, A., Oomen, R. A., Paez, S., Palsbøll, P. J., Pampoulie, C., Ruiz-López, M. J., Svardal, H., Theofanopoulou, C., … Zammit, G. (2022). The era of reference genomes in conservation genomics. Trends in Ecology & Evolution, 37(3), 197–202. https://doi.org/10.1016/j.tree.2021.11.008\n\n\nFuller, Z. L., Mocellin, V. J. L., Morris, L. A., Cantin, N., Shepherd, J., Sarre, L., Peng, J., Liao, Y., Pickrell, J., Andolfatto, P., Matz, M., Bay, L. K., & Przeworski, M. (2020). Population genetics of the coral Acropora millepora: Toward genomic prediction of bleaching. Science, 369(6501), eaba4674. https://doi.org/10.1126/science.aba4674\n\n\nGarcía-Dorado, A., & Caballero, A. (2021). Neutral genetic diversity as a useful tool for conservation biology. Conservation Genetics, 22(4), 541–545. https://doi.org/10.1007/s10592-021-01384-9\n\n\nGarrison, E., Kronenberg, Z. N., Dawson, E. T., Pedersen, B. S., & Prins, P. (2022). A spectrum of free software tools for processing the VCF variant call format: Vcflib, bio-vcf, Cyvcf2, hts-nim and slivar. PLOS Computational Biology, 18(5), e1009123. https://doi.org/10.1371/journal.pcbi.1009123\n\n\nGarrison, E., & Marth, G. (2012). Haplotype-based variant detection from short-read sequencing. arXiv:1207.3907 [q-Bio]. http://arxiv.org/abs/1207.3907\n\n\nGillespie, J. H. (2004). Population Genetics: A Concise Guide (2nd edition). Johns Hopkins University Press.\n\n\nGraham Coop. (2020). Notes on Population Genetics. https://github.com/cooplab/popgen-notes\n\n\nGutenkunst, R. N., Hernandez, R. D., Williamson, S. H., & Bustamante, C. D. (2009). Inferring the joint demographic history of multiple populations from multidimensional SNP frequency data. PLoS Genetics, 5(10), e1000695. https://doi.org/10.1371/journal.pgen.1000695\n\n\nHahn, M. (2019). Molecular Population Genetics (First). Oxford University Press.\n\n\nHaller, B. C., & Messer, P. W. (2019). SLiM 3: Forward Genetic Simulations Beyond the Wright. Molecular Biology and Evolution, 36(3), 632–637. https://doi.org/10.1093/molbev/msy228\n\n\nHaller, B. C., & Messer, P. W. (2022). SLiM: An Evolutionary Simulation Framework.\n\n\nHaller, Ben. (2016). Messer Lab SLiM. In Messer Lab. https://messerlab.org/slim/\n\n\nHansen, N. F. (2016). Variant Calling From Next Generation Sequence Data. In E. Mathé & S. Davis (Eds.), Statistical Genomics: Methods and Protocols (pp. 209–224). Springer. https://doi.org/10.1007/978-1-4939-3578-9_11\n\n\nHartl, D. L., & Clark, A. G. (1997). Principles of population genetics. Sinauer Associates.\n\n\nHein, J., Schierup, M. H., & Wiuf, C. (2005). Gene genealogies, variation and evolution: A primer in coalescent theory. Oxford University Press. https://books.google.se/books?id=CCmLNAEACAAJ\n\n\nHein, J., Schierup, M., & Wiuf, C. (2004). Gene genealogies, variation and evolution. A primer in coalescent theory. In Systematic Biology - SYST BIOL (Vol. 54).\n\n\nHermisson, J. (2017). Mathematical population genetics. https://www.mabs.at/fileadmin/user_upload/p_mabs/Lecture_Notes_2017\n\n\nHermisson, J. (2018). Mathematical population genetics II. https://www.mabs.at/fileadmin/user_upload/p_mabs/Lecture_Notes_2018\n\n\nHohenlohe, P. A., Hand, B. K., Andrews, K. R., & Luikart, G. (2019). Population Genomics Provides Key Insights in Ecology and Evolution. In O. P. Rajora (Ed.), Population Genomics: Concepts, Approaches and Applications (pp. 483–510). Springer International Publishing. https://doi.org/10.1007/13836_2018_20\n\n\nHou, H., Pedersen, B., & Quinlan, A. (2021). Balancing efficient analysis and storage of quantitative genomics data with the D4 format and D4tools. Nature Computational Science, 1(6), 441–447. https://doi.org/10.1038/s43588-021-00085-0\n\n\nHTS format specifications. (2023). https://samtools.github.io/hts-specs/\n\n\nHubisz, M., & Siepel, A. (2020). Inference of Ancestral Recombination Graphs Using ARGweaver. In J. Y. Dutheil (Ed.), Statistical Population Genomics (pp. 231–266). Springer US. https://doi.org/10.1007/978-1-0716-0199-0_10\n\n\nHurst, L. D. (2002). The Ka/Ks ratio: Diagnosing the form of sequence evolution. Trends in Genetics, 18(9), 486–487. https://doi.org/10.1016/S0168-9525(02)02722-1\n\n\nHurst, L. D. (2009). Genetics and the understanding of selection. Nature Reviews Genetics, 10(2), 83–93. https://doi.org/10.1038/nrg2506\n\n\nJohri, P., Aquadro, C. F., Beaumont, M., Charlesworth, B., Excoffier, L., Eyre-Walker, A., Keightley, P. D., Lynch, M., McVean, G., Payseur, B. A., Pfeifer, S. P., Stephan, W., & Jensen, J. D. (2022). Recommendations for improving statistical inference in population genomics. PLOS Biology, 20(5), e3001669. https://doi.org/10.1371/journal.pbio.3001669\n\n\nKelleher, J., Wong, Y., Wohns, A. W., Fadil, C., Albers, P. K., & McVean, G. (2019). Inferring whole-genome histories in large population datasets. Nature Genetics, 51(9), 1330–1338. https://doi.org/10.1038/s41588-019-0483-y\n\n\nKimura, M. (1983). The neutral theory of molecular evolution. Cambridge University Press. https://doi.org/10.1017/CBO9780511623486\n\n\nKimura, M., & Ohta, T. (1971). Protein Polymorphism as a Phase of Molecular Evolution. Nature, 229(5285), 467–469. https://doi.org/10.1038/229467a0\n\n\nKorneliussen T, N. R., Albrechtsen A. (2014). ANGSD: Analysis of next generation sequencing data. BMC Bioinformatics 15(1):356. https://doi.org/doi: 10.1186/s12859-014-0356-4\n\n\nKorneliussen, T. S., Albrechtsen, A., & Nielsen, R. (2014). ANGSD: Analysis of Next Generation Sequencing Data. BMC Bioinformatics, 15(1), 356. https://doi.org/10.1186/s12859-014-0356-4\n\n\nKorunes, K. L., & Samuk, K. (2021). Pixy: Unbiased estimation of nucleotide diversity and divergence in the presence of missing data. Molecular Ecology Resources, 21(4), 1359–1368. https://doi.org/10.1111/1755-0998.13326\n\n\nKreitman, M. (1983). Nucleotide polymorphism at the alcohol dehydrogenase locus of Drosophila melanogaster. Nature, 304(5925), 412. https://doi.org/10.1038/304412a0\n\n\nKuderna, L. F. K., Gao, H., Janiak, M. C., Kuhlwilm, M., Orkin, J. D., Bataillon, T., Manu, S., Valenzuela, A., Bergman, J., Rousselle, M., Silva, F. E., Agueda, L., Blanc, J., Gut, M., de Vries, D., Goodhead, I., Harris, R. A., Raveendran, M., Jensen, A., … Marques Bonet, T. (2023). A global catalog of whole-genome diversity from 233 primate species. Science, 380(6648), 906–913. https://doi.org/10.1126/science.abn7829\n\n\nKumar, P., Henikoff, S., & Ng, P. C. (2009). Predicting the effects of coding non-synonymous variants on protein function using the SIFT algorithm. Nature Protocols, 4(7), 1073–1081. https://doi.org/10.1038/nprot.2009.86\n\n\nKumar, S., & Subramanian, S. (2002). Mutation rates in mammalian genomes. Proceedings of the National Academy of Sciences, 99(2), 803–808. https://doi.org/10.1073/pnas.022629899\n\n\nLan, T., & Lindqvist, C. (2019). Paleogenomics: Genome-Scale Analysis of Ancient DNA and Population and Evolutionary Genomic Inferences. In O. P. Rajora (Ed.), Population Genomics: Concepts, Approaches and Applications (pp. 323–360). Springer International Publishing. https://doi.org/10.1007/13836_2017_7\n\n\nLaurie, C. C., Nickerson, D. A., Anderson, A. D., Weir, B. S., Livingston, R. J., Dean, M. D., Smith, K. L., Schadt, E. E., & Nachman, M. W. (2007). Linkage Disequilibrium in Wild Mice. PLOS Genetics, 3(8), e144. https://doi.org/10.1371/journal.pgen.0030144\n\n\nLawson DJ, F. D., van Dorp L. (2018). A tutorial on how not to over-interpret STRUCTURE and ADMIXTURE bar plots. Nat Commun. 14;9(1):3258. https://doi.org/doi: 10.1038/s41467-018-05257-7\n\n\nLeffler, E. M., Bullaughey, K., Matute, D. R., Meyer, W. K., Ségurel, L., Venkat, A., Andolfatto, P., & Przeworski, M. (2012). Revisiting an Old Riddle: What Determines Genetic Diversity Levels within Species? PLOS Biology, 10(9), e1001388. https://doi.org/10.1371/journal.pbio.1001388\n\n\nLewis, D. (2023). Biggest ever study of primate genomes has surprises for humanity. Nature. https://doi.org/10.1038/d41586-023-01776-6\n\n\nLi, H. (2013). Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM. arXiv:1303.3997 [q-Bio]. https://arxiv.org/abs/1303.3997\n\n\nLi, H. (2014). Toward better understanding of artifacts in variant calling from high-coverage samples. Bioinformatics, 30(20), 2843–2851. https://doi.org/10.1093/bioinformatics/btu356\n\n\nLi, H. (2018). Minimap2: Pairwise alignment for nucleotide sequences. Bioinformatics, 34(18), 3094–3100. https://doi.org/10.1093/bioinformatics/bty191\n\n\nLi, H., & Durbin, R. (2011). Inference of human population history from individual whole-genome sequences. Nature, 475(7357), 493–496. https://doi.org/10.1038/nature10231\n\n\nLi, R., Li, Y., Fang, X., Yang, H., Wang, J., Kristiansen, K., & Wang, J. (2009). SNP detection for massively parallel whole-genome resequencing. Genome Research, 19(6), 1124–1132. https://doi.org/10.1101/gr.088013.108\n\n\nLipson, M. (2020). Applying F4-statistics and admixture graphs: Theory and examples. Molecular Ecology Resources, 20(6), 1658–1667. https://doi.org/10.1111/1755-0998.13230\n\n\nLiu, C.-C., Shringarpure, S., Lange, K., & Novembre, J. (2020). Exploring Population Structure with Admixture Models and Principal Component Analysis. In J. Y. Dutheil (Ed.), Statistical Population Genomics (pp. 67–86). Springer US. https://doi.org/10.1007/978-1-0716-0199-0_4\n\n\nLou, R. N., Jacobs, A., Wilder, A. P., & Therkildsen, N. O. (2021). A beginner’s guide to low-coverage whole genome sequencing for population genomics. Molecular Ecology, 30(23), 5966–5993. https://doi.org/10.1111/mec.16077\n\n\nLuu, K., Bazin, E., & Blum, M. G. B. (2017). Pcadapt: An R package to perform genome scans for selection based on principal component analysis. Molecular Ecology Resources, 17(1), 67–77. https://doi.org/10.1111/1755-0998.12592\n\n\nLynch, M. (2007). The origins of genome architecture. Sinauer Associates.\n\n\nMaier, R., Flegontov, P., Flegontova, O., Changmai, P., & Reich, D. (2022). On the limits of fitting complex models of population history to genetic data (p. 2022.05.08.491072). bioRxiv. https://doi.org/10.1101/2022.05.08.491072\n\n\nMaier, Robert. (2022). Paper notes. https://uqrmaie1.github.io/admixtools/articles/paper.html\n\n\nMaruki, T., & Lynch, M. (2017). Genotype Calling from Population-Genomic Sequencing Data. G3 Genes|Genomes|Genetics, 7(5), 1393–1404. https://doi.org/10.1534/g3.117.039008\n\n\nMary-Huard, T., & Balding, D. (2023). Fast and accurate joint inference of coancestry parameters for populations and/or individuals. PLOS Genetics, 19(1), e1010054. https://doi.org/10.1371/journal.pgen.1010054\n\n\nMcLaren, W., Gil, L., Hunt, S. E., Riat, H. S., Ritchie, G. R. S., Thormann, A., Flicek, P., & Cunningham, F. (2016). The Ensembl Variant Effect Predictor. Genome Biology, 17(1), 122. https://doi.org/10.1186/s13059-016-0974-4\n\n\nMcLaren, W., Pritchard, B., Rios, D., Chen, Y., Flicek, P., & Cunningham, F. (2010). Deriving the consequences of genomic variants with the Ensembl API and SNP Effect Predictor. Bioinformatics, 26(16), 2069–2070. https://doi.org/10.1093/bioinformatics/btq330\n\n\nMcVean. (2009). A genealogical interpretation of principal components analysis. PLoS Genetics Oct;5(10):e1000686. https://doi.org/doi: 10.1371/journal.pgen.1000686\n\n\nMenozzi P, C.-S. L., Piazza A. (1978). Synthetic maps of human gene frequencies in europeans. Science 1;201(4358):786-92. https://doi.org/doi: 10.1126/science.356262\n\n\nMiller, C. (2020). Human Biology. Thompson Rivers University.\n\n\nNazareno, A. G., & Knowles, L. L. (2021). There Is No “Rule of Thumb”: Genomic Filter Settings for a Small Plant Population to Obtain Unbiased Gene Flow Estimates. Frontiers in Plant Science, 12. https://www.frontiersin.org/articles/10.3389/fpls.2021.677009\n\n\nNei, M. (1973). Analysis of Gene Diversity in Subdivided Populations. Proceedings of the National Academy of Sciences, 70(12), 3321–3323. https://doi.org/10.1073/pnas.70.12.3321\n\n\nNei, M., & Kumar, S. (2000). Molecular Evolution and Phylogenetics. Oxford University Press.\n\n\nNielsen, R. (2005). Molecular Signatures of Natural Selection. Annual Review of Genetics, 39(1), 197–218. https://doi.org/10.1146/annurev.genet.39.073003.112420\n\n\nNielsen, R., Korneliussen, T., Albrechtsen, A., Li, Y., & Wang, J. (2012). SNP Calling, Genotype Calling, and Sample Allele Frequency Estimation from New-Generation Sequencing Data. PLOS ONE, 7(7), e37558. https://doi.org/10.1371/journal.pone.0037558\n\n\nNielsen, R., Paul, J. S., Albrechtsen, A., & Song, Y. S. (2011). Genotype and SNP calling from next-generation sequencing data. Nature Reviews Genetics, 12(6), 443–451. https://doi.org/10.1038/nrg2986\n\n\nNovembre J, B. K., Johnson T. (2008). Genes mirror geography within europe. Nature. 2008 Nov 6;456(7218):98-101. https://doi.org/doi: 10.1038/nature07331\n\n\nOhta, T. (1973). Slightly Deleterious Mutant Substitutions in Evolution. Nature, 246(5428), 96. https://doi.org/10.1038/246096a0\n\n\nOkonechnikov, K., Conesa, A., & García-Alcalde, F. (2016). Qualimap 2: Advanced multi-sample quality control for high-throughput sequencing data. Bioinformatics, 32(2), 292–294. https://doi.org/10.1093/bioinformatics/btv566\n\n\nPatterson, N., Price, A. L., & Reich, D. (2006). Population Structure and Eigenanalysis. PLOS Genetics, 2(12), e190. https://doi.org/10.1371/journal.pgen.0020190\n\n\nPedersen, B. S., & Quinlan, A. R. (2018). Mosdepth: Quick coverage calculation for genomes and exomes. Bioinformatics, 34(5), 867–868. https://doi.org/10.1093/bioinformatics/btx699\n\n\nPennisi, E. (2019). The allure of monkeyflowers. Science, 365(6456), 854–857. https://doi.org/10.1126/science.365.6456.854\n\n\nPeter, B. (2016). Admixture, population structure, and f-statistics. Genetics 202(4):1485-501. https://doi.org/doi: 10.1534/genetics.115.183913\n\n\nPeter, B. (2022). A geometric relationship of F2, F3 and F4-statistics with principal component analysis. Philos Trans R Soc Lond B Biol Sci. 377(1852):20200413. https://doi.org/doi: 10.1098/rstb.2020.0413\n\n\nPeter, B. M. (2016). Admixture, Population Structure, and F-Statistics. Genetics, 202(4), 1485–1501. https://doi.org/10.1534/genetics.115.183913\n\n\nPicard toolkit. (2019). In Broad Institute, GitHub repository. https://broadinstitute.github.io/picard/; Broad Institute.\n\n\nPope, N. S., Singh, A., Childers, A. K., Kapheim, K. M., Evans, J. D., & López-Uribe, M. M. (2023). The expansion of agriculture has shaped the recent evolutionary history of a specialized squash pollinator. Proceedings of the National Academy of Sciences, 120(15), e2208116120. https://doi.org/10.1073/pnas.2208116120\n\n\nPurcell, S., Neale, B., Todd-Brown, K., Thomas, L., Ferreira, M. A. R., Bender, D., Maller, J., Sklar, P., de Bakker, P. I. W., Daly, M. J., & Sham, P. C. (2007). PLINK: A Tool Set for Whole-Genome Association and Population-Based Linkage Analyses. The American Journal of Human Genetics, 81(3), 559–575. https://doi.org/10.1086/519795\n\n\nQuinlan, A. R., & Hall, I. M. (2010). BEDTools: A flexible suite of utilities for comparing genomic features. Bioinformatics, 26(6), 841–842. https://doi.org/10.1093/bioinformatics/btq033\n\n\nRead groups. (2023). In GATK. https://gatk.broadinstitute.org/hc/en-us/articles/360035890671-Read-groups\n\n\nReinert, K., Langmead, B., Weese, D., & Evers, D. J. (2015). Alignment of Next-Generation Sequencing Reads. Annual Review of Genomics and Human Genetics, 16(1), 133–151. https://doi.org/10.1146/annurev-genom-090413-025358\n\n\nRodrigues, M. F., Kern, A. D., & Ralph, P. L. (2023). Shared evolutionary processes shape landscapes of genomic variation in the great apes (p. 2023.02.07.527547). bioRxiv. https://doi.org/10.1101/2023.02.07.527547\n\n\nRomiguier, J., Gayral, P., Ballenghien, M., Bernard, A., Cahais, V., Chenuil, A., Chiari, Y., Dernat, R., Duret, L., Faivre, N., Loire, E., Lourenco, J. M., Nabholz, B., Roux, C., Tsagkogeorga, G., Weber, A. a.-T., Weinert, L. A., Belkhir, K., Bierne, N., … Galtier, N. (2014). Comparative population genomics in animals uncovers the determinants of genetic diversity. Nature, 515(7526), 261–263. https://doi.org/10.1038/nature13685\n\n\nSchlötterer, C., Tobler, R., Kofler, R., & Nolte, V. (2014). Sequencing pools of individuals - mining genome-wide polymorphism data without big funding. Nature Reviews. Genetics, 15(11), 749–763. https://doi.org/10.1038/nrg3803\n\n\nSchraiber, J., & Akey, J. (2015). Methods and models for unravelling human evolutionary history. Nat Rev Genet. 16(12):727-40. https://doi.org/doi: 10.1038/nrg4005\n\n\nShen, W., Le, S., Li, Y., & Hu, F. (2016). SeqKit: A Cross-Platform and Ultrafast Toolkit for FASTA/Q File Manipulation. PLOS ONE, 11(10), e0163962. https://doi.org/10.1371/journal.pone.0163962\n\n\nSmith, J. M., & Haigh, J. (1974). The hitch-hiking effect of a favourable gene. Genetics Research, 23(1), 23–35. https://doi.org/10.1017/S0016672300014634\n\n\nStankowski, S., Chase, M. A., Fuiten, A. M., Rodrigues, M. F., Ralph, P. L., & Streisfeld, M. A. (2019). Widespread selection and gene flow shape the genomic landscape during a radiation of monkeyflowers. PLOS Biology, 17(7), e3000391. https://doi.org/10.1371/journal.pbio.3000391\n\n\nStoler, N., & Nekrutenko, A. (2021). Sequencing error profiles of Illumina sequencing instruments. NAR Genomics and Bioinformatics, 3(1), lqab019. https://doi.org/10.1093/nargab/lqab019\n\n\nStorz, J. F. (2005). INVITED REVIEW: Using genome scans of DNA polymorphism to infer adaptive population divergence. Molecular Ecology, 14(3), 671–688. https://doi.org/10.1111/j.1365-294X.2005.02437.x\n\n\nTalla, V., Soler, L., Kawakami, T., Dincă, V., Vila, R., Friberg, M., Wiklund, C., & Backström, N. (2019). Dissecting the Effects of Selection and Mutation on Genetic Diversity in Three Wood White (Leptidea) Butterfly Species. Genome Biology and Evolution, 11(10), 2875–2886. https://doi.org/10.1093/gbe/evz212\n\n\nTool Documentation Index. (2023). In GATK. https://gatk.broadinstitute.org/hc/en-us/articles/13832655155099--Tool-Documentation-Index\n\n\nvan der Valk, T., Pečnerová, P., Díez-del-Molino, D., Bergström, A., Oppenheimer, J., Hartmann, S., Xenikoudakis, G., Thomas, J. A., Dehasque, M., Sağlıcan, E., Fidan, F. R., Barnes, I., Liu, S., Somel, M., Heintzman, P. D., Nikolskiy, P., Shapiro, B., Skoglund, P., Hofreiter, M., … Dalén, L. (2021). Million-year-old DNA sheds light on the genomic history of mammoths. Nature, 591(7849), 265–269. https://doi.org/10.1038/s41586-021-03224-9\n\n\nVertebrate Genomes Project. (n.d.). https://vertebrategenomesproject.org. Retrieved November 3, 2022, from https://vertebrategenomesproject.org\n\n\nWakeley, J. (2008). Coalescent Theory: An Introduction (1st Edition edition). Roberts and Company Publishers.\n\n\nWaples, R. S. (2022). What Is Ne, Anyway? Journal of Heredity, 113(4), 371–379. https://doi.org/10.1093/jhered/esac023\n\n\nWebster, M. T., Beaurepaire, A., Neumann, P., & Stolle, E. (2023). Population Genomics for Insect Conservation. Annual Review of Animal Biosciences, 11(1), 115–140. https://doi.org/10.1146/annurev-animal-122221-075025\n\n\nWebster, Matthew, & Yuanzhen Liu. (2022). Genetic Variation in Mountain Bumblebees.\n\n\nWetterstrand, KA. DNA Sequencing Costs: Data from the NHGRI Genome Sequencing Program (GSP). www.genome.gov/sequencingcostsdata\n\n\nWilli, Y., Kristensen, T. N., Sgrò, C. M., Weeks, A. R., Ørsted, M., & Hoffmann, A. A. (2022). Conservation genetics as a management tool: The five best-supported paradigms to assist the management of threatened species. Proceedings of the National Academy of Sciences, 119(1), e2105076119. https://doi.org/10.1073/pnas.2105076119\n\n\nWisely, S. M., Buskirk, S. W., Fleming, M. A., McDonald, D. B., & Ostrander, E. A. (2002). Genetic Diversity and Fitness in Black-Footed Ferrets Before and During a Bottleneck. Journal of Heredity, 93(4), 231–237. https://doi.org/10.1093/jhered/93.4.231\n\n\nWright, S. (1931). Evolution in Mendelian Populations. Genetics, 16(2), 97–159. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1201091/\n\n\nY. C. Brandt, D., Wei, X., Deng, Y., Vaughn, A. H., & Nielsen, R. (2022). Evaluation of methods for estimating coalescence times using ancestral recombination graphs. Genetics, iyac044. https://doi.org/10.1093/genetics/iyac044"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "The aim of this workshop is to provide an introduction to commonly used methods in population genomics. As the focus of the course is on hands-on work, the topics have been designed to cover the fundamental analyses that are common in many population genomics studies. The course consists of lectures and exercises, with a focus on the practical aspects of analyses. Whereas lectures introduce some background theory, their primary aim is to set the stage for accompanying exercises.\n\nCovered topicsLearning objectivesRequirements\n\n\n\nFoundations of population genetics\nIntroduction to simulation and the coalescent\nBasics of variant calling\nVariant filtering and sequence masks\nCharacterization and intepretation of DNA sequence variation\nCalculation and interpretation of summary statistics from variation data\nInvestigating population structure with admixture modelling and principal component analyses\nDemographic modelling using sequentially Markovian coalescent models and linkage disequlibrium\nSelection scans\n\n\n\nUpon completion of this course, you will be able to:\n\ndescribe the different forces of evolution and how they influence genetic variation\nunderstand and interpret genealogical trees and how they relate to genetic variation data\ndescribe the basics of the coalescent\nperform simple coalescent simulations with msprime\nrun simple SLiM forward simulation models\ndescribe and run the steps of a variant calling pipeline, including quality control of raw reads, read mapping, and variant calling\nknow how and when to filter raw variant calls using manual coverage filters\ndescribe and calculate nucleotide diversity from variation data\nanalyze population structure with admixture modelling and dimensionality reduction methods\nperform demographic modelling with sequential Markovian coalescent models\ndescribe methods that identify regions undergoing adaptation and selection\nrun selection scans, score identified regions and interpret findings in the context of genome annotations\n\n\n\n\nBasic knowledge in R or Python\nBasic knowledge of variant calling, or the equivalent of NBIS course “Introduction to Bioinformatics using NGS data”\nBasic knowledge of population genetics\nBasic understanding of frequentist statistics\nA computer\n\nDesirable:\n\nExperience with analysis of NGS and other omic data"
  },
  {
    "objectID": "exercises/compute_environment/index.html",
    "href": "exercises/compute_environment/index.html",
    "title": "Compute environment",
    "section": "",
    "text": "Prerequisite: UPPMAX account\n\n\n\n\n\nTo run exercises on UPPMAX you need an account. You can apply for an account here.\n\n\n\nWe will primarily be using Uppsala’s high-performance computing (HPC) center UPPMAX to run exercises. Course material will be hosted in a dedicated course project directory /proj/naiss2023-22-1084.\nWe recommend you setup a working directory based on your username in /proj/naiss2023-22-1084/users in which to run your exercises:\nmkdir -p /proj/naiss2023-22-1084/users/YOURUSERNAME\ncd /proj/naiss2023-22-1084/users/YOURUSERNAME\nAll computations should be run on a compute node. You can request an interactive session with the interactive command. For example, to request an eight hour job on 4 cores, run\ninteractive -A naiss2023-22-1084 -n 4 \\\n   --time 08:00:00 \\\n   --reservation=naiss2023-22-1084_#\nwhere # is a number that corresponds to the day of the week, starting from 1 (Monday=1, Tuesday=2, and so on).\n\n\n\n\n\n\nPlease do not book more than 4 cores\n\n\n\nWe have priviliged access to a limited number of nodes. Please do not book more than 4 cores or else your fellow students will experience long waiting times.\n\n\n\n\n\n\n\n\nMake sure to login to a compute node before running any heavy commands\n\n\n\n\n\n\n\nUPPMAX hosts tutorials and user guides at https://www.uppmax.uu.se/support/user-guides/. In particular, https://www.uppmax.uu.se/support/user-guides/guide--first-login-to-uppmax/ has information on how to connect to and work on UPPMAX."
  },
  {
    "objectID": "exercises/compute_environment/index.html#fa-server-uppmax",
    "href": "exercises/compute_environment/index.html#fa-server-uppmax",
    "title": "Compute environment",
    "section": "",
    "text": "Prerequisite: UPPMAX account\n\n\n\n\n\nTo run exercises on UPPMAX you need an account. You can apply for an account here.\n\n\n\nWe will primarily be using Uppsala’s high-performance computing (HPC) center UPPMAX to run exercises. Course material will be hosted in a dedicated course project directory /proj/naiss2023-22-1084.\nWe recommend you setup a working directory based on your username in /proj/naiss2023-22-1084/users in which to run your exercises:\nmkdir -p /proj/naiss2023-22-1084/users/YOURUSERNAME\ncd /proj/naiss2023-22-1084/users/YOURUSERNAME\nAll computations should be run on a compute node. You can request an interactive session with the interactive command. For example, to request an eight hour job on 4 cores, run\ninteractive -A naiss2023-22-1084 -n 4 \\\n   --time 08:00:00 \\\n   --reservation=naiss2023-22-1084_#\nwhere # is a number that corresponds to the day of the week, starting from 1 (Monday=1, Tuesday=2, and so on).\n\n\n\n\n\n\nPlease do not book more than 4 cores\n\n\n\nWe have priviliged access to a limited number of nodes. Please do not book more than 4 cores or else your fellow students will experience long waiting times.\n\n\n\n\n\n\n\n\nMake sure to login to a compute node before running any heavy commands\n\n\n\n\n\n\n\nUPPMAX hosts tutorials and user guides at https://www.uppmax.uu.se/support/user-guides/. In particular, https://www.uppmax.uu.se/support/user-guides/guide--first-login-to-uppmax/ has information on how to connect to and work on UPPMAX."
  },
  {
    "objectID": "exercises/compute_environment/index.html#fa-laptop-jupyter-notebooks",
    "href": "exercises/compute_environment/index.html#fa-laptop-jupyter-notebooks",
    "title": "Compute environment",
    "section": "\n Jupyter Notebooks",
    "text": "Jupyter Notebooks\nJupyter Notebook exercises will be run in local compute environments on your laptop. See the section below on setting up a pgip conda environment, which by default installs jupyter and its dependencies.\n\n JupyterLite\nThere are some Jupyter Notebook exercises that are hosted online and run using JupyterLite which is a JupyterLab distribution that runs entirely in the browser. Apart from having a browser, no preparations are necessary. Note that some users have reported issues with Firefox and that Google Chrome may be a better solution."
  },
  {
    "objectID": "exercises/compute_environment/index.html#sec-compute-environment-conda",
    "href": "exercises/compute_environment/index.html#sec-compute-environment-conda",
    "title": "Compute environment",
    "section": "\n Conda",
    "text": "Conda\nExercises that require local software installation will make use of the conda package manager to install necessary requirements from the package repositories bioconda and conda-forge. This is also the fallback solution in case there are issues with the HPC.\n1. Install conda\nTo start using conda, follow the quick command line install instructions to install the minimal conda installer miniconda.\n2. Configure conda\nConfigure conda to access the package repositories (see also bioconda usage). This will modify your ~/.condarc file:\n\nconda config --add channels defaults\nconda config --add channels bioconda\nconda config --add channels conda-forge\nconda config --set channel_priority strict\n\n\n\n\n\n\n\nImportant\n\n\n\nPlease note that the order of these commands is important! When conda config --add is run it adds the channel to the top of the list in your configuration, so your ~/.condarc will end up looking like this:\ncat ~/.condarc\nchannels:\n  - conda-forge\n  - bioconda\n  - defaults\nchannel_priority: strict\n\n\n3. Create an isolated course environment\nIt is suggested you create and change to a isolated environment pgip dedicated to the course. The command below will create an environment named pgip and install the packages python version 3.10, an R base installation (r-base), the jupyter package that provides support for Jupyter Notebooks, an R kernel for Jupyter, and the mamba package manager.\n\nconda create --name pgip python=3.10 r-base jupyter r-irkernel mamba\nconda activate pgip\n\nThe activate command is required to access the isolated environment named pgip. Once you have activated the environment, you gain access to whatever programs are installed. To deactivate an environment you issue the command conda deactivate.\n4. Install packages\nInstallation of packages in an environment is done with the install command, but we recommend you use the mamba package manager as it is faster (mamba is a rewrite of conda in C++). An example of how to install packages bcftools, angsd, mosdepth follows (remember to activate pgip!):\n\n\n\n\n\n\n03-Nov-2023: Package errors\n\n\n\nSome users have reported errors in that bcftools and angsd cannot be found, despite setting the proper channels. We are looking into the issue, but unless there are issues with UPPMAX, we will not need to install any additional packages apart from those that went into the creation of the pgip environment above. You can therefore treat the code below as examples only.\n\n\n\nconda activate pgip\nmamba install bcftools angsd mosdepth\n\nor if you have packages listed in an environment file\n#| label: conda-install-packages-from-environment-file\n#| echo: true\n#| eval: false\nmamba env update -f environment.yml"
  },
  {
    "objectID": "exercises/compute_environment/index.html#tools",
    "href": "exercises/compute_environment/index.html#tools",
    "title": "Compute environment",
    "section": "Tools",
    "text": "Tools\nComputer exercise requirements are listed in Tools callout blocks in each exercise. The Tools callout block contains listings of programs, along with package dependencies and specifications for UPPMAX and conda, whenever relevant. An example block is shown below.\n\n\n\n\n\n\nTools - example\n\n\n\n\n\nExample Tools block.\n\n\nListing\nUPPMAX modules\nConda\n\n\n\nProvides list of packages linked to repository, and citation when available.\n\nfastqc\n\nbwa (Li, 2013)\n\n\n\n\nProvides command and instructions to load relevant UPPMAX modules.\nExample:\n\nmodule load uppmax bioinfo-tools bwa/0.7.17 \\\n    FastQC/0.11.9\n\n\n\nProvides a conda environment file that lists dependencies and where to retrieve them.\nTo install, copy the contents in the code block to a file environment.yml and install packages with mamba env update -f environment.yml.\nchannels:\n  - conda-forge\n  - bioconda\n  - defauts\ndependencies:\n  - bwa=0.7.17\n  - fastqc=0.12.1"
  },
  {
    "objectID": "exercises/simulation/index.html",
    "href": "exercises/simulation/index.html",
    "title": "Introduction to simulation",
    "section": "",
    "text": "Compute environment setup\n\n\n\n\n\nNo setup required."
  },
  {
    "objectID": "exercises/simulation/index.html#sec-exercise-simulation-howto",
    "href": "exercises/simulation/index.html#sec-exercise-simulation-howto",
    "title": "Introduction to simulation",
    "section": "Instructions",
    "text": "Instructions\nStart by going through the HOWTO"
  },
  {
    "objectID": "exercises/simulation/index.html#sec-exercise-simulation-coalescent",
    "href": "exercises/simulation/index.html#sec-exercise-simulation-coalescent",
    "title": "Introduction to simulation",
    "section": "1. Introduction to the coalescent",
    "text": "1. Introduction to the coalescent\nWork through the introduction to the coalescent workbook."
  },
  {
    "objectID": "exercises/simulation/index.html#sec-exercise-simulation-msprime",
    "href": "exercises/simulation/index.html#sec-exercise-simulation-msprime",
    "title": "Introduction to simulation",
    "section": "2. Introduction to msprime",
    "text": "2. Introduction to msprime\nWork through the introduction to msprime workbook."
  },
  {
    "objectID": "exercises/variant_filtering/index.html",
    "href": "exercises/variant_filtering/index.html",
    "title": "Variant filtering",
    "section": "",
    "text": "Compute environment setup\n\n\n\n\n\nIf you haven’t already done so, please read Compute environment for information on how to prepare your working directory.\nIn this exercise we will look at ways of filtering variant data. We will begin by applying filters to the variant file containing variant sites only, followed by an approach that filters on sequencing depth in a variant file containing both variant and invariant sites. The latter methodology can then be generalized to generate depth-based filters from BAM files."
  },
  {
    "objectID": "exercises/variant_filtering/index.html#background",
    "href": "exercises/variant_filtering/index.html#background",
    "title": "Variant filtering",
    "section": "Background",
    "text": "Background\nRegardless of how a raw variant call set has been produced, the calls will be of varying quality for a number of reasons. For high-coverage sequencing, the two most common are incompleteness of the reference sequence and misalignments in repetitive regions (Li, 2014). Low-coverage sequencing comes with its own biases and issues, with the most important being the difficulty to accurately call genotypes (Maruki & Lynch, 2017).\nIn order to improve the accuracy of downstream inference, a number of analysis-dependent quality control filters should be applied to the raw variant call set (for a concise summary, see Lou et al. (2021)). In this exercise, we will begin by applying filters to the variant file containing variant sites only, followed by a more general approach based on depth filtering of a variant file consisting of all sites, variant as well as invariant. If time permits, we will also look at an approach that generates depth profiles directly from read mappings (BAM files) and that works also when it is impractical due to file size to include invariant sites in the variant file.\nIt is worthwhile to spend time thinking about filtering. As we will see, there are numerous metrics to filter on, and different applications require different filters. This is not as straightforward as it first may seem, and even experts struggle to get filtering settings right.\nSome recommended data filters\nThere are many ways to filter data. Choosing the right set of filters is not easy, and choosing appropriate thresholds depends on application, among other things. Below we list some recommended data filters and thresholds that have general applicability and recently have been reviewed (Lou et al., 2021, Table 3):\n\n\ndepth: Given the difficulty of accurately genotyping low-coverage sites, it is recommended to set a minimum read depth cutoff to remove false positive calls. It is also recommended to set a maximum depth cutoff as excessive coverage is often due to mappings to repetitive regions. The thresholds will depend on the depth profile over all sites, but is usually chosen as a range around the mean or median depth (e.g. lower threshold 0.8X mean, upper threshold median + 2 standard deviations).\n\nminimum number of individuals: To avoid sites with too much missing data across individuals, a common requirement is that a minimum number (fraction) of individuals, say 75%, have sequence coverage (depth-based filter) or genotype calls.\n\nquality (p-value): Most variant calling software provide a Phred-scaled probability score that a genotype is a true genotype. Quality values below 20 (i.e., 1%) should not be trusted, but could be set much higher (i.e., lower p-value) depending on application. Note that if a VCF file includes invariant sites, they have quality values set to 0, which renders quality based filtering inappropriate.\n\nMAF: Filter sites based on a minimum minor allele frequency (MAF) threshold. The appropriate choice depends on application. For instance, for PCA or admixture analyses, low-frequency SNPs are uninformative, and a reasonably large cutoff (say, 0.05-0.10) could be set. If an analysis depends on invariant sites, this filter should not be applied.\n\n\n\n\n\n\n\nImportant\n\n\n\nFor applications where invariant sites should be included, such as genetic diversity calculations, neither quality nor MAF filtering should be applied."
  },
  {
    "objectID": "exercises/variant_filtering/index.html#sec-basic-filtering",
    "href": "exercises/variant_filtering/index.html#sec-basic-filtering",
    "title": "Variant filtering",
    "section": "Basic filtering of a VCF file2\n",
    "text": "Basic filtering of a VCF file2\n\nWe will begin by creating filters for a VCF file consisting of variant sites only for red and yellow ecotypes. Before we start, let’s review some statistics for the entire (unfiltered) call set:\n\nbcftools stats variantsites.vcf.gz | grep ^SN\n\nSN  0   number of samples:  10\nSN  0   number of records:  128395\nSN  0   number of no-ALTs:  0\nSN  0   number of SNPs: 105508\nSN  0   number of MNPs: 0\nSN  0   number of indels:   23086\nSN  0   number of others:   0\nSN  0   number of multiallelic sites:   10412\nSN  0   number of multiallelic SNP sites:   2108\n\n\nKeep track of these numbers as we will use them to evaluate the effects of filtering.\nGenerate random subset of variants\nDepending on the size of a study, both in terms of reference sequence and number of samples, the VCF output can become large; a VCF file may in fact contain millions of variants and be several hundred GB! We want to create filters by examining distributions of VCF quality metrics and setting reasonable cutoffs. In order to decrease run time, we will look at a random sample of sites. We use the vcflib program vcfrandomsample to randomly sample approximately 100,000 sites from our VCF file3:\n\n# Set parameter r = 100000 / total number of variants\nbcftools view variantsites.vcf.gz | vcfrandomsample -r 0.8 |\\\n    bgzip -c &gt; variantsites.subset.vcf.gz\nbcftools index variantsites.subset.vcf.gz\nbcftools stats variantsites.subset.vcf.gz |\\\n    grep \"number of records:\"\n\nSN  0   number of records:  102837\n\n\nThe -r parameter sets the rate of sampling which is why we get approximately 100,000 sites. You will need to adjust this parameter accordingly.\nWe will now use vcftools to compile statistics. By default, vcftools outputs results to files with a prefix out. in the current directory. You can read up on settings and options by consulting the man pages with man vcftools4. Therefore, we define a variable OUT where we will output our quality metrics, along with a variable referencing our variant subset:\n\nmkdir -p vcftools\nOUT=vcftools/variantsites.subset\nVCF=variantsites.subset.vcf.gz\n\nGenerate statistics for filters\nvcftools can compile many different kinds of statistics. Below we will focus on the ones relevant to our data filters. We will generate metrics and plot results as we go along, with the goal of generating a set of filtering thresholds to apply to the data.\nTotal depth per site\nTo get a general overview of depth of coverage, we first generate the average depth per sample5:\n\nvcftools --gzvcf $VCF --depth --out $OUT 2&gt;/dev/null\ncat ${OUT}.idepth\ncsvtk summary -t -f MEAN_DEPTH:mean ${OUT}.idepth\n\nINDV    N_SITES MEAN_DEPTH\nPUN-R-ELF   102661  8.56171\nPUN-R-JMC   102641  9.49788\nPUN-R-LH    102678  9.17452\nPUN-R-MT    102635  9.4127\nPUN-R-UCSD  102720  8.83886\nPUN-Y-BCRD  102625  9.82563\nPUN-Y-INJ   102597  8.2163\nPUN-Y-LO    102605  7.80022\nPUN-Y-PCT   102581  9.049\nPUN-Y-POTR  102561  8.43227\nMEAN_DEPTH:mean\n8.88\n\n\nThe average coverage over all samples is 8.9X. This actually is in the low range for a protocol based on explicitly calling genotypes. At 5X coverage, there may be a high probability that only one of the alleles has been sampled (Nielsen et al., 2011), whereby sequencing errors may be mistaken for true variation.\nThen we calculate depth per site to see if we can identify reasonable depth cutoffs:\n\nvcftools --gzvcf $VCF --site-depth --out $OUT 2&gt;/dev/null\nhead -n 3 ${OUT}.ldepth\n\nCHROM   POS SUM_DEPTH   SUMSQ_DEPTH\nLG4 2105    9   23\nLG4 2130    11  21\n\n\nSo, for each position, we have a value (column SUM_DEPTH) for the total depth across all samples.\nWe plot the distribution of total depths by counting how many times each depth is observed. This can be done with csvtk summary where we count positions and group (-g) by the SUM_DEPTH value:6\n\ncsvtk summary -t -g SUM_DEPTH -f POS:count -w 0 ${OUT}.ldepth |\\\n csvtk sort -t -k 1:n |\\\n csvtk plot line -t - -x SUM_DEPTH -y POS:count \\\n    --point-size 0.01 --xlab \"Depth of coverage (X)\" \\\n    --ylab \"Genome coverage (bp)\" \\\n    --width 9.0 --height 3.5 &gt; $OUT.ldepth.png\n\n\n\n\n\n\nFigure 1: Distribution of the total depth per site for all samples.\n\n\n\n\n\n\n\nOn csvtk as plotting software\n\n\n\n\n\nYou are of course perfectly welcome to use R or some other software to make these plots. We choose to generate the plots using csvtk to avoid too much context switching, and also because it emulates much of the functionality in R, albeit much less powerful when it comes to plotting.\n\n\n\nAs Figure 1 shows, most sites fall within a peak, but also that there are sites with very high coverage, up to ten times as high as the depth at the peak maximum. We calculate some range statistics to get an idea of the spread. The following csvtk command will calculate the minimum, first quartile, median, mean, third quartile, and maximum of the third column (SUM_DEPTH):\n\ncsvtk summary -t -f 3:min,3:q1,3:median,3:mean,3:q3,3:max,3:stdev vcftools/variantsites.subset.ldepth\n\nSUM_DEPTH:min   SUM_DEPTH:q1    SUM_DEPTH:median    SUM_DEPTH:mean  SUM_DEPTH:q3    SUM_DEPTH:max   SUM_DEPTH:stdev\n1.00    55.00   72.00   88.63   88.00   33988.00    235.62\n\n\nThe range from the first quartile (q1) to the third (q3) is 55-88, showing most sites have a depth between 50-100X. We redraw the plot to zoom in on the peak:\n\n\n\n\n\nFigure 2: Zoomed in version of Figure 1 which was achieved by adding the options --x-min 0 --x-max 140 --y-max 2500 to the plotting call.\n\nWe could choose a filter based on the quantile statistics above, or by eye-balling the graph. In this example, we could have chosen the range 50-150X, which equates to 5-15X depth per sample; note that your values will probably be different.\nAs an aside, we mention that there is a command to directly get the per-site mean depth, --site-mean-depth:\n\nvcftools --gzvcf $VCF --site-mean-depth --out $OUT 2&gt;/dev/null\nhead -n 3 ${OUT}.ldepth.mean\n\nCHROM   POS MEAN_DEPTH  VAR_DEPTH\nLG4 2105    0.9 1.65556\nLG4 2130    1.1 0.988889\n\n\nVariant quality distribution\nAnother quantity of interest is the variant quality. Recall, variant quality scores are Phred-scaled scores, meaning a value of 10 has a 10% chance of being wrong, 20 a 1% chance, and so on; you typically want to at least filter on 20 or even higher. We extract and plot the quality values below:\n\nvcftools --gzvcf $VCF --site-quality --out $OUT\n\n\n# To improve histogram, filter out extreme quality scores. You\n# may have to fiddle with the exact values\ncsvtk filter -t -f \"QUAL&gt;0\" -f \"QUAL&lt;1000\" ${OUT}.lqual  | \\\n csvtk summary -t -g QUAL -f POS:count -w 0 - |\\\n csvtk sort -t -k 1:n |\\\n csvtk plot hist -t --bins 100 - \\\n          --xlab \"Quality value\" \\\n    --ylab \"Count\" \\\n    --width 9.0 --height 3.5 &gt; $OUT.lqual.png\n\n\n\n\n\n\nFigure 3: Distribution of variant quality scores.\n\nClearly most quality scores are above 20-30. For many applications, we recommend setting 30 as the cutoff.\nMinor allele frequency distribution\nSince we are going to calculate nucleotide diversities, we will not filter on the minor allele frequency (MAF) here. Nevertheless, we generate the distribution and plot for discussion purposes. The --freq2 will output the frequencies only, adding the option --max-alleles 2 to focus only on bi-allelic sites:\n\nvcftools --gzvcf $VCF --freq2 --out $OUT --max-alleles 2 2&gt;/dev/null\nhead -n 3 ${OUT}.frq\n\nCHROM   POS N_ALLELES   N_CHR   {FREQ}\nLG4 2105    2   4   0   1\nLG4 2130    2   14  0.857143    0.142857\n\n\nThe last two columns are frequencies ordered according to the reference allele. Therefore, we need to pick the minimum value to get the MAF. We can use csvtk mutate to create a new column\n\ncsvtk fix -t ${OUT}.frq 2&gt;/dev/null |\\\n csvtk mutate2 -t -n maf -e '${5} &gt; ${6} ? \"${6}\" : \"${5}\" ' - |\\\n csvtk plot hist -t --bins 20 -f maf - \\\n       --xlab \"Minor allele frequency\" \\\n       --ylab \"Count\" \\\n       --width 9.0 --height 3.5 &gt; $OUT.frq.png\n\n\n\n\n\n\nFigure 4: Distribution of minor allele frequencies.\n\nSince our variant file consists of 10 individuals, that is, 20 chromosomes, there are only so many frequencies that we can observe, which is why the histogram looks a bit disconnected7. In fact, given 20 chromosomes, MAF=0.05 corresponds to one alternative allele among all individuals (singleton), MAF=0.1 to two, and so on. The maximum value is 0.5, which is to be expected, as it is a minor allele frequency. We note that there are more sites with a low minor allele frequency, which in practice means there are many singleton variants.\nThis is where filtering on MAF can get tricky. Singletons may correspond to sequencing error, but if too hard a filter is applied, the resulting site frequency spectrum (SFS) will be skewed. For statistics that are based on the SFS, this may lead biased estimates. Since we will be applying such a statistic, we do not filter on the MAF here. Note, however, that for other applications, such as population structure, it may be warranted to more stringently (say, MAF&gt;0.1) filter out low-frequency variants.\nMissing data for individuals and sites\nThe proportion missing data per individual can indicate whether the input DNA was of poor quality, and that the individual should be excluded from analysis. Note that in this case, missing data refers to a missing genotype call and not sequencing depth!\nWe can calculate the proportion of missing data\n\nvcftools --gzvcf $VCF --missing-indv --out $OUT 2&gt;/dev/null\nhead -n 3 ${OUT}.imiss\n\nINDV    N_DATA  N_GENOTYPES_FILTERED    N_MISS  F_MISS\nPUN-R-ELF   102837  0   6856    0.0666686\nPUN-R-JMC   102837  0   6544    0.0636347\n\n\nand look at the results, focusing on the F_MISS column (proportion missing sites):\n\ncsvtk plot hist -t --x-min 0 -f F_MISS ${OUT}.imiss &gt; ${OUT}.imiss.png\n\n\n\n\n\n\nFigure 5: Distribution of missingness per sample.\n\nHere, the proportion lies in the range 0.06-0.10 for all samples, which indicates good coverage of all samples and we refrain from taking any action.\nSimilarly, we can look at missingness per site. This is related to the filter based on minimum number of individuals suggested by Lou et al. (2021). We calculate\n\nvcftools --gzvcf $VCF --missing-site --out $OUT 2&gt;/dev/null\nhead -n 3 ${OUT}.lmiss\n\nCHR POS N_DATA  N_GENOTYPE_FILTERED N_MISS  F_MISS\nLG4 2105    20  0   16  0.8\nLG4 2130    20  0   6   0.3\n\n\nand plot to get an idea of if there are sites that lack data.\n\ncsvtk plot hist --bins 20 -t -f F_MISS ${OUT}.lmiss &gt; ${OUT}.lmiss.png\n\n\n\n\n\n\nFigure 6: Distribution of missingness among sites.\n\nAs Figure 6 shows, many sites have no or little missing data, but given the low coverage, there is a non-negligible number of sites with higher missingness. We calculate range statistics to get a feeling for a good cutoff:\n\ncsvtk summary -t -f 6:min,6:q1,6:median,6:mean,6:q3,6:max vcftools/variantsites.subset.lmiss\n\nF_MISS:min  F_MISS:q1   F_MISS:median   F_MISS:mean F_MISS:q3   F_MISS:max\n0.00    0.00    0.00    0.08    0.10    0.90\n\n\nThe mean missingness is 8%, so we can safely use 25% missingness as threshold. Typical values of tolerated missingness lie in the range 5-25%. Note that vcftools interprets this value as 1 - missingness, so it has to be inverted to 75% when filtering!\nHeterozygosity\nvcftools can calculate the heterozygosity per individual. More specifically, it estimates the inbreeding coefficient F for each individual.\n\nvcftools --gzvcf $VCF --het --out $OUT 2&gt;/dev/null\ncat ${OUT}.het\n\nINDV    O(HOM)  E(HOM)  N_SITES F\nPUN-R-ELF   72504   65550.5 87270   0.32015\nPUN-R-JMC   68142   65746.6 87478   0.11023\nPUN-R-LH    70774   65951.2 87753   0.22121\nPUN-R-MT    69881   65680.2 87353   0.19383\nPUN-R-UCSD  74596   65493.4 87440   0.41476\nPUN-Y-BCRD  69232   64812.3 86131   0.20731\nPUN-Y-INJ   71134   64080.6 84976   0.33756\nPUN-Y-LO    72702   63237.7 84256   0.45029\nPUN-Y-PCT   74423   64380.1 85831   0.46818\nPUN-Y-POTR  71638   64426.3 85646   0.33986\n\n\nHere, F is a measure of how much the observed homozygotes O(HOM) differ from the expected (E(HOM); expected by chance under Hardy-Weinberg equilibrium), and may be negative. vcftools calculates F from the expression \\(F=(O-E)/(N-E)\\)8, which you can verify by substituting the variables in the output.\nIf F is positive (\\(O(HOM) &gt; E(HOM)\\)), i.e., there are more observed homozygotes than expected, then there is a deficit of heterozygotes, which could be a sign of inbreeding or signs of allelic dropout in case of low sequencing coverage.\nIf F is negative, there are fewer observed homozygotes than expected, or conversely, an excess of heterozygotes. This could be indicative of poor sequence quality (bad mappings) or contamination (Purcell et al., 2007).\nThe underlying assumption is HWE, which holds for F=0.\nIn this case, we know that the samples are from two different populations, red and yellow. In such cases, we actually expect a deficit of heterozygotes (and consequently, positive F) simply due to something called the Wahlund effect.\n\n\n\n\n\n\nWarning\n\n\n\nThe inbreeding coefficient is a population-level statistic and is not reliable for small sample sizes (\\(n&lt;10\\), say). Therefore, our sample size is in the lower range and the results should be taken with a grain of salt.\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\n\nUse bcftools view -s SAMPLENAMES | vcftools --vcf - --het --stdout to calculate the heterozygosity for red and yellow samples. Substitute SAMPLENAMES for a comma-separated list of samples.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\nbcftools view -s PUN-R-ELF,PUN-R-JMC,PUN-R-LH,PUN-R-MT,PUN-R-UCSD $VCF |\\\n vcftools --vcf - --het --stdout 2&gt;/dev/null\n\nINDV    O(HOM)  E(HOM)  N_SITES F\nPUN-R-ELF   41876   37724.6 56642   0.21945\nPUN-R-JMC   37403   37798.4 56739   -0.02087\nPUN-R-LH    39878   37895.0 56857   0.10458\nPUN-R-MT    38950   37637.9 56422   0.06985\nPUN-R-UCSD  43575   37488.3 56419   0.32153\n\n\n\n\n\n\n\n\n\n\n\n\nFiltering the VCF\nNow that we have decided on filters we can apply them to the VCF. We first set the filters as variables:\n\nMISS=0.75\nQUAL=30\nMIN_DEPTH=5\nMAX_DEPTH=15\n\nand run vcftools as follows:\n\nOUTVCF=${VCF%.subset.vcf.gz}.filtered.vcf.gz\nvcftools --gzvcf $VCF \\\n   --remove-indels --max-missing $MISS \\\n   --min-meanDP $MIN_DEPTH --max-meanDP $MAX_DEPTH \\\n   --minDP $MIN_DEPTH --maxDP $MAX_DEPTH --recode \\\n   --stdout 2&gt;/dev/null |\n gzip -c &gt; $OUTVCF\n\nCompare the results with the original input:\n\nbcftools stats $OUTVCF | grep \"^SN\"\n\nSN  0   number of samples:  10\nSN  0   number of records:  37757\nSN  0   number of no-ALTs:  0\nSN  0   number of SNPs: 37560\nSN  0   number of MNPs: 0\nSN  0   number of indels:   0\nSN  0   number of others:   0\nSN  0   number of multiallelic sites:   1629\nSN  0   number of multiallelic SNP sites:   665\n\n\nQuite a substantial portion variants have in fact been removed, which here can most likely be attributed to the low average sequencing coverage."
  },
  {
    "objectID": "exercises/variant_filtering/index.html#depth-filtering-of-vcf-with-invariant-sites",
    "href": "exercises/variant_filtering/index.html#depth-filtering-of-vcf-with-invariant-sites",
    "title": "Variant filtering",
    "section": "Depth filtering of VCF with invariant sites",
    "text": "Depth filtering of VCF with invariant sites\nNow we turn our attention to a VCF file containing variant and invariant sites. We will generate depth-based filters, with the motivation that they represent portions of the genome that are accessible to analysis, regardless of whether they contain variants or not. In so doing, we treat filtered sites as missing data and do not assume that they are invariant, as many software packages do.\n\n\n\n\nFigure 7: Coverage distributions for three hypothetical samples along with the cumulative coverage for all samples.\n\n\n\nFigure 7 illustrates the sequencing coverage of three samples. The important thing to note is that the coverage is uneven. Some regions lack coverage entirely, e.g., due to random sampling or errors in the reference sequence. Other regions have excessive coverage, which could be a sign of repeats that have been collapsed in the reference. A general coverage filter could then seek to mask out sites where a fraction (50%, say) of individuals have too low or excessive coverage.\nThe right panel illustrates the sum of coverages across all samples. Minimum and maximum depth filters could be applied to the aggregate coverages of all samples, or samples grouped by population, to eliminate sites confounding data support.\nAs mentioned, the VCF in this exercise contains all sites; that is, both monomorphic and polymorphic sites are present. Every site contains information about depth and other metadata, which makes it possible to apply coverage filters directly to the variant file itself.\nHowever, it may not always be possible to generate a VCF with all sites. Species with large genomes will produce files so large that they prevent efficient downstream processing. Under these circumstances, ad hoc coverage filters can be applied to the BAM files to in turn generate sequence masks that can be used in conjunction with the variant file. This is the topic for the advanced session (Section 4).\nRegardless of approach, the end result is a set of regions that are discarded (masked) for a given analysis. They can be given either as a BED file, or a sequence mask, which is a FASTA-like file consisting of integer digits (between 0 and 9) for each position on a chromosome. Then, by setting a cutoff, an application can mask positions higher than that cutoff. We will generate mask files with 0 and 1 digits, an example of which is shown below, where the central 10 bases of the reference (top) are masked (bottom).\n\n\n&gt;LG4 LG4:12000001-12100000\nGGACAATTACCCCCTCCGTTATGTTTCAGT\n\n&gt;LG4\n000000000011111111110000000000\n\n\nData summary and subset\nWe start by summarising the raw data, as before.\n\nbcftools stats allsites.vcf.gz | grep ^SN\n\nSN  0   number of samples:  10\nSN  0   number of records:  100000\nSN  0   number of no-ALTs:  91890\nSN  0   number of SNPs: 3980\nSN  0   number of MNPs: 0\nSN  0   number of indels:   1197\nSN  0   number of others:   0\nSN  0   number of multiallelic sites:   541\nSN  0   number of multiallelic SNP sites:   69\n\n\nData for depth filters\nBy now you should be familiar with the vcftools commands to generate relevant data for filters. In particular, we used --site-depth to generate depth profiles over all sites, and --missing-site to generate missingness data, based on genotype presence/abscence, for every site. Use these same commands again to generate a set of depth filters.\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\n\nUse vcflib and vcftools to select a subset of variants from which to generate data. Use vcftools commands --site-depth and --missing-site as before to\n\ngenerate data\n(possibly) compute summary statistics with csvtk\n\nplot depth distributions\nselect thresholds for depth-based and missingness filters\nfilter the input VCF\n\nCall the final output file allsites.filtered.vcf.gz and compare your output to the input file.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\nallsites subset\n\n# Set parameter r = 100000 / total number of variants; input file\n# here consists of 100000 entries. Adjust this parameter.\nbcftools view allsites.vcf.gz | vcfrandomsample -r 1.0 |\\\n    bgzip -c &gt; allsites.subset.vcf.gz\nbcftools index allsites.subset.vcf.gz\nbcftools stats allsites.subset.vcf.gz |\\\n    grep \"^SN\"\n\nSN  0   number of samples:  10\nSN  0   number of records:  100000\nSN  0   number of no-ALTs:  91890\nSN  0   number of SNPs: 3980\nSN  0   number of MNPs: 0\nSN  0   number of indels:   1197\nSN  0   number of others:   0\nSN  0   number of multiallelic sites:   541\nSN  0   number of multiallelic SNP sites:   69\n\n\n\nmkdir -p vcftools\nOUT=vcftools/allsites.subset\nVCF=allsites.subset.vcf.gz\n\nDepth per site\n\nvcftools --gzvcf $VCF --site-depth --out $OUT 2&gt;/dev/null\nhead -n 3 ${OUT}.ldepth\ncsvtk summary -t -f 3:min,3:q1,3:median,3:mean,3:q3,3:max,3:stdev ${OUT}.ldepth\n\nCHROM   POS SUM_DEPTH   SUMSQ_DEPTH\nLG4 1   15  37\nLG4 2   16  38\nSUM_DEPTH:min   SUM_DEPTH:q1    SUM_DEPTH:median    SUM_DEPTH:mean  SUM_DEPTH:q3    SUM_DEPTH:max   SUM_DEPTH:stdev\n0.00    58.00   76.00   78.93   91.00   2041.00 92.21\n\n\n\n\n\n\n\nFigure 8: Zoomed in view of depth distribution for all sites.\n\nMissingness\n\nvcftools --gzvcf $VCF --missing-site --out $OUT 2&gt;/dev/null\nhead -n 3 ${OUT}.lmiss\ncsvtk summary -t -f 6:min,6:q1,6:median,6:mean,6:q3,6:max ${OUT}.lmiss\n\nCHR POS N_DATA  N_GENOTYPE_FILTERED N_MISS  F_MISS\nLG4 1   20  0   6   0.3\nLG4 2   20  0   4   0.2\nF_MISS:min  F_MISS:q1   F_MISS:median   F_MISS:mean F_MISS:q3   F_MISS:max\n0.00    0.00    0.10    0.16    0.20    1.00\n\n\n\ncsvtk plot hist --bins 20 -t -f F_MISS ${OUT}.lmiss &gt; ${OUT}.lmiss.png\n\n\n\n\n\n\nFigure 9: Distribution of missingness among all sites.\n\nFilter input\nUnless there is any strange bias that leads to a difference in coverage between variant and invariant sites, the final values should be similar to those before. We set filters and generate the output:\n\nMISS=0.75\nMIN_DEPTH=5\nMAX_DEPTH=15\n\n\nOUTVCF=${VCF%.subset.vcf.gz}.filtered.vcf.gz\nvcftools --gzvcf $VCF \\\n   --remove-indels --max-missing $MISS \\\n   --min-meanDP $MIN_DEPTH --max-meanDP $MAX_DEPTH \\\n   --minDP $MIN_DEPTH --maxDP $MAX_DEPTH --recode \\\n   --stdout 2&gt;/dev/null |\n gzip -c &gt; $OUTVCF\n\nCompare the results with the original input:\n\nbcftools stats $OUTVCF | grep \"^SN\"\n\nSN  0   number of samples:  10\nSN  0   number of records:  46691\nSN  0   number of no-ALTs:  43386\nSN  0   number of SNPs: 2244\nSN  0   number of MNPs: 0\nSN  0   number of indels:   0\nSN  0   number of others:   0\nSN  0   number of multiallelic sites:   129\nSN  0   number of multiallelic SNP sites:   43\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenotype depth data and BED output\nInstead of calculating missing genotypes per site, we can retrieve the individual depth for each genotype with --geno-depth. Since we know cutoffs for mean depth (5-15), we can run this command on the main input file (allsites.vcf.gz). For reasons that soon will become clear, we also rerun --site-depth-mean.\n\nVCF=allsites.vcf.gz\nOUT=vcftools/allsites\nvcftools --gzvcf  ${VCF} --geno-depth --out $OUT 2&gt;/dev/null\nvcftools --gzvcf  ${VCF} --site-mean-depth --out $OUT 2&gt;/dev/null\nhead -n 3 ${OUT}.gdepth\n\nCHROM   POS PUN-R-ELF   PUN-R-JMC   PUN-R-LH    PUN-R-MT    PUN-R-UCSD  PUN-Y-BCRD  PUN-Y-INJ   PUN-Y-LO    PUN-Y-PCT   PUN-Y-POTR\nLG4 1   1   0   3   1   3   0   3   0   2   2\nLG4 2   1   1   3   1   3   0   3   0   2   2\n\n\nWe could then combine these two files and perform filtering as follows: for each site check that\n\nthe mean depth is within the filter range\nthere is a minimimum number of genotypes with sufficient depth\nindividual genotype depth does not exceed a maximum depth threshold\n\nIf any of the points above fail, the site is discarded. We keep track of sites that pass the filters and output positions in BED format (a 0-based tab-separated format consisting of columns chrom, chromStart, and chromEnd).\nHere is some code to achieve these goals. Unfortunately csvtk doesn’t seem to have support for calculating column margins out of the box, which is why we have to resort to this complicated construct using awk to count the number of individual genotypes that pass the coverage threshold 5.\n\nBEDOUT=${VCF%.vcf.gz}.keep.bed\ncsvtk join -t ${OUT}.ldepth.mean ${OUT}.gdepth -f CHROM,POS |\\\n    csvtk filter -t -f \"MEAN_DEPTH&gt;=5\" |\\\n    csvtk filter -t -f \"MEAN_DEPTH&lt;=15\" |\\\n    awk -v FS=\"\\t\" -v OFS=\"\\t\" \\\n        'NR &gt; 1 {count=0; for (i=4; i&lt;=NF; i++)\\\n {if ($i&gt;4) count++ }; if (count&gt;=5) print $1, $2 - 1, $2}'|\\\n    bedtools merge &gt; ${BEDOUT}\nhead -n 3 $BEDOUT\n\nLG4 76  99\nLG4 278 336\nLG4 346 409\n\n\nThe BED file contains a list of regions that are accessible to analysis.\nSequence masks\nIn addition to the BED output files, we can generate sequence masks. First, we set a variable to point to the reference sequence and index it.\n\nexport REF=M_aurantiacus_v1.fasta\nsamtools faidx ${REF}\n\nNow, we use the command bedtools makefasta to make a sequence mask file in FASTA format consisting solely of 1’s:9\n\nawk 'BEGIN {OFS=\"\\t\"} {print $1, 0, $2}' ${REF}.fai &gt; ${REF}.bed\nbedtools maskfasta -fi ${REF} -mc 1 -fo ${REF}.mask.fa -bed ${REF}.bed\n\nWe generate a file where all positions are masked because the BED files contain regions that we want to keep. Therefore, we want to convert corresponding positions to zeros. This file will be used as a template for all mask files.\nWe then apply bedtools maskfasta again to unmask (set to 0) the positions that overlap with the BED coordinates:\n\nbedtools maskfasta -fi ${REF}.mask.fa -mc 0 -fo ${REF}.unmask.fa \\\n   -bed allsites.keep.bed\nhead -n 3 ${REF}.unmask.fa\n\n&gt;LG4\n111111111111111111111111111111111111111111111111111111111111\n111111111111111100000000000000000000000111111111111111111111\n\n\nWe can convince ourselves that this has worked by counting the number of unmasked positions in both the BED file (with bedtools genomecov) and sequence mask:\n\nbedtools genomecov -i allsites.keep.bed -g ${REF}.fai | grep genome\n# tr: -d deletes all characters not (-c, complement) in the character\n# set '0'. wc: -m option counts characters\ncat ${REF}.unmask.fa | tr -d -c '0' | wc -m\n\ngenome  0   20935   100000  0.20935\ngenome  1   79065   100000  0.79065\n79065\n\n\nNote that 0 and 1 in the bedtools genomecov output refers to coverage (i.e., absence/presence) and not unmask/mask as in the mask FASTA file.\nExample: Using a sequence mask with vcftools\n\nThe sequence mask file can be used with vcftools with the option --mask. Before we use, however, we need to convert the mask file to one sequence per line10. seqkit is a neat tool that allows us to do this without hassle. As an example, we then perform a genetic diversity calculation with and without mask file to highlight the difference:\n\nWIDEMASK=${REF}.unmask.wide.fa\nseqkit seq -w 0 ${REF}.unmask.fa &gt; ${WIDEMASK}\nvcftools --gzvcf allsites.vcf.gz --mask $WIDEMASK \\\n         --site-pi --stdout 2&gt;/dev/null |\\\n    csvtk summary -t --ignore-non-numbers --decimal-width 4 \\\n    --fields PI:count,PI:mean\nvcftools --gzvcf allsites.vcf.gz --site-pi --stdout 2&gt;/dev/null |\\\n    csvtk summary -t --ignore-non-numbers --decimal-width 4 \\\n    --fields PI:count,PI:mean\n\nPI:count    PI:mean\n79065   0.0183\nPI:count    PI:mean\n100000  0.0208\n\n\nClearly, filtering may have significant impact on the final outcome. You must choose your filters wisely!"
  },
  {
    "objectID": "exercises/variant_filtering/index.html#sec-advanced-filtering",
    "href": "exercises/variant_filtering/index.html#sec-advanced-filtering",
    "title": "Variant filtering",
    "section": "Advanced depth filtering on BAM files",
    "text": "Advanced depth filtering on BAM files\n\n\n\n\n\n\nImportant\n\n\n\nThis exercise is optional. It was created prior to the previous filtering exercises and may contain overlapping explanations and information. The procedure closely resembles that from the section on genotype depth data above, but depth profiles are now calculated from BAM files, which requires different tools.\n\n\nIn this section, we will restrict our attention to coverage-based filters, with the aim of generating sequence masks to denote regions of a reference sequence that contain sufficient information across individuals and populations. Furthermore, the masks will be applied in the context of genetic diversity calculations, in which case specific filters on polymorphic sites (e.g., p-value or minimum minor allele frequency (MAF)) should not be applied (all sites contain information).\nMapped reads provide information about how well a given genomic region has been represented during sequencing, and this information is usually summarized as the sequencing coverage. For any locus, this is equivalent to the number of reads mapping to that locus.\nSequencing coverage is typically not uniformly distributed over the reference. Reasons may vary but include uneven mapping coverage due to repeat regions, low coverage due to mis-assemblies, or coverage biases generated in the sequencing process. Importantly, both variable and monomorphic sites must be treated identically in the filtering process to eliminate biases between the two kinds of sites.\nIn this part, we will use mosdepth and bedtools to quickly generate depth of coverage profiles of mapped data. mosdepth is an ultra-fast command line tool for calculating coverage from a BAM file. By default, it generates a summary of the global distribution, and per-base coverage in bed.gz format. We will be using the per-base coverage for filtering.\nAlternatively, mosdepth can also output results in a highly compressed format d4, which has been developed to handle the ever increasing size of resequencing projects. Files in d4 format can be processed with the d4-tools tool (Hou et al., 2021). For instance, d4tools view will display the coverage in bed format. We mention this in passing as it may be relevant when working with large genomes or sample sizes, but given the size of our sample data, we will be using bedtools from now on.\nPer sample coverage\nWe start by calculating per-sample coverages with mosdepth. For downstream purposes, we need to save the size of the chromosomes we’re looking at, and for many applications, a fasta index file is sufficient.\n\nexport REF=M_aurantiacus_v1.fasta\nsamtools faidx ${REF}\n\nThe syntax to generate coverage information for a BAM file is mosdepth &lt;prefix&gt; &lt;input file&gt;. Here, we add the -Q option to exclude reads with a mapping quality less than 20:\n\nmosdepth -Q 20 PUN-Y-INJ PUN-Y-INJ.sort.dup.recal.bam\n\nThe per-base coverage output file will be named PUN-Y-INJ.per-base.bed.gz and can be viewed with bgzip:\n\nbgzip -c -d PUN-Y-INJ.per-base.bed.gz | head -n 5\n\nLG4 0   9   3\nLG4 9   13  4\nLG4 13  53  5\nLG4 53  56  6\nLG4 56  62  7\n\n\nTo get an idea of what the coverage looks like over the chromsome, we will make use of two versatile programs for dealing with genomic interval data and delimited text files. Both programs operate on streams, enabling the construction of powerful piped commands at the command line (see below).\nThe first is bedtools, which consists of a set of tools to perform genome arithmetic on bed-like file formats. The bed format is a tab-delimited format that at its simplest consists of the three columns chrom (the chromosome name), chromStart, and chromEnd, the start and end coordinates of a region.\nThe second is csvtk, a program that provides tools for dealing with tab- or comma-separated text files. Avid R users will see that many of the subcommands are similar to those in the tidyverse dplyr package.\nWe can use these programs in a one-liner to generate a simple coverage plot (Figure 10)11\n\nbedtools intersect -a &lt;(bedtools makewindows -g ${REF}.fai -w 1000) \\\n      -b PUN-Y-INJ.per-base.bed.gz -wa -wb | \\\n  bedtools groupby -i - -g 1,2,3 -c 7 -o mean | \\\n  csvtk plot -t line -x 2 -y 4 --point-size 0.01 --xlab Position \\\n      --ylab Coverage --width 9.0 --height 3.5 &gt; fig-plot-coverage.png\n\n\n\n\n\n\nFigure 10: Coverage for sample PUN-Y-INJ in 1kb windows. Experiment changing the window size (-w) parameter to change smoothing.\n\nApparently there are some high-coverage regions that could be associated with, e.g., collapsed repeat regions in the assembly. Let’s compile coverage results for all samples, using bash string manipulation to generate file prefix12\n\n# [A-Z] matches characters A-Z, * is a wildcard character that matches\n# anything\nfor f in [A-Z]*.sort.dup.recal.bam; do\n # Extract the prefix by removing .sort.dup.recal.bam\n prefix=${f%.sort.dup.recal.bam}\n mosdepth -Q 20 $prefix $f\n # Print sample name\n echo -e -n \"$prefix\\t\"\n # Get the summary line containing the total coverage\n cat $prefix.mosdepth.summary.txt | grep total\ndone &gt; ALL.mosdepth.summary.txt\n# View the file\ncat ALL.mosdepth.summary.txt\n\nPUN-R-ELF   total   100000  845166  8.45    0   187\nPUN-R-JMC   total   100000  934032  9.34    0   244\nPUN-R-LH    total   100000  940246  9.40    0   225\nPUN-R-MT    total   100000  956272  9.56    0   233\nPUN-R-UCSD  total   100000  812507  8.13    0   293\nPUN-Y-BCRD  total   100000  882549  8.83    0   320\nPUN-Y-INJ   total   100000  818921  8.19    0   229\nPUN-Y-LO    total   100000  656112  6.56    0   151\nPUN-Y-PCT   total   100000  836694  8.37    0   179\nPUN-Y-POTR  total   100000  795201  7.95    0   205\n\n\nWe can calculate the total coverage by summing the values of the fifth column with csvtk as follows:\n\ncsvtk summary -H -t ALL.mosdepth.summary.txt -f 5:sum\n\nto get the total coverage 84.78, which gives a hint at where the diploid coverage peak should be.\nSample set coverages\nIn this section, we will summarize coverage information for different sample sets, the motivation being that different filters may be warranted depending on what samples are being analysed. For instance, the coverage cutoffs for all samples will most likely be different from those applied to the subpopulations. In practice this means summing coverage tracks like those in Figure 10 for all samples.\nWe can combine the coverage output from different samples with bedtools unionbedg. We begin by generating a coverage file for all samples, where the output columns will correspond to individual samples. To save typing, we collect the sample names and generate matching BED file names to pass as arguments to options -names and -i, respectively. Also, we include positions with no coverage (-empty) which requires the use of a genome file (option -g). The BED output is piped to bgzip which compresses the output, before finally indexing with tabix13.\n\n\nSAMPLES=$(csvtk grep -f Taxon -r -p \"yellow\" -r -p \"red\" sampleinfo.csv | csvtk cut -f SampleAlias | grep -v SampleAlias | tr \"\\n\" \" \")\nBEDGZ=$(for sm in $SAMPLES; do echo -e -n \"${sm}.per-base.bed.gz \"; done)\nbedtools unionbedg -header -names $SAMPLES -g ${REF}.fai -empty -i $BEDGZ | bgzip &gt; ALL.bg.gz\ntabix -f -p bed -S 1 ALL.bg.gz\n\n\n\n\n\n\n\n Command line magic\n\n\n\n\n\nThe code above works as follows. We first use csvtk to grep (search) for the population names red and yellow in the Taxon column in sampleinfo.csv, thereby filtering the output to lines where Taxon matches the population names. Then, we cut out the interesting column SampleAlias and remove the header (grep -v SampleAlias matches anything but SampleAlias). Finally, tr translates newline character \\n to space. The output is stored in the SAMPLES variable through the command substitution ($()) syntax.\nWe then iterate through the $SAMPLES to generate the input file names with the echo command, storing the output in $BEDGZ. These variables are passed on to bedtools unionbedg to generate a bedgraph file combining all samples.\n\n\n\n\nAs mentioned previously, we also need to combine coverages per populations yellow and red.\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\n\nUsing the previous command as a template, try to generate per population coverage files.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\n\nYou only need to modify the code that generates SAMPLES by grepping for each population separately (csvtk grep -f Taxon -r -p red and so on), or setting them manually. Remember also to modify the output file name (e.g., red.bg.gz).\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\nAn example using a for loop is shown here. You could copy-paste the code above and explicitly write out the population labels.\n\nfor pop in red yellow; do\n SAMPLES=$(csvtk grep -f Taxon -r -p $pop sampleinfo.csv | csvtk cut -f SampleAlias | grep -v SampleAlias | tr \"\\n\" \" \")\n BEDGZ=$(for sm in $SAMPLES; do echo -e -n \"${sm}.per-base.bed.gz \"; done)\n bedtools unionbedg -header -names $SAMPLES -g ${REF}.fai -empty -i $BEDGZ | bgzip &gt; $pop.bg.gz\n tabix -f -p bed -S 1 $pop.bg.gz\ndone\n\n\n\n\n\n\n\n\n\n\n\n\nTotal coverage\nSince we eventually want to filter on total coverage, we sum per sample coverages for each sample set with awk:\n\n\nbgzip -c -d ALL.bg.gz | \\\n awk -v FS=\"\\t\" -v OFS=\"\\t\" 'NR &gt; 1 {sum=0; for (i=4; i&lt;=NF; i++) sum+=$i; print $1, $2, $3, sum}' | \\\n bgzip &gt; ALL.sum.bed.gz\ntabix -f -p bed ALL.sum.bed.gz\n\nHere we use awk to sum from columns 4 and up (NF is the number of the last column).\n\nFor illustration, we plot the total coverage:\n\n\nbedtools intersect -a &lt;(bedtools makewindows -g ${REF}.fai -w 1000) \\\n    -b ALL.sum.bed.gz -wa -wb | \\\n  bedtools groupby -i - -g 1,2,3 -c 7 -o mean | \\\n  csvtk plot -t line -x 2 -y 4 --point-size 0.01 --xlab Position \\\n    --ylab Coverage --width 9.0 --height 3.5 &gt; fig-plot-total-coverage.png\n\n\n\n\n\n\n\nFigure 11: Total coverage in 1kb windows.\n\nIn order to define thresholds for subsequent filtering, we need to know the total coverage distribution. Therefore, we plot the proportion of the genome coverage versus depth of coverage (similar to k-mer plots in sequence assembly projects). To do so we must summarize our coverage file such that we count how many bases have a given coverage. This can be achieved by noting that each row in the BED file consists of the columns CHROM, START, END, and COVERAGE. We can generate a histogram table by, for each value of COVERAGE, summing the length of the regions (END - START).\n\n\n# Add column containing length of region (end - start)\ncsvtk mutate2 -t -H -w 0 -e '$3-$2' ALL.sum.bed.gz | \\\n # Sum the regions and *group* by the coverage (fourth column);\n # this gives the total number of bases with a given coverage\n csvtk summary -t -H -g 4 -f 5:sum -w 0 | \\\n csvtk sort -t -k 1:n | \\\n awk -v cumsum=0 'BEGIN {OFS=\",\"; cumsum=0} {cumsum += $2; print $1,$2,cumsum}' &gt; ALL.sum.bed.csv\n\n\nWe plot the coverage distribution below, along with a plot of the cumulative coverage.\n\n\ncsvtk plot line -H ALL.sum.bed.csv -x 1 -y 2 --point-size 0.01 \\\n   --xlab \"Depth of coverage (X)\" --ylab \"Genome coverage (bp)\" \\\n   --width 9.0 --height 3.5 &gt; fig-plot-total-coverage-distribution.png\ncsvtk plot line -H ALL.sum.bed.csv -x 1 -y 3 --point-size 0.01 \\\n   --xlab \"Depth of coverage (X)\" --ylab \"Cumulative genome coverage (kbp)\" \\\n   --width 9.0 --height 3.5 &gt; fig-plot-total-coverage-distribution-cumulative.png\n\n\n\n\n\n(a) Genome coverage\n\n\n\n\n\n(b) Cumulative genome coverage\n\n\nFigure 12: Genome coverage vs depth of coverage.\n\n\n\nIn Figure 12 a, a diploid peak is evident at around coverage X=100; we zoom in on that region to get a better view:\n\ncsvtk plot line -H ALL.sum.bed.csv -x 1 -y 2 --point-size 0.01 \\\n    --xlab \"Depth of coverage (X)\" --ylab \"Genome coverage (bp)\" \\\n    --width 9.0 --height 3.5 --x-min 40 --x-max 140\n\n\n\n\n\n(a) Genome coverage\n\nFigure 13: Genome coverage vs depth of coverage.\n\n\n(Lou et al., 2021) point out that appropriate thresholds depend on the data set, but as a general rule recommend a minimum depth threshold at &lt;0.8X average coverage, and a maximum depth threshold at mean coverage plus one or two standard deviations. For the sake of simplicity, you could here infer a cutoff simply by manually inspecting Figure 13; here, we will use the range 50-110.\nWe then use these thresholds to generate a BED file containing regions that are accessible, i.e., have sufficient coverage for downstream analyses. We also calculate the number of bases that pass the filtering criteria.\n\n\ncsvtk filter -t -H ALL.sum.bed.gz -f '4&gt;50' | \\\n csvtk filter -t -H -f '4&lt;110' | \\\n bgzip -c &gt; ALL.sum.depth.bed.gz\nbedtools genomecov -i ALL.sum.depth.bed.gz -g ${REF}.fai  | grep genome\n\n\nConsequently, 75.2% of the genome is accessible by depth.\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\n\nGenerate coverage sums for the red and yellow sample sets, and from these determine coverage thresholds and apply the thresholds to generate BED files with accessible regions.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\nWe base the answer on the previous code.\n\n\nfor pop in red yellow; do\n bgzip -c -d $pop.bg.gz | \\\n  awk -v FS=\"\\t\" -v OFS=\"\\t\" 'NR &gt; 1 {sum=0; for (i=4; i&lt;=NF; i++) sum+=$i; print $1, $2, $3, sum}' | \\\n  bgzip &gt; $pop.sum.bed.gz\n tabix -f -p bed $pop.sum.bed.gz\n csvtk mutate2 -t -H -w 0 -e '$3-$2' $pop.sum.bed.gz | \\\n csvtk summary -t -H -g 4 -f 5:sum -w 0 | \\\n csvtk sort -t -k 1:n | \\\n awk -v cumsum=0 'BEGIN {OFS=\",\"; cumsum=0} {cumsum += $2; print $1,$2,cumsum}' &gt; $pop.sum.bed.csv\ndone\n\n\n\nfor pop in red yellow; do\ncat ${pop}.sum.bed.csv | \\\n  csvtk plot line -x 1 -y 2 --point-size 0.01 \\\n    --xlab \"Depth of coverage (X)\" --ylab \"Genome coverage (bp)\" \\\n    --width 9.0 --height 3.5 --x-min 0 --x-max 100 &gt; \\\n    fig-plot-total-coverage-distribution-hist-zoom-in-$pop.png\ndone\n\n\n\n\n\n(a) Zoomed in genome coverage, red\n\n\n\n\n\n(b) Zoomed in genome coverage, yellow\n\n\nFigure 14: Zoomed in coverage distribution for red and yellow ecotypes.\n\n\nBased on Figure 14, we generate bed files with depths passing cutoffs:\n\n# red filter: 20-60\ncsvtk filter -t -H red.sum.bed.gz -f '4&gt;20' | \\\n csvtk filter -t -H -f '4&lt;60' | \\\n bgzip -c &gt; red.sum.depth.bed.gz\nbedtools genomecov -i red.sum.depth.bed.gz -g ${REF}.fai  | grep genome\n\n# yellow filter: 20-55\ncsvtk filter -t -H yellow.sum.bed.gz -f '4&gt;20' | \\\n csvtk filter -t -H -f '4&lt;55' | \\\n bgzip -c &gt; yellow.sum.depth.bed.gz\nbedtools genomecov -i yellow.sum.depth.bed.gz -g ${REF}.fai  | grep genome\n\ngenome  0   20853   100000  0.20853\ngenome  1   79147   100000  0.79147\ngenome  0   23231   100000  0.23231\ngenome  1   76769   100000  0.76769\n\n\n\n\n\n\n\n\n\n\n\n\nNow we have combined total per sample coverage for ALL samples, and for sample sets red and yellow. The upcoming task will be to generate sequence masks from the total coverage and minimum number of individuals with coverage greater than zero.\nFilter on minimum number of individuals\nIn addition to filtering on total coverage, we will also filter on the minimum number of individuals with a minimum depth. This is to account for cases where regions that pass the minimum coverage filter originate from just a few samples with unusually high coverage. Here, we will remove sites where more than 50% of individuals have zero coverage.\n\n\nbgzip -c -d ALL.bg.gz | \\\n  awk -v FS=\"\\t\" 'BEGIN {OFS=\"\\t\"} NR &gt; 1 {count=0; for (i=4; i&lt;=NF; i++) {if ($i&gt;0) count+=1}; if (count&gt;=((NF-3)*0.5)) {print $1, $2, $3}}' | \\\n  bgzip &gt; ALL.ind.bed.gz\ntabix -f -p bed ALL.ind.bed.gz\n\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\n\nUse bedtools genomecov to determine the proportion of bases that are filtered out. Use ${REF}.fai as the argument to the required option -g.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\nbedtools genomecov -i ALL.ind.bed.gz -g ${REF}.fai\n\nLG4 0   7694    100000  0.07694\nLG4 1   92306   100000  0.92306\ngenome  0   7694    100000  0.07694\ngenome  1   92306   100000  0.92306\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\n\nGenerate coverage sums for red and yellow sample sets.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\nfor pop in red yellow; do\n  bgzip -c -d $pop.bed.gz | awk -v FS=\"\\t\" 'BEGIN {OFS=\"\\t\"} NR &gt; 1 {count=0; for (i=4; i&lt;=NF; i++) {if ($i&gt;0) count+=1}; if (count&gt;=((NF-3)*0.5)) {print $1, $2, $3}}' | bgzip &gt; $pop.ind.bed.gz\n  tabix -f -p bed $pop.ind.bed.gz\ndone\n\n[bgzip] Could not open red.bed.gz: No such file or directory\n[bgzip] Could not open yellow.bed.gz: No such file or directory\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequence masks\nFinally, as before, we can convert the BED output to sequence mask files in FASTA format. Recall that we first have to make a template genome mask file where all positions are masked:\n\nawk 'BEGIN {OFS=\"\\t\"} {print $1, 0, $2}' ${REF}.fai &gt; ${REF}.bed\nbedtools maskfasta -fi ${REF} -mc 1 -fo ${REF}.mask.fa -bed ${REF}.bed\n\nThen, for each sample set, we will use bedtools intersect to intersect the BED files corresponding to the total sum coverage and the filter on number of individuals. bedtools intersect makes it easy to combine multiple BED files, so any other filters, or genomic features such as exons, could be added to make a compound mask file. The resulting BED files is used as input to bedtools maskfasta.\n\nbedtools intersect -a ALL.sum.depth.bed.gz -b ALL.ind.bed.gz \\\n   -g ${REF}.fai | bgzip &gt; ALL.unmask.bed.gz\ntabix -f -p bed ALL.unmask.bed.gz\nbedtools maskfasta -fi ${REF}.mask.fa -mc 0 -fo ${REF}.unmask.fa \\\n   -bed ALL.unmask.bed.gz\nhead -n 3 ${REF}.unmask.fa\n\n&gt;LG4\n111111111111111111111111111111111111111111111111111111111111\n111111111111111111100000000000000000000000000000000111111111\n\n\nWe can once again convince ourselves that this has worked by counting the number of unmasked positions:\n\n# tr: -d deletes all characters not (-c, complement) in the character\n# set '0'. wc: -m option counts characters\ncat ${REF}.unmask.fa | tr -d -c '0' | wc -m\nbedtools genomecov -i ALL.unmask.bed.gz -g ${REF}.fai | grep genome\n\n75236\ngenome  0   24764   100000  0.24764\ngenome  1   75236   100000  0.75236\n\n\nNote that 0 and 1 in the bedtools genomecov output refers to coverage (i.e., absence/presence) and not unmask/mask as in the mask FASTA file.\n\n\n\n\n\n\nExercise\n\n\n\n\n\n\n\nCreate unmask files for red and yellow populations.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\nfor pop in red yellow; do\n bedtools intersect -a $pop.sum.depth.bed.gz -b $pop.ind.bed.gz \\\n    -g ${REF}.fai | bgzip &gt; $pop.unmask.bed.gz\n tabix -f -p bed $pop.unmask.bed.gz\n bedtools maskfasta -fi ${REF}.mask.fa -mc 0 -fo ${REF}.$pop.unmask.fa \\\n    -bed $pop.unmask.bed.gz\ndone"
  },
  {
    "objectID": "exercises/variant_filtering/index.html#conclusion",
    "href": "exercises/variant_filtering/index.html#conclusion",
    "title": "Variant filtering",
    "section": "Conclusion",
    "text": "Conclusion\nCongratulations! You have now gone through a set of tedious and complex steps to generate output files that determine what regions in a reference DNA sequence are amenable to analysis. In the next exercise we will use these files as inputs to different programs that calculate diversity statistics from population genomic data."
  },
  {
    "objectID": "exercises/variant_filtering/index.html#footnotes",
    "href": "exercises/variant_filtering/index.html#footnotes",
    "title": "Variant filtering",
    "section": "Footnotes",
    "text": "Footnotes\n\nThe password is provided by the course instructor↩︎\nThis exercise is inspired by and based on https://speciationgenomics.github.io/filtering_vcfs/]↩︎\nWe select a fix number that should contain enough information to generate reliable statistics. This number should not change significantly even when files contain vastly different numbers of sites, which is why we need adjust the parameter r to the number of sites in the file.↩︎\nvcftools does not have a -h or --help option.↩︎\nThe 2&gt;/dev/null outputs messages from vcftools to a special file /dev/null which is a kind of electronic dustbin.↩︎\nOn viewing csvtk plots: either you can redirect (&gt;) the results from csvtk to a png output file, or you can pipe (|) it to the command display (replace &gt; $OUT.ldepth.png by | display, which should fire up a window with your plot.↩︎\nYou can try different values of the --bins option↩︎\nPurcell et al. (2007), p. 565 gives a coherent derivation of this estimator↩︎\nWe need to generate a BED file representation of the FASTA index unfortuanely as bedtools makefasta doesn’t handle FASTA indices natively.↩︎\nFor vcftools; unfortunate, but that’s the way it is↩︎\nThe one-liner combines the results of several commands in a pipe stream. Also, Bash redirections are used to gather the results from the output of bedtools makewindows to bedtools intersect. The intersection commands collects coverage data in 1kb windows that are then summarized by bedtools groupby.↩︎\nThe % operator deletes the shortest match of $substring from back of $string: ${string%substring}. See Bash string manipulation for more information.↩︎\nInstead of using the command substitution, you could look into the sample info file and set the sample names manually: SAMPLES=\"PUN-Y-BCRD PUN-R-ELF PUN-Y-INJ PUN-R-JMC PUN-R-LH PUN-Y-LO PUN-R-MT PUN-Y-PCT PUN-Y-POTR PUN-R-UCSD\"↩︎"
  },
  {
    "objectID": "exercises/population_structure/index.html",
    "href": "exercises/population_structure/index.html",
    "title": "Population structure",
    "section": "",
    "text": "Compute environment setup\n\n\n\n\n\nIf you haven’t already done so, please read Compute environment for information on how to prepare your working directory."
  },
  {
    "objectID": "exercises/population_structure/index.html#rendered-notebooks",
    "href": "exercises/population_structure/index.html#rendered-notebooks",
    "title": "Population structure",
    "section": "Rendered notebooks",
    "text": "Rendered notebooks\n\nThe rendered notebook instructions are located as html files at:\nhttps://nbisweden.github.io/workshop-pgip/exercises/population_structure/pca_mds_toy_example.html\nhttps://nbisweden.github.io/workshop-pgip/exercises/population_structure/pca_admixture_1000G.html"
  },
  {
    "objectID": "exercises/population_structure/index.html#jupyter-notebooks",
    "href": "exercises/population_structure/index.html#jupyter-notebooks",
    "title": "Population structure",
    "section": "Jupyter Notebooks",
    "text": "Jupyter Notebooks\nNotebooks are available for download at https://uppsala.instructure.com/courses/86976/pages/population-structure-notebooks"
  },
  {
    "objectID": "exercises/psmc/index.html",
    "href": "exercises/psmc/index.html",
    "title": "PSMC",
    "section": "",
    "text": "Compute environment setup\n\n\n\n\n\nIf you haven’t already done so, please read Compute environment for information on how to prepare your working directory."
  },
  {
    "objectID": "exercises/psmc/index.html#practical-information",
    "href": "exercises/psmc/index.html#practical-information",
    "title": "PSMC",
    "section": "Practical information",
    "text": "Practical information\nAll the files you need are located here: /proj/naiss2023-22-1084/private/demography/psmc.\nWe will be using PSMC (https://github.com/lh3/psmc).\nPSMC is a programs to infer demography history and population size over time based on whole genome data.\nTo run the commands you have two options today:\n\nCreate a bash script and submit to SLURM;\nStart an Interactive session on Rackham and run manually each step. I recommend this option for today.\n\nHow to start interactive mode on Rackham:\n#| echo: true\n#| eval: false\ninteractive -A naiss2023-22-1084 -n 4 \\\n   --partition core --time 08:00:00 \\\n   --reservation=naiss2023-22-1084_4\nYou need to load all modules on Rackham so you don’t have to worry about installing each program that we will need in this exercise.\nmodule load bioinfo-tools bcftools psmc samtools htslib"
  },
  {
    "objectID": "exercises/psmc/index.html#psmc",
    "href": "exercises/psmc/index.html#psmc",
    "title": "PSMC",
    "section": "PSMC",
    "text": "PSMC\nWhen you are running PSMC for your own projects you will need to perform all steps, but today we have a shorter version of the process, so you can look at the results more quickly.\nOne a regular day this is the process:\n\nYou will need a BAM file with reads mapped to a reference genome, just like you did on Tuesday at the Variant Calling exercise (https://nbisweden.github.io/workshop-pgip/exercises/variant_calling/#variant-calling-overview). For PSMC and MSMC it is recommended a minimum of 12x coverage, we discussed this a bit more during the lecture. The organism also needs to be diploid.\nFor PSMC you need to get a diploid consensus from the BAM file, using a command like:\n\n#| echo: true\n#| eval: false\nbcftools mpileup -C50 -uf ref.fa aln.bam | bcftools view -c - \\\n      | vcfutils.pl vcf2fq -d 10 -D 100 | gzip &gt; diploid.fq.gz\nAfter that you will need to convert the diploid consensus to a PSMC input file. PSMC comes with a script for that:\n#| echo: true\n#| eval: false\nfq2psmcfa -q20 diploid.fq.gz &gt; diploid.psmcfa\nThen you will run PSMC for your sample. It is important downstream to know the generation time and mutation rate for your species.\nFor today we will be using a pre-made psmcfa file. This file was generated based on a simulated dataset created with ms.\n\nPSMC input file\nThe .psmcfa file used for PSMC input is located at /proj/naiss2023-22-1084/private/demography/psmc/psmc_input.psmcfa.\nTake a look inside with less psmc_input.psmcfa, you will see something like:\n&gt;1\nTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTKTTTTTTTTTTTTTTTTTTTTTTTT\nTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT\nTTTTTTTTTTTTTTTKTTTTTTTKTTTTTTTTTTTTKTTTTTTTTTTTTTTTTKTTTTTT\nTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTKTTTTTTTTTTTTTTTTTTTT\n\nWhere &gt;1 indicates the chromosome, and then every window is assigned a T or a K. Can you guess what T and K means in this context?\n\n\nRunning PSMC\nWe will be running PSMC as:\n#| echo: true\n#| eval: false\npsmc -N25 -t15 -r5 -p 4+25*2+4+6 -o output.psmc psmc_input.psmcfa\nPSMC has a lot of parameters, and it can feel a bit of a black box for most users.\n-N = number of iterations\n–p = number of free atomic time intervals. This can be confusing. It\nmeans 64 atomic time intervals and 28 free intervals parameters. The\nfirst population size parameter spans the first 4 atomic time intervals,\neach of the next 25 parameters spans 2 intervals, the 27th spans 4\nintervals and the last parameter spans the last 6 time intervals.\n–t = upper limit of time to most recent common ancestor, or the maximum\ncoalescence time\nThe PSMC algorithm breaks down the history of a population into a series of time intervals, each of which corresponds to a different era in the population’s past. The boundaries between these time intervals are estimated using genetic data and coalescent theory, which describes how genealogical relationships between individuals change over time.\nAtomic time allows researchers to compare the relative timing of demographic events, such as population size changes or bottlenecks, without making assumptions about the actual calendar dates.\nThe aim of these parameters is that after 20 rounds of iterations, at least 10 recombinations are inferred to occur in the intervals each parameter spans. These parameters are the default for PSMC and were tested for the analysis of human data.\nPlease note that PSMC runs for hours, so once you see it is running, you can abort it. If you want, you can submit this as a job to Uppmax and check the results after ~3-4 hours.\nSince we don’t have that time, I have the output file ready for you.\nThe results file is:\n/proj/naiss2023-22-1084/private/demography/psmc/results.psmc\nYou can plot it two ways in this exercise.\n\nUse the plot_results.py script.\n\nJust run ./plot_results.py at the directory with the script and the .psmc file. This script was written to output a PDF file with the real population history (one of the benefits of using simulations) and the PSMC estimate. Once everybody reaches this stage we will stop and talk about the results a bit. This script has baked in all the options from the regular PSMC plotting tool below.\n\n\nPSMC has a script for plotting the results. Just run the command:\n\n\n#| echo: true\n#| eval: false\npsmc_plot.pl -u 2.5e-8 -g 25 psmc_plot results.psmc\nIt includes the µ for this “species” (2.5e-8), and the generation time (25). These parameters are fundamental to scale the x axis of the plot. If you provide the plotting tool with the wrong information, your x axis scale will be off and your interpretations will be essentially meaningless. If you are curious about how psmc_plot rescales the time, you can read about it in detail at the program’s paper here (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3154645/)."
  },
  {
    "objectID": "exercises/psmc/index.html#references",
    "href": "exercises/psmc/index.html#references",
    "title": "PSMC",
    "section": "References",
    "text": "References\n\nThe ms PSMC input and the PSMC plotting for simulated data use scripts I modified from Willy Rodríguez (https://github.com/willyrv/ms-PSMC)."
  },
  {
    "objectID": "slides/index.html",
    "href": "slides/index.html",
    "title": "Slides",
    "section": "",
    "text": "A note on usage\nHtml slides have been authored using revealjs and can be viewed directly in the browser. In some cases, there are accompanying speaker notes that can be viewed by pressing s. Whenever there is a  symbol, it links to a recipe that is related to the figure or content on the active slide.\n\n\nSlides\n\n\n\n\n\n\n\nPopulation genomics in practice\n\n\nWhat is population genomics?\n\n\n\nPer Unneberg\n\n\n\n\n\n\n\n\n\n\n\nPopulation genetics\n\n\nFoundations\n\n\n\nPer Unneberg\n\n\n\n\n\n\n\n\n\n\n\nSimulation\n\n\nPrimer on the coalescent and forward simulation\n\n\n\nPer Unneberg\n\n\n\n\n\n\n\n\n\n\n\nVariant calling\n\n\nFrom sequence data to variant call set\n\n\n\nPer Unneberg\n\n\n\n\n\n\n\n\n\n\n\nVariant filtering\n\n\nFrom raw variant calls to high-quality call sets\n\n\n\nPer Unneberg\n\n\n\n\n\n\n\n\n\n\n\nGenetic diversity\n\n\nTheory and practice\n\n\n\nPer Unneberg\n\n\n\n\n\n\n\n\n\n\n\nPopulation structure\n\n\nPrincipal Component Analysis, Admixture and F-statistics\n\n\n\nNikolay Oskolkov, (uses material from lectures of Ben Peter, Anders Albrechtsen, Ida Moltke, Graham Coop)\n\n\n\n\n\n\n\n\n\n\n\nDemographic inference\n\n\n\nAndre Soares\n\n\n\n\n\n\n\n\n\n\n\nSelection\n\n\n\nJason Hill\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "slides/pgip/index.html#intended-learning-outcomes",
    "href": "slides/pgip/index.html#intended-learning-outcomes",
    "title": "Population genomics in practice",
    "section": "Intended learning outcomes",
    "text": "Intended learning outcomes\nCourse\n\nPresent minimum toolkit of methods that should be known to anyone starting out in population genomics\nSufficiently small for one-week workshop\n\nLecture\n\nPresent practical example of toolkit as applied in (Fuller et al., 2020)\nBriefly discuss baseline model (Johri et al., 2022)\n\n\n\nAim of lecture is to:\n\npresent a practical application of commonly used methods in population genomics\nlink population genomics to population genetics\ndiscuss statistical inference and the need of a baseline model with which to compare observations and conclusions\n\nWhat is population genomics?\nPoints from (Hahn, 2019, pp. 249–250):\n\nwhole-genome data instead of single loci - population genomics is population genetics for whole-genome sequences\n\nif only this, not too exciting\n\nmajor promise: enables analyses not possible for single loci or that require genomic context\naddresses interactions between different forces, notably selection and demographic history\n\nSome applications\n\ngenome-wide scans for selection\n\nselection vs demography (p. 251)\n\nmethods for genome-wide scans (p. 258)\n\nCaveats\n\nnon-independence (p. 267)\n\ndifferent statistics rely on similar input\noverlapping peaks from different statistics not independent\n\n\nGeneral points\n(Hartl & Clark, 1997, pp. 469–470):\n\nmore emphasis on differences within populations\ngoal: understand differences among genomes -&gt; requires complete sequence data from multiple individuals\n\n(Li & Durbin, 2011, supplementary notes, p. 6) on the use of PSMC on autosomes:\n“…highly consistent except for the very recent history, demonstrating the power of using whole-genome data.”"
  },
  {
    "objectID": "slides/pgip/index.html#example-population-genetics-of-the-coral-acropora-millepora",
    "href": "slides/pgip/index.html#example-population-genetics-of-the-coral-acropora-millepora",
    "title": "Population genomics in practice",
    "section": "Example: Population genetics of the coral Acropora millepora",
    "text": "Example: Population genetics of the coral Acropora millepora\n\n\nMotivation: corals are facing hard times and to prevent future losses of coral cover a better understanding of genetics is warranted.\n\n\nGenome assembly and sampling\n\nMotivation: most analyses require a reference sequence with which to compare resequenced samples\n\nAssemble high-quality reference genome\nChoice of populations, sampling locations\n\n\n\n\n\n\n\nFigure 1: Genome assembly and sample collection.\n\n\n\n\n\nFuller et al. (2020)\n\n\n\n\n\n(Fuller et al., 2020) is an example of a population genomics study that applies methods that could be seen as a basic foundation of population genomics. We believe these present a minimum toolkit of methods that should be known to anyone starting out in population genomics, and that is sufficiently small to be presented in a one-week workshop. At the end of this lecture, we will discuss some more advanced applications in population genomics.\nGenome assembly and sampling\nWhy: most analyses require a reference sequence with which to compare resequenced samples\nPoints to consider:\n\nchoice of reference individual\nthe number of populations\nthe number of samples (more sites better than many samples per population)\nthe geographical distribution of samples\nsequencing depth (low-coverage often sufficient)"
  },
  {
    "objectID": "slides/pgip/index.html#example-population-genetics-of-the-coral-acropora-millepora-1",
    "href": "slides/pgip/index.html#example-population-genetics-of-the-coral-acropora-millepora-1",
    "title": "Population genomics in practice",
    "section": "Example: Population genetics of the coral Acropora millepora",
    "text": "Example: Population genetics of the coral Acropora millepora\n\n\nMotivation: corals are facing hard times and to prevent future losses of coral cover a better understanding of genetics is warranted.\n\nDescribe genetic structure and demographic history\n\nMotivation:\n\naddress basic question of why genetic structure looks the way it does\ndemographic history may generate signals similar to selection\n\n\n\n\n\nFigure 2: Variation and demographic history inferred from 44 resequenced individuals.\n\n\n\n\n\nFuller et al. (2020)\n\n\n\n\nVariation and demographic history\nWhy: summarizing diversity provides (indirect) information on population size and more, as does the linkage structure. Estimate demographic history since fluctuating population size may produce signals similar to those of selection\n\nLD decay: important for imputation (e.g., stephens_AccountingDecayLinkage_2005) and setting window size for genome scans, where a common rule of thumb is to set the size larger than the genome background: this ensures windows are, in some sense, independent\nThe extent of LD and its decay with genetic distance are useful parameters for determining the number of markers needed to successfully map a QTL, and the resolution with which the trait can be successfully mapped otyama_EvaluationLinkageDisequilibrium_2019\n0.363% average pi, but large variation.\nmany psmc plots show decline in population size, which could be an effect of bottleneck during pleistocene. Also population divergence (ghost ancestral populations, splits, extinction) can affect population size\nin aDNA studies missingness is common (i.e., heterozygotes are underestimated) and has to be accounted for since coalescence times are affected and may influence estimate of population size"
  },
  {
    "objectID": "slides/pgip/index.html#example-population-genetics-of-the-coral-acropora-millepora-2",
    "href": "slides/pgip/index.html#example-population-genetics-of-the-coral-acropora-millepora-2",
    "title": "Population genomics in practice",
    "section": "Example: Population genetics of the coral Acropora millepora",
    "text": "Example: Population genetics of the coral Acropora millepora\n\n\nMotivation: corals are facing hard times and to prevent future losses of coral cover a better understanding of genetics is warranted.\n\nCharacterize population structure\n\nMotivation:\n\nidentify populations for contrasts in e.g. selection scans\nidentify admixed individuals that should be removed from analyses\nidentify barriers to gene flow etc\n\n\n\n\n\nFigure 3: Characterizing population structure and gene flow across 12 refs\n\n\n\n\n\nFuller et al. (2020)\n\n\n\n\nPopulation structure:\nWhy: many reasons: 1) identifying populations for contrasts in e.g. selection scans 2) identify admixed individuals that should be removed from analyses 3) identify barriers to gene flow etc\n\nno discernible relationship between geographic distance and genetic differentiation -&gt; gene flow\n\nfor this reason, Fst between populations is low\n\nEEMS (Estimated Effective Migration Surfaces) models relationship between genetics and geography petkova_VisualizingSpatialPopulation_2016\n\nIndicative of high connectivity among 12 sampled reefs."
  },
  {
    "objectID": "slides/pgip/index.html#example-population-genetics-of-the-coral-acropora-millepora-3",
    "href": "slides/pgip/index.html#example-population-genetics-of-the-coral-acropora-millepora-3",
    "title": "Population genomics in practice",
    "section": "Example: Population genetics of the coral Acropora millepora",
    "text": "Example: Population genetics of the coral Acropora millepora\n\n\nMotivation: corals are facing hard times and to prevent future losses of coral cover a better understanding of genetics is warranted.\n\nGenomic scans for selection\n\nMotivation: identify loci associated with adaptation / selection\n\nlittle differentiation over reefs, however thermal regimes\ngenomic scan for \\(\\pi\\) (diversity) outliers\n\n\n\n\n\nFigure 4: Genomic scans for local adaptation detect a signal at sacsin\n\n\n\n\n\nFuller et al. (2020)\n\n\n\n\nSelection scan\nWhy: identify loci associated with adaptation / selection, which provides potential mechanisms for adaptation, as well as information that could be important for conservation strategies\nLittle differentiation across reefs -&gt; little population structure over hundreds of kilometers. However, there are environmental differences (thermal regimes). Scan for pi outliers:\n\npoints to sacsin gene\nh12 measures the frequency of the two most common haplotypes; red indicate 0.01% outlier genome-wide\n4C: tree for central 1kb region in sacsin deeper than split from A.digitifera and A.tenuis\n\nvariation in sacsin has been maintained for long time\nco-chaperone for heat-shock protein Hsp70"
  },
  {
    "objectID": "slides/pgip/index.html#example-population-genetics-of-the-coral-acropora-millepora-4",
    "href": "slides/pgip/index.html#example-population-genetics-of-the-coral-acropora-millepora-4",
    "title": "Population genomics in practice",
    "section": "Example: Population genetics of the coral Acropora millepora",
    "text": "Example: Population genetics of the coral Acropora millepora\nStudy highlights common analyses in population genomics study:\n\n\nGenome assembly, resequencing, variant calling and filtering\nDescription of variation (e.g., \\(\\pi\\)) and genetic structure (LD)\nDescription of population structure (admixture, PCA)\nModelling of demographic history (PSMC)\nGenome scans for adaptive traits"
  },
  {
    "objectID": "slides/pgip/index.html#population-genetics",
    "href": "slides/pgip/index.html#population-genetics",
    "title": "Population genomics in practice",
    "section": "Population genetics",
    "text": "Population genetics\n\n\n \n\n\nMutation\n\n\n\nSelection\n\n\n\n \n\n\nRecombination\n\n\n\nDrift\n\n\n\n\n(Fuller et al., 2020) paper has population genetics in title -&gt; population genetics is a key ingredient.\nPopulation genetics focuses on the genetic basis of evolution. It is mainly a theoretical subject, owing to the slow changes of genetic variation. As such, it tries to explain the shape and structure of genetic variation from theoretical predictions and models."
  },
  {
    "objectID": "slides/pgip/index.html#from-population-genetics-to-population-genomics",
    "href": "slides/pgip/index.html#from-population-genetics-to-population-genomics",
    "title": "Population genomics in practice",
    "section": "From population genetics to population genomics",
    "text": "From population genetics to population genomics\n\n\n\n\nThe variable sites at the Drosophila melanogaster ADH locus (Kreitman, 1983)\n\n\n\n\n\nFirst study of natural population. However, limited to one locus.\n\n\nfrom locus-based studies (e.g., alcohol dehydrogenase in Drosophila (Kreitman, 1983)) to genome-wide (e.g., Drosophila population genomics (Begun et al., 2007)\nnote: studied loci have often not been randomly chosen, which is another argument for whole-genome studies\nenabler: sequencing technology\n\n(Fuller et al., 2020) paper has population genetics in title -&gt; population genetics is a key ingredient.\nRefer to Hahn’s points about learning something about global patterns:\n\nselection acts locally, demography globally\nthe structure of genetic variation and how it depends on\n\nrecombination landscapes and linked selection\ndemographic changes\nidentification of neutral loci\n\n\nSo, not simply about applying 10000 selection tests for multiple loci\nAll of the points above point to the importance of statistics which implies mathematics / computational skills important"
  },
  {
    "objectID": "slides/pgip/index.html#from-population-genetics-to-population-genomics-1",
    "href": "slides/pgip/index.html#from-population-genetics-to-population-genomics-1",
    "title": "Population genomics in practice",
    "section": "From population genetics to population genomics",
    "text": "From population genetics to population genomics\n\n\n\nPatterns of polymorphism and divergence (Begun et al., 2007)\n\n\n\n\nSame system but genome-wide. Plots represent all chromosomes and the entire genome.\n\nBegun et al. (2007) study: same system (Drosophila) but more individuals and whole genome. All of a sudden possible to ask questions about the general characteristics of diversity, not just limited to single loci."
  },
  {
    "objectID": "slides/pgip/index.html#from-population-genetics-to-population-genomics-2",
    "href": "slides/pgip/index.html#from-population-genetics-to-population-genomics-2",
    "title": "Population genomics in practice",
    "section": "From population genetics to population genomics",
    "text": "From population genetics to population genomics\n\n\n\n\nNumbers of polymorphic and fixed variants (Begun et al., 2007)\n\n\n\n\n\nNovelty: now possible to do genome-wide characterization of variation in different functional contexts\n\nNovelty: now possible to do genome-wide characterization of variation in different functional contexts"
  },
  {
    "objectID": "slides/pgip/index.html#the-technological-revolution-in-sequencing-and-computing",
    "href": "slides/pgip/index.html#the-technological-revolution-in-sequencing-and-computing",
    "title": "Population genomics in practice",
    "section": "The technological revolution in sequencing and computing",
    "text": "The technological revolution in sequencing and computing\n\n\n\n\n\n\nFigure 5: Sequencing cost ($) per megabase (Wetterstrand, KA)\n\n\n\n\n\n\n\n\nMoore’s law"
  },
  {
    "objectID": "slides/pgip/index.html#statistical-inference-in-population-genomics",
    "href": "slides/pgip/index.html#statistical-inference-in-population-genomics",
    "title": "Population genomics in practice",
    "section": "Statistical inference in population genomics",
    "text": "Statistical inference in population genomics\nThe data deluge requires advanced statistical methods and models to do inference. Today data production outpaces theoretical advances. Therefore, take care not to attach too much faith to a test that explains data well.\n\nA population genomics study should aim at generating a baseline model that takes into account the processes that shape genetic variation (Johri et al., 2022):\n\nmutation\nrecombination\ngene conversion\npurifying selection acting on functional regions and its effects on linked variants (background selection)\ngenetic drift with demographic history and geographic structure\n\n\n\nCaution against adaptationist storytelling; always compare to a baseline model that takes potential confounding factors into account"
  },
  {
    "objectID": "slides/pgip/index.html#applications-of-population-genomics",
    "href": "slides/pgip/index.html#applications-of-population-genomics",
    "title": "Population genomics in practice",
    "section": "Applications of population genomics",
    "text": "Applications of population genomics\n\n\n\n\n\nconservation genomics (Webster et al., 2023)\n\n\n\n\n\nspeciation genomics (Stankowski et al., 2019)\n\n\n\n\n\ndisentangle forces that create variation (Rodrigues et al., 2023)\n\n\n\n\n\npaleogenomics (aDNA) (van der Valk et al., 2021)\n\n\n\n\n\ndomestication (Barrera-Redondo et al., 2020)\n\n\n\n\n\necology (Hohenlohe et al., 2019)"
  },
  {
    "objectID": "slides/pgip/index.html#bibliography",
    "href": "slides/pgip/index.html#bibliography",
    "title": "Population genomics in practice",
    "section": "Bibliography",
    "text": "Bibliography\n\n\nBarrera-Redondo, J., Piñero, D., & Eguiarte, L. E. (2020). Genomic, Transcriptomic and Epigenomic Tools to Study the Domestication of Plants and Animals: A Field Guide for Beginners. Frontiers in Genetics, 11.\n\n\nBegun, D. J., Holloway, A. K., Stevens, K., Hillier, L. W., Poh, Y.-P., Hahn, M. W., Nista, P. M., Jones, C. D., Kern, A. D., Dewey, C. N., Pachter, L., Myers, E., & Langley, C. H. (2007). Population Genomics: Whole-Genome Analysis of Polymorphism and Divergence in Drosophila simulans. PLOS Biology, 5(11), e310. https://doi.org/10.1371/journal.pbio.0050310\n\n\nFuller, Z. L., Mocellin, V. J. L., Morris, L. A., Cantin, N., Shepherd, J., Sarre, L., Peng, J., Liao, Y., Pickrell, J., Andolfatto, P., Matz, M., Bay, L. K., & Przeworski, M. (2020). Population genetics of the coral Acropora millepora: Toward genomic prediction of bleaching. Science, 369(6501), eaba4674. https://doi.org/10.1126/science.aba4674\n\n\nHahn, M. (2019). Molecular Population Genetics (First). Oxford University Press.\n\n\nHartl, D. L., & Clark, A. G. (1997). Principles of population genetics. Sinauer Associates.\n\n\nHohenlohe, P. A., Hand, B. K., Andrews, K. R., & Luikart, G. (2019). Population Genomics Provides Key Insights in Ecology and Evolution. In O. P. Rajora (Ed.), Population Genomics: Concepts, Approaches and Applications (pp. 483–510). Springer International Publishing. https://doi.org/10.1007/13836_2018_20\n\n\nJohri, P., Aquadro, C. F., Beaumont, M., Charlesworth, B., Excoffier, L., Eyre-Walker, A., Keightley, P. D., Lynch, M., McVean, G., Payseur, B. A., Pfeifer, S. P., Stephan, W., & Jensen, J. D. (2022). Recommendations for improving statistical inference in population genomics. PLOS Biology, 20(5), e3001669. https://doi.org/10.1371/journal.pbio.3001669\n\n\nKreitman, M. (1983). Nucleotide polymorphism at the alcohol dehydrogenase locus of Drosophila melanogaster. Nature, 304(5925), 412. https://doi.org/10.1038/304412a0\n\n\nLi, H., & Durbin, R. (2011). Inference of human population history from individual whole-genome sequences. Nature, 475(7357), 493–496. https://doi.org/10.1038/nature10231\n\n\nRodrigues, M. F., Kern, A. D., & Ralph, P. L. (2023). Shared evolutionary processes shape landscapes of genomic variation in the great apes (p. 2023.02.07.527547). bioRxiv. https://doi.org/10.1101/2023.02.07.527547\n\n\nStankowski, S., Chase, M. A., Fuiten, A. M., Rodrigues, M. F., Ralph, P. L., & Streisfeld, M. A. (2019). Widespread selection and gene flow shape the genomic landscape during a radiation of monkeyflowers. PLOS Biology, 17(7), e3000391. https://doi.org/10.1371/journal.pbio.3000391\n\n\nvan der Valk, T., Pečnerová, P., Díez-del-Molino, D., Bergström, A., Oppenheimer, J., Hartmann, S., Xenikoudakis, G., Thomas, J. A., Dehasque, M., Sağlıcan, E., Fidan, F. R., Barnes, I., Liu, S., Somel, M., Heintzman, P. D., Nikolskiy, P., Shapiro, B., Skoglund, P., Hofreiter, M., … Dalén, L. (2021). Million-year-old DNA sheds light on the genomic history of mammoths. Nature, 591(7849), 265–269. https://doi.org/10.1038/s41586-021-03224-9\n\n\nWebster, M. T., Beaurepaire, A., Neumann, P., & Stolle, E. (2023). Population Genomics for Insect Conservation. Annual Review of Animal Biosciences, 11(1), 115–140. https://doi.org/10.1146/annurev-animal-122221-075025\n\n\nWetterstrand, KA. DNA Sequencing Costs: Data from the NHGRI Genome Sequencing Program (GSP). www.genome.gov/sequencingcostsdata\n\n\n\n\nPopulation genomics in practice"
  },
  {
    "objectID": "slides/simulation/index.html#intended-learning-outcomes",
    "href": "slides/simulation/index.html#intended-learning-outcomes",
    "title": "Simulation",
    "section": "Intended learning outcomes",
    "text": "Intended learning outcomes\nIntroduction to the coalescent and simulation in msprime, with two exercises on the coalescent and msprime. The students should be able to:\n\nDescribe need for simulations\nDemonstrate the coalescent step by step\nDetail some properties of coalescent trees\nDefine the site-frequency spectrum\nDescribe the coalescent with recombination\nPerform simple simulations in msprime"
  },
  {
    "objectID": "slides/simulation/index.html#the-wright-fisher-model-and-simulations",
    "href": "slides/simulation/index.html#the-wright-fisher-model-and-simulations",
    "title": "Simulation",
    "section": "The Wright-Fisher model and simulations",
    "text": "The Wright-Fisher model and simulations\n\n\n\n\n\n\nFigure 1: Wright-Fisher model for 50 generations, 30 individuals\n\n\n\n\n\n\n\n\n\nRecap\nModel of a population describing genealogies under the following assumptions\n\ndiscrete and non-overlapping generations\nhaploid individuals or two subpopulations (males and females)\nconstant population size\nall individuals are equally fit\npopulation has no geographical or social structure\nno recombination\n\n\nForward simulation\n\n\n\n\n(p. 15 Hein et al., 2005) shows the fraction of genes without descendants. Focus on the number of descendants for one gene i, which is X ~ Bin(2N, 1/2N). Since E(X)=1, for large 2N, X is almos Po(1), such that P(no descendants) = P(X=0) = e^{-1}\nLow reproductive success: forward simulations costly!"
  },
  {
    "objectID": "slides/simulation/index.html#the-wright-fisher-model-and-simulations-1",
    "href": "slides/simulation/index.html#the-wright-fisher-model-and-simulations-1",
    "title": "Simulation",
    "section": "The Wright-Fisher model and simulations",
    "text": "The Wright-Fisher model and simulations\n\n\n\n\n\n\nFigure 2: Wright-Fisher model for 50 generations, 30 individuals\n\n\n\n\n\n\n\n\n\n\nFigure 3: Reproductive success in percent per generation.\n\n\n\n\n\n\nMean reproductive success = 63.4%. Can show for large populations P(no descendants)=\\(1 - e^{-1} \\approx 0.632\\)\n\n\n\n\n(p. 15 Hein et al., 2005) shows the fraction of genes without descendants. Focus on the number of descendants for one gene i, which is X ~ Bin(2N, 1/2N). Since E(X)=1, for large 2N, X is almos Po(1), such that P(no descendants) = P(X=0) = e^{-1}\nLow reproductive success: forward simulations costly!"
  },
  {
    "objectID": "slides/simulation/index.html#forward-and-backward-simulation",
    "href": "slides/simulation/index.html#forward-and-backward-simulation",
    "title": "Simulation",
    "section": "Forward and backward simulation",
    "text": "Forward and backward simulation\n\n\n\n\n\n\nFigure 4: Forward simulation.\n\n\n\n\n\n\n\n\n\n\nFigure 5: Backward simulation.\n\n\n\n\n\n\n\nSimulated nodes are filled with black. Genealogy of interest is highlighted in thick black lines.\n\nForward simulations: require that we keep track of the entire population -&gt; computationally challenging.\nBackward simulations: require only tracking the sample -&gt; quicker. However, cannot model selection."
  },
  {
    "objectID": "slides/simulation/index.html#why-do-we-want-simulations-anyway",
    "href": "slides/simulation/index.html#why-do-we-want-simulations-anyway",
    "title": "Simulation",
    "section": "Why do we want simulations anyway?",
    "text": "Why do we want simulations anyway?\n\n\nNull model\n\nGenerate neutral null distributions to compare with observed data\n\nExploration\n\nUse to gain understanding and improve interpretation of mutational processes\n\nMathematical complexity\n\nNo analytical solutions for linked selection and the like \\(\\rightarrow\\) must use simulations\n\nBenchmarking\n\nUse to generate test data with known properties on which to test and evaluate new methods\n\nModel training\n\nGenerate training data for machine learning, e.g., Approximate Bayesian Computation (ABC) or Neural Networks (NNs)"
  },
  {
    "objectID": "slides/simulation/index.html#coalescent-simulations",
    "href": "slides/simulation/index.html#coalescent-simulations",
    "title": "Simulation",
    "section": "Coalescent simulations",
    "text": "Coalescent simulations\n\n\nThe coalescent simulates the genealogy of a sample of individuals on which mutations are “sprinkled” according to a Poisson process.\n\nSimulate ancestry (genealogy)\n\n\n\n\n\n\n\n\n\n\nNB: only the samples on the genealogy are needed, but the entire population is shown as a means to compare with forward simulations."
  },
  {
    "objectID": "slides/simulation/index.html#coalescent-simulations-1",
    "href": "slides/simulation/index.html#coalescent-simulations-1",
    "title": "Simulation",
    "section": "Coalescent simulations",
    "text": "Coalescent simulations\n\n\nThe coalescent simulates the genealogy of a sample of individuals on which mutations are “sprinkled” according to a Poisson process.\n\nSimulate ancestry (genealogy)\nSimulate mutations"
  },
  {
    "objectID": "slides/simulation/index.html#coalescent-simulations-2",
    "href": "slides/simulation/index.html#coalescent-simulations-2",
    "title": "Simulation",
    "section": "Coalescent simulations",
    "text": "Coalescent simulations\n\n\nThe coalescent simulates the genealogy of a sample of individuals on which mutations are “sprinkled” according to a Poisson process.\n\nSimulate ancestry (genealogy)\nSimulate mutations\n\n\nExercise\n\nHow many mutations are common to all samples? How many mutations does sample 1 have? Sample 2?\nAssuming the ancestral state is denoted 0 (prior to the first generation) and the derived state 1, what are the sequences of the samples?\n\n\n\n\n\n\n\n\n\nAnswers to exercise: 2 mutations are common to all samples. Sample 1 has 3 mutations, sample 2 has 4.\n(arbitrarily) ordering the sites from top to bottom (oldest mutation comes first), the sequences are:\n1: 11100 2: 11101 3: 11010"
  },
  {
    "objectID": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115",
    "href": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115",
    "title": "Simulation",
    "section": "Simulating genealogies (Hahn, 2019, p. 115)",
    "text": "Simulating genealogies (Hahn, 2019, p. 115)\n\n\n\nStart with \\(i=n\\) chromosomes"
  },
  {
    "objectID": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-1",
    "href": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-1",
    "title": "Simulation",
    "section": "Simulating genealogies (Hahn, 2019, p. 115)",
    "text": "Simulating genealogies (Hahn, 2019, p. 115)\n\n\n\nStart with \\(i=n\\) chromosomes\nChoose time to next coalescent event from an exponential distribution with parameter \\(\\lambda=i(i-1)/2\\)"
  },
  {
    "objectID": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-2",
    "href": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-2",
    "title": "Simulation",
    "section": "Simulating genealogies (Hahn, 2019, p. 115)",
    "text": "Simulating genealogies (Hahn, 2019, p. 115)\n\n\n\nStart with \\(i=n\\) chromosomes\nChoose time to next coalescent event from an exponential distribution with parameter \\(\\lambda=i(i-1)/2\\)\nChoose two chromosomes at random to coalesce"
  },
  {
    "objectID": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-3",
    "href": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-3",
    "title": "Simulation",
    "section": "Simulating genealogies (Hahn, 2019, p. 115)",
    "text": "Simulating genealogies (Hahn, 2019, p. 115)\n\n\n\nStart with \\(i=n\\) chromosomes\nChoose time to next coalescent event from an exponential distribution with parameter \\(\\lambda=i(i-1)/2\\)\nChoose two chromosomes at random to coalesce\nMerge the two lineages and set \\(i \\rightarrow i - 1\\)"
  },
  {
    "objectID": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-4",
    "href": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-4",
    "title": "Simulation",
    "section": "Simulating genealogies (Hahn, 2019, p. 115)",
    "text": "Simulating genealogies (Hahn, 2019, p. 115)\n\n\n\nStart with \\(i=n\\) chromosomes\nChoose time to next coalescent event from an exponential distribution with parameter \\(\\lambda=i(i-1)/2\\)\nChoose two chromosomes at random to coalesce\nMerge the two lineages and set \\(i \\rightarrow i - 1\\)\nIf \\(i&gt;1\\), go to step 2; if not, stop."
  },
  {
    "objectID": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-5",
    "href": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-5",
    "title": "Simulation",
    "section": "Simulating genealogies (Hahn, 2019, p. 115)",
    "text": "Simulating genealogies (Hahn, 2019, p. 115)\n\n\n\nStart with \\(i=n\\) chromosomes\nChoose time to next coalescent event from an exponential distribution with parameter \\(\\lambda=i(i-1)/2\\)\nChoose two chromosomes at random to coalesce\nMerge the two lineages and set \\(i \\rightarrow i - 1\\)\nIf \\(i&gt;1\\), go to step 2; if not, stop."
  },
  {
    "objectID": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-6",
    "href": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-6",
    "title": "Simulation",
    "section": "Simulating genealogies (Hahn, 2019, p. 115)",
    "text": "Simulating genealogies (Hahn, 2019, p. 115)\n\n\n\nStart with \\(i=n\\) chromosomes\nChoose time to next coalescent event from an exponential distribution with parameter \\(\\lambda=i(i-1)/2\\)\nChoose two chromosomes at random to coalesce\nMerge the two lineages and set \\(i \\rightarrow i - 1\\)\nIf \\(i&gt;1\\), go to step 2; if not, stop."
  },
  {
    "objectID": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-7",
    "href": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-7",
    "title": "Simulation",
    "section": "Simulating genealogies (Hahn, 2019, p. 115)",
    "text": "Simulating genealogies (Hahn, 2019, p. 115)\n\n\n\nStart with \\(i=n\\) chromosomes\nChoose time to next coalescent event from an exponential distribution with parameter \\(\\lambda=i(i-1)/2\\)\nChoose two chromosomes at random to coalesce\nMerge the two lineages and set \\(i \\rightarrow i - 1\\)\nIf \\(i&gt;1\\), go to step 2; if not, stop."
  },
  {
    "objectID": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-8",
    "href": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-8",
    "title": "Simulation",
    "section": "Simulating genealogies (Hahn, 2019, p. 115)",
    "text": "Simulating genealogies (Hahn, 2019, p. 115)\n\n\n\nStart with \\(i=n\\) chromosomes\nChoose time to next coalescent event from an exponential distribution with parameter \\(\\lambda=i(i-1)/2\\)\nChoose two chromosomes at random to coalesce\nMerge the two lineages and set \\(i \\rightarrow i - 1\\)\nIf \\(i&gt;1\\), go to step 2; if not, stop."
  },
  {
    "objectID": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-9",
    "href": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-9",
    "title": "Simulation",
    "section": "Simulating genealogies (Hahn, 2019, p. 115)",
    "text": "Simulating genealogies (Hahn, 2019, p. 115)\n\n\n\nStart with \\(i=n\\) chromosomes\nChoose time to next coalescent event from an exponential distribution with parameter \\(\\lambda=i(i-1)/2\\)\nChoose two chromosomes at random to coalesce\nMerge the two lineages and set \\(i \\rightarrow i - 1\\)\nIf \\(i&gt;1\\), go to step 2; if not, stop."
  },
  {
    "objectID": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-10",
    "href": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-10",
    "title": "Simulation",
    "section": "Simulating genealogies (Hahn, 2019, p. 115)",
    "text": "Simulating genealogies (Hahn, 2019, p. 115)\n\n\n\nStart with \\(i=n\\) chromosomes\nChoose time to next coalescent event from an exponential distribution with parameter \\(\\lambda=i(i-1)/2\\)\\(^1\\)\nChoose two chromosomes at random to coalesce\nMerge the two lineages and set \\(i \\rightarrow i - 1\\)\nIf \\(i&gt;1\\), go to step 2; if not, stop.\n\n\n\\(^1\\): The exponential can be parametrized in two different ways, so that the parameter to the function is either \\(\\lambda\\) or \\(\\beta=1/\\lambda\\)."
  },
  {
    "objectID": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-11",
    "href": "slides/simulation/index.html#simulating-genealogies-hahn_molecularpopulationgenetics_2019-p.-115-11",
    "title": "Simulation",
    "section": "Simulating genealogies (Hahn, 2019, p. 115)",
    "text": "Simulating genealogies (Hahn, 2019, p. 115)\n\n\n\nStart with \\(i=n\\) chromosomes\nChoose time to next coalescent event from an exponential distribution with parameter \\(\\lambda=i(i-1)/2\\)\\(^1\\)\nChoose two chromosomes at random to coalesce\nMerge the two lineages and set \\(i \\rightarrow i - 1\\)\nIf \\(i&gt;1\\), go to step 2; if not, stop.\n\n\n\\(^1\\): The exponential can be parametrized in two different ways, so that the parameter to the function is either \\(\\lambda\\) or \\(\\beta=1/\\lambda\\).\n\n\n\n\n\n\nFigure 6: A simulated genealogy. The \\(T_i\\) represent the waiting time when the state has \\(i\\) chromosomes."
  },
  {
    "objectID": "slides/simulation/index.html#some-properties-of-the-tree",
    "href": "slides/simulation/index.html#some-properties-of-the-tree",
    "title": "Simulation",
    "section": "Some properties of the tree",
    "text": "Some properties of the tree\n\n\n\n\n\n\nFigure 7: A coalescent tree with numbered nodes. Nodes 1-5 correspond to the samples and are leaves. The internal nodes 6-8 (and the unlabelled root) are ancestral chromosomes (unsampled). The \\(T_i\\) represent the waiting time when the state has \\(i\\) chromosomes, whereas \\(\\tau_i\\) correspond to the branch length from node \\(i\\) to its parent.\n\n\n\n\n\n\nExpected waiting time to coalesce when \\(i\\) lineages: \\(E(T_i) = \\frac{2}{i(i-1)}\\)\nBranch lengths can be derived from waiting times. For instance, \\(\\tau_1=\\tau_2=T_5+T_4\\) and \\(\\tau_4=\\tau_5=T_5\\)\nTime to the most recent common ancestor (MRCA) is sum of wating times: \\(T_{MRCA} = \\sum_{i=2}^n T_i\\)\nwith expected value \\(E(T_{MRCA}) = \\sum_{i=2}^nE(T_i) = 2\\left(1 - \\frac{1}{n}\\right)\\)\nThe expected total tree height is \\(E(T_{total}) = \\sum_{i=2}^n iE(T_i) = 2\\sum_{i=2}^n\\frac{1}{i-1}\\)\n\n\n\nNote that the parametrization is in 2N generations (continuous time approximation); some use N, others 4N, and so on.\nExpected waiting time: the first expression follows from the fact that the waiting time, given \\(i\\) chromosomes, is exponentially distributed with parameter \\(\\lambda=i(i-1)/2\\). For an exponentially distributed variable \\(X\\), the expected value is simply \\(E(X)=1/\\lambda\\).\nOther relations are most easily derived by studying the tree and summing up relevant branches or time intervals."
  },
  {
    "objectID": "slides/simulation/index.html#coalescent-simulations-vary-in-topology-and-height",
    "href": "slides/simulation/index.html#coalescent-simulations-vary-in-topology-and-height",
    "title": "Simulation",
    "section": "Coalescent simulations vary in topology and height",
    "text": "Coalescent simulations vary in topology and height\n\n\nCode\nimport msprime\nseeds = [12, 15, 16, 34, 63, 30]\ntrees = [msprime.sim_ancestry(3, random_seed=x) for x in seeds]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExamples of coalescent simulations. Note the variation in tree topology and height."
  },
  {
    "objectID": "slides/simulation/index.html#diminishing-returns-of-adding-more-samples",
    "href": "slides/simulation/index.html#diminishing-returns-of-adding-more-samples",
    "title": "Simulation",
    "section": "Diminishing returns of adding more samples",
    "text": "Diminishing returns of adding more samples\n\n\n\n\n\nFigure 8: Dependence of \\(E[T_{MRCA}]\\) and \\(E[T_{total}]\\) on the sample size n. Already at low values of n the value of \\(E[T_{MRCA}]\\) is close to its asymptotic value, which has practical consequences for the measurement of DNA variation. Adapted from Wakeley (2008), Fig. 3.3.\n\n\n\n\n\n\n\nAdding a sample only adds \\(2/n\\) to the total tree length. Also, adding a sample will add little to \\(T_{MRCA}\\), or equivalently, will most likely add a very recent coalescent event to the tree for large enough \\(n\\). Note that \\(n=20\\) here is equivalent to 10 diploid individuals."
  },
  {
    "objectID": "slides/simulation/index.html#adding-mutations",
    "href": "slides/simulation/index.html#adding-mutations",
    "title": "Simulation",
    "section": "Adding mutations",
    "text": "Adding mutations\n\n\n\n\n\n\nFigure 9: Adding mutations on a coalescent genealogy.\n\n\n\n\n\n\nMutations are added by placing them on branches, where the probability of ending up on a branch \\(\\tau_i\\) is equal to its normalized length, where normalization is by the total tree branch length:\n\\[\nP(\\text{mutation on branch }i) = \\frac{\\tau_i}{\\sum_j\\tau_j} =\n\\frac{\\tau_i}{T_{total}}\n\\]\nThe total number of segregating sites \\(S\\) to be thrown on the tree is modelled as a Poisson random variable which expresses the probability of a given number of events in time \\(t\\):\n\\[\nS = Po(\\theta/2T_{total})\n\\]\n\n\n\nSofar we have looked at genealogies; now add mutations.\nIn words: sample a number of segregating sites from the Poisson distribution, and “sprinkle” them on the tree.\nThe parametrization \\(\\lambda = \\theta / 2\\) is defined with reference to the average heterozygosity between two sequences being \\(\\theta\\) (by Tajima; see Wakeley (2008), p. 92)"
  },
  {
    "objectID": "slides/simulation/index.html#the-coalescent-and-diversity",
    "href": "slides/simulation/index.html#the-coalescent-and-diversity",
    "title": "Simulation",
    "section": "The coalescent and diversity",
    "text": "The coalescent and diversity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\nT\nT\nA\nC\nA\nA\nT\nC\nC\nG\nA\nT\nC\nG\nT\n\n\nT\nT\nA\nC\nG\nA\nT\nG\nC\nG\nC\nT\nC\nG\nT\n\n\nT\nC\nA\nC\nA\nA\nT\nG\nC\nG\nA\nT\nG\nG\nA\n\n\nT\nT\nA\nC\nG\nA\nT\nG\nC\nG\nC\nT\nC\nG\nT\n\n\n\n*\n\n\n*\n\n\n*\n\n\n*\n\n*\n\n*\n\n\n\n\n\n\n\\[\n\\begin{align}\n\\pi & = \\sum_{j=1}^S h_j = \\sum_{j=1}^{S} \\frac{n}{n-1}\\left(1 - \\sum_i p_i^2 \\right) \\\\\n& \\stackrel{S=6,\\\\ n=4}{=} \\sum_{j=1}^{6} \\frac{4}{3}\\left(1 - \\sum_i p_i^2\\right) \\\\\n& = \\frac{4}{3}\\left(\\mathbf{\\color{#a7c947}{4}}\\left(1-\\frac{1}{16}-\\frac{9}{16}\\right) + \\mathbf{\\color{#a7c947}{2}}\\left(1 - \\frac{1}{4} - \\frac{1}{4}\\right)\\right) = \\frac{10}{3}\n\\end{align}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this notation one can show that \\(\\pi\\), the nucleotide diversity, is\n\\[\n\\begin{align}\n\\pi & = \\frac{\\sum_{i=1}^{n-1}i(n-i)\\xi_i}{n(n-1)/2} \\\\\n& \\stackrel{n=4}{=} \\frac{1*(4-1)*4 + 2*(4-2)*2}{6}\n= \\frac{10}{3}\n\\end{align}\n\\]\n\n\n\n\nMany statistical quantities can be related to the site frequency spectrum (SFS), which is a summary of the frequencies of the segregating sites. Let \\(\\xi_i\\) be the number of chromosomes in the sample with \\(i\\) minor alleles. In the example above we have \\(S=6\\) mutations on \\(n=4\\) chromosomes."
  },
  {
    "objectID": "slides/simulation/index.html#the-impact-of-topology-on-the-sfs",
    "href": "slides/simulation/index.html#the-impact-of-topology-on-the-sfs",
    "title": "Simulation",
    "section": "The impact of topology on the SFS",
    "text": "The impact of topology on the SFS\n\n\n\n\n\nNeutral\n\n\n\n\n\n\n\nExpansion\n\n\n\n\n\n\n\nBottleneck\n\n\n\n\n\n\n\nSelection\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: The SFS under neutrality and selection\n\n\n\n\nMany tests for selection are based on the SFS which in turn is influenced by the topology of the tree.\n\n\n\nTake home: topologies influence shape of SFS\nExample: Tajima’s D\nTests common versus rare alleles. Numerator compares nucleotide diversity \\(\\pi\\) to Watterson’s theta, \\(\\theta_W\\).\n\nD &lt; 0\n\nrecent population increase or positive selection\n\nD &gt; 0\n\npopulation contraction or balancing selection"
  },
  {
    "objectID": "slides/simulation/index.html#on-non-recombining-chromosomes-and-assortment",
    "href": "slides/simulation/index.html#on-non-recombining-chromosomes-and-assortment",
    "title": "Simulation",
    "section": "On non-recombining chromosomes and assortment",
    "text": "On non-recombining chromosomes and assortment\n\n\n\n\n\n\n\n\n\n\n\nBoth siblings inherit chromosome from paternal grandfather\nChromosomes coalesce at father\n\n\n\n\n\n\n\n\n\n\n\nSiblings inherit different grandparental chromosomes \\(\\Rightarrow\\) chromosomes coalesce God knows when in the past\nGenealogies differ\n\n\n\n\nNB: the right genealogy is so small the sequences don’t coalesce. The following slide will show a larger genealogy where all sequence coalesce."
  },
  {
    "objectID": "slides/simulation/index.html#the-ancestral-recombination-graph",
    "href": "slides/simulation/index.html#the-ancestral-recombination-graph",
    "title": "Simulation",
    "section": "The ancestral recombination graph",
    "text": "The ancestral recombination graph\n\n  \n\nY. C. Brandt et al. (2022, fig. 1a)\n\n\nProperties:\n\nmarginal trees constitute a sequence of trees (tree sequence) along a chromosome\neach tree represents the genealogy of a non-recombining part of the chromosome\nneighbouring trees are correlated\n\nInterpretation: chromosomes are mosaics of non-recombining units\n\nGoing backwards in time, we now have two events to track. We have already encountered coalescence, that is, the merging of lineages. We now also need to monitor recombination events, at which point a genealogy splits into two separate paths. A recombination event takes place on a sequence, such that the genealogical history of the recombined sequence differs on either side of the recombination breakpoint. In the ARG, by convention the sequence to the left of the breakpoint takes the left path, the sequence to the right the right path.\nThe end consequence of recombination is that the chromosome/sequence will consist of non-recombining units with different genealogical histories. However, neighbouring genealogies will be similar - they are correlated - a fact that is of importance for the tree sequence data structure used in msprime."
  },
  {
    "objectID": "slides/simulation/index.html#the-ancestral-recombination-graph-as-sequence-of-trees",
    "href": "slides/simulation/index.html#the-ancestral-recombination-graph-as-sequence-of-trees",
    "title": "Simulation",
    "section": "The ancestral recombination graph as sequence of trees",
    "text": "The ancestral recombination graph as sequence of trees\n\n\n\n\nThe ancestral recombination graph as a tree sequence (Baumdicker et al., 2022, fig. 5)\n\n\n\n\nProperties:\n\nmarginal trees constitute a sequence of trees (tree sequence) along a chromosome\neach tree represents the genealogy of a non-recombining part of the chromosome\nneighbouring trees are correlated\n\nInterpretation: chromosomes are mosaics of non-recombining units"
  },
  {
    "objectID": "slides/simulation/index.html#msprime-is-a-fast-coalescent-simulator",
    "href": "slides/simulation/index.html#msprime-is-a-fast-coalescent-simulator",
    "title": "Simulation",
    "section": "msprime is a fast coalescent simulator",
    "text": "msprime is a fast coalescent simulator\nOriginal coalescent simulator implementions assumed small sample sizes and could only simulate short recombining sequences. msprime was developed to address these shortcomings as today we have\n\nchromosome-level assemblies that require full treatment of recombination (very complex problem)\nbiobank datasets consisting of 100’s of thousands of samples\n\n\n\nFeatures\n\ncan simulate millions of whole chromosomes\nwell-designed mature API\nsuccinct data structure (tree sequences) has led to advances in forwards-time simulation\ncan be used together with forwards-time simulators\n\n\nLimitations\n\nassumes neutrality - can’t simulate selection"
  },
  {
    "objectID": "slides/simulation/index.html#msprime-stores-variation-data-as-tree-sequences",
    "href": "slides/simulation/index.html#msprime-stores-variation-data-as-tree-sequences",
    "title": "Simulation",
    "section": "msprime stores variation data as tree sequences",
    "text": "msprime stores variation data as tree sequences\n\nTree sequences (Baumdicker et al., 2022, fig. 2)"
  },
  {
    "objectID": "slides/simulation/index.html#tree-sequences-compress-data",
    "href": "slides/simulation/index.html#tree-sequences-compress-data",
    "title": "Simulation",
    "section": "Tree sequences compress data",
    "text": "Tree sequences compress data\n\nData compression (Kelleher et al., 2019, fig. 1c)"
  },
  {
    "objectID": "slides/simulation/index.html#simulating-ancestry-with-msprime",
    "href": "slides/simulation/index.html#simulating-ancestry-with-msprime",
    "title": "Simulation",
    "section": "Simulating ancestry with msprime",
    "text": "Simulating ancestry with msprime\n\nFrom msprime quickstart\n\nimport msprime\n# Simulate an ancestral history for 3 diploid samples under the coalescent\n# with recombination on a 5kb region with human-like parameters.\nts = msprime.sim_ancestry(\n    samples=3,\n    recombination_rate=1e-8,\n    sequence_length=5_000,\n    population_size=10_000,\n    random_seed=123456)\nprint(ts.draw_svg())\n\n\n\nGenome position0141782400150003158402691013315840269101231584026910113501784291011"
  },
  {
    "objectID": "slides/simulation/index.html#simulating-mutations-with-msprime",
    "href": "slides/simulation/index.html#simulating-mutations-with-msprime",
    "title": "Simulation",
    "section": "Simulating mutations with msprime",
    "text": "Simulating mutations with msprime\nimport msprime\nts = msprime.sim_ancestry(\n    samples=3,\n    recombination_rate=1e-8,\n    sequence_length=5_000,\n    population_size=10_000,\n    random_seed=123456)\nmutated_ts = msprime.sim_mutations(ts, rate=1e-8, random_seed=54321)\nprint(mutated_ts.draw_svg())\n\n\n\nGenome position01417824001500031584026901013315840269110123315840262910113501784291011"
  },
  {
    "objectID": "slides/simulation/index.html#slim",
    "href": "slides/simulation/index.html#slim",
    "title": "Simulation",
    "section": "SLiM",
    "text": "SLiM\nSLiM (Selection on Linked Mutations) (Haller & Messer, 2019) is a forwards-time simulator. As its name implies, it models selection and thus is a complement to coalescent-based simulators.\n\n\nWhy SLiM?\n\nflexibility - scripting language Eidos allows for modelling complex scenarios with little code\nperformance - optimized code base\nGUI - interactive execution and graphical debugging\n\n\nHaller & Messer (2022)"
  },
  {
    "objectID": "slides/simulation/index.html#forward-simulation-in-slim-1",
    "href": "slides/simulation/index.html#forward-simulation-in-slim-1",
    "title": "Simulation",
    "section": "Forward simulation in SLiM",
    "text": "Forward simulation in SLiM\n\n\n\nExecution of first() events\nExecution of early() events\nGeneration of offspring; for each offspring:\n\nChoose source subpop for parental individuals, based on migration rates\nChoose parent 1, based on cached fitness values\nChoose parent 2, based on fitness and any defined mateChoice() callbacks\nGenerate the candidate offspring, with mutation and recombination (including mutation() and recombination() callbacks)\nSuppress/modify the candidate, using defined modifyChild() callbacks\n\nRemoval of fixed mutations unless convertToSubstitution==F\nOffspring become parents\nExecution of late() events\nFitness recalculation using mutationEffect() and fitnessEffect() callbacks\nTick/cycle count increment\n\n\n\n\n\n\nFigure 11: Forward simulation.\n\n\n\n\n\n\n\n\nSLiM works forward in time according to a tick cycle, which basically is a counter of time steps.\nHaller & Messer (2019), pp. 603–610 describes the steps in more details; some clarifying comments are added belowe wrt to the slide flowchart. There is a lot to unpack here, and the summary flowchart captures most of the essentials.\n\nfirst events: prior to generation of offspring; don’t affect fitness. Rare use.\nearly: catch-all event to do things before generation of offspring\ngeneration of offspring\n\nChoose source subpop for parental individuals, based on migration rates\nChoose parent 1, based on cached fitness values\nChoose parent 2, based on fitness and any defined mateChoice() callbacks\nGenerate the candidate offspring, with mutation and recombination (including mutation() and recombination() callbacks)\nSuppress/modify the candidate, using defined modifyChild() callbacks\n\nRemoval of fixed mutations unless convertToSubstitution==F - for simulation efficiency reasons\nOffspring become parents\nExecution of late() events - e.g., changing of selection or dominance coefficients\nFitness recalculation using mutationEffect() and fitnessEffect() callbacks\nTick/cycle count increment"
  },
  {
    "objectID": "slides/simulation/index.html#simple-neutral-simulation-in-slim",
    "href": "slides/simulation/index.html#simple-neutral-simulation-in-slim",
    "title": "Simulation",
    "section": "Simple neutral simulation in SLiM",
    "text": "Simple neutral simulation in SLiM\n\n// set up a simple neutral simulation\ninitialize()\n{\n// set the overall mutation rate\ninitializeMutationRate(1e-7);\n// m1 mutation type: neutral\ninitializeMutationType(\"m1\", 0.5, \"f\", 0.0);\n// g1 genomic element type: uses m1 for all mutations\ninitializeGenomicElementType(\"g1\", m1, 1.0);\n// uniform chromosome of length 100 kb\ninitializeGenomicElement(g1, 0, 99999);\n// uniform recombination along the chromosome\ninitializeRecombinationRate(1e-8);\n}\n// create a population of 500 individuals\n1 early()\n{\nsim.addSubpop(\"p1\", 500);\n}\n// run to tick 10000\n10000 early()\n{\nsim.simulationFinished();\n}\n\nComes with a huge manual (Haller & Messer, 2022) (700+ pages!)"
  },
  {
    "objectID": "slides/simulation/index.html#recapitation---combining-the-best-of-two-worlds",
    "href": "slides/simulation/index.html#recapitation---combining-the-best-of-two-worlds",
    "title": "Simulation",
    "section": "Recapitation - combining the best of two worlds",
    "text": "Recapitation - combining the best of two worlds\n\n\nA recent addition to SLiM is that it records data in tree sequence format (as in msprime)  we can combine backward and forward simulations!\n\n\n\nBackward simulation that adds coalescent (neutral) history\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nForward simulation with selection or some other process that isn’t supported by the coalescent"
  },
  {
    "objectID": "slides/simulation/index.html#simulation-of-null-distributions",
    "href": "slides/simulation/index.html#simulation-of-null-distributions",
    "title": "Simulation",
    "section": "Simulation of null distributions",
    "text": "Simulation of null distributions\n\n\n\nFigure 12: Empirical distribution function of SweepFinder2 composite likelihood ratio (CLR) scores from observed data versus null simulations for three populations of squash bee (E. pruinosa). msprime was used to simulate data (without selection) using the inferred demographic model and recombination map. The eastern population in particular shows signs of selective sweeps. Pope et al. (2023), Fig S8.\n\n\n\n\n\nAuthors inferred demographic history and recombination map. The inferred values were used to simulate data with msprime. SweepFinder2 (DeGiorgio et al., 2016) was used to calculate composite likelihood ratio (CLR) scores on both observed and simulated data to assess significance quantiles.\n\n\nThe details of the sweep finding / paper are not the main point here; rather, we want to highlight the use of simulations to generate null distribution scores (here, for CLR values) such that significance quantiles can be derived and applied to the observed data.\nOriginal figure legend:\n\nEmpiricial distribution functions of SWEEPFINDER 2 composite likelihood ratio (CLR) scores from the observed data and null simulations for each major E. pruinosa lineage (log-transformed for visualization). The null simulations were generated using the inferred demographic model and recombination maps (see Methods in main text). The observed and null distributions match each other quite closely in the Mexican lineage (MX). In the Western lineage (CO), the tail of the CLR score distribution deviates slightly from the null simulations. In the Eastern lineage (PA), the tail of the observed CLR score distribution is extremely heavy relative to the null. This suggests the existence of selective sweeps in both CO and PA, but especially in PA"
  },
  {
    "objectID": "slides/simulation/index.html#simulations-of-genomic-landscapes-in-monkeyflower",
    "href": "slides/simulation/index.html#simulations-of-genomic-landscapes-in-monkeyflower",
    "title": "Simulation",
    "section": "Simulations of genomic landscapes in monkeyflower",
    "text": "Simulations of genomic landscapes in monkeyflower\n\n\n\n\n\nFigure 13: Sampling locations\n\n\n\n\n\n\n\n\nFigure 14: Genomic landscapes simulated under different divergence histories.\n\n\n\n\n\n\nMonkeyflower (Mimulus aurantiacus) radiation in California shows wide adaptive range and phenotypic diversity. Stankowski et al. (2019) et al use simulations (SLiM and msprime) to shed light on processes that shape genomic landscapes, which are correlated between species.\n\nWe will look more closely at this system tomorrow.\n\n\nSimulations are based on variations of a neutral base model that starts out with an ancestral population (N=10,000) that after 10N generation splits to two daughter populations (N=10,000 each) and are simulated another 10N generations. The chromosome is 21Mbp (similar in size to a monkeyflower chromosome) consisting of a central neutrally evolving region flanked by two regions where non-neutral processes are “allowed”. Models are:\n\nneutral\nBGS (non-neutral mutations are deleterious)\nBateson-Dobzhansky-Muller incompatibility (BDMI); after split, fraction variants deleterious in one population, neutral in other\npositive selection\nBGS and positive selection\nlocal adaptation; 4 but also after split some variants beneficial in one population, neutral in other\n\nFigure caption:\n\nFig 7. Genomic landscapes simulated under different divergence histories. Each row of plots shows patterns of within- and between-population variation (π, dxy, and FST) across the chromosome (500-kb windows) at 5 time points (N generations, where N = 10,000) during one of the scenarios The selection parameter (Ns, where s = Ns/N), proportion of deleterious (−) and positive mutations (+), and number of migrants per generation (Nm; 0 unless stated) for these simulations are as follows: (i) neutral divergence (no selection), (ii) BGS (−Ns = 100; −prop = 0.1), (iii) BDMI (−Ns = 100, −prop = 0.05, Nm = 0.1), (iv) positive selection (+Ns = 100, +prop = 0.001), (v) BGS and positive selection (−Ns = 100, −prop = 0.1; +Ns = 100, +prop = 0.005), and (vi) local adaptation (+Ns = 100, +prop = 0.001, Nm = 0.1). The gray boxes in the first column show the areas of the chromosome that are experiencing selection, while the white central area evolves neutrally. Note that π (in populations a and b) and dxy have been mean centered so they can be viewed on the same scale. Uncentered values and additional simulations with different parameter combinations and more time points can be found in S13 Fig. BDMI, Bateson-Dobzhansky-Muller incompatibility; BGS, background selection."
  },
  {
    "objectID": "slides/simulation/index.html#neural-network-recombination-landscape-prediction",
    "href": "slides/simulation/index.html#neural-network-recombination-landscape-prediction",
    "title": "Simulation",
    "section": "Neural network recombination landscape prediction",
    "text": "Neural network recombination landscape prediction\n\n\n\n\nFigure 15: Cartoon of Recombination Landscape Estimation using Recurrent Neural Networks (ReLERNN) workflow (Adrion et al., 2020)\n\n\n\n\n\nUse msprime simulations to generate training data for neural network.\n\nMethods paper; one of the first examples of using msprime simulations to generate training data for a neural network.\nFigure caption:\n\nA cartoon depicting a typical workflow using ReLERNN’s four modules (shaded boxes) for (A) individually sequenced genomes or (B) pooled sequences. ReLERNN can optionally (dotted lines) utilize output from stairwayplot, SMC++, and MSMC to simulate under a demographic history with msprime. Training inlays show the network architectures used, with the GRU inlay in (B) depicting the gated connections within each hidden unit. Here, r, z, ht, and ht˜ are the reset gate, update gate, activation, and candidate activation, respectively (Cho et al. 2014). The genotype matrix encodes alleles as reference (−1), alternative (1), or padded/missing data (0; not shown). Variant positions are encoded along the real number line (0–1)."
  },
  {
    "objectID": "slides/simulation/index.html#bibliography",
    "href": "slides/simulation/index.html#bibliography",
    "title": "Simulation",
    "section": "Bibliography",
    "text": "Bibliography\n\n\nAdrion, J. R., Galloway, J. G., & Kern, A. D. (2020). Predicting the Landscape of Recombination Using Deep Learning. Molecular Biology and Evolution, 37(6), 1790–1808. https://doi.org/10.1093/molbev/msaa038\n\n\nBaumdicker, F., Bisschop, G., Goldstein, D., Gower, G., Ragsdale, A. P., Tsambos, G., Zhu, S., Eldon, B., Ellerman, E. C., Galloway, J. G., Gladstein, A. L., Gorjanc, G., Guo, B., Jeffery, B., Kretzschumar, W. W., Lohse, K., Matschiner, M., Nelson, D., Pope, N. S., … Kelleher, J. (2022). Efficient ancestry and mutation simulation with msprime 1.0. Genetics, 220(3), iyab229. https://doi.org/10.1093/genetics/iyab229\n\n\nDeGiorgio, M., Huber, C. D., Hubisz, M. J., Hellmann, I., & Nielsen, R. (2016). SweepFinder2: Increased sensitivity, robustness and flexibility. Bioinformatics, 32(12), 1895–1897. https://doi.org/10.1093/bioinformatics/btw051\n\n\nHahn, M. (2019). Molecular Population Genetics (First). Oxford University Press.\n\n\nHaller, B. C., & Messer, P. W. (2019). SLiM 3: Forward Genetic Simulations Beyond the Wright. Molecular Biology and Evolution, 36(3), 632–637. https://doi.org/10.1093/molbev/msy228\n\n\nHaller, B. C., & Messer, P. W. (2022). SLiM: An Evolutionary Simulation Framework.\n\n\nHein, J., Schierup, M. H., & Wiuf, C. (2005). Gene genealogies, variation and evolution: A primer in coalescent theory. Oxford University Press. https://books.google.se/books?id=CCmLNAEACAAJ\n\n\nKelleher, J., Wong, Y., Wohns, A. W., Fadil, C., Albers, P. K., & McVean, G. (2019). Inferring whole-genome histories in large population datasets. Nature Genetics, 51(9), 1330–1338. https://doi.org/10.1038/s41588-019-0483-y\n\n\nPope, N. S., Singh, A., Childers, A. K., Kapheim, K. M., Evans, J. D., & López-Uribe, M. M. (2023). The expansion of agriculture has shaped the recent evolutionary history of a specialized squash pollinator. Proceedings of the National Academy of Sciences, 120(15), e2208116120. https://doi.org/10.1073/pnas.2208116120\n\n\nStankowski, S., Chase, M. A., Fuiten, A. M., Rodrigues, M. F., Ralph, P. L., & Streisfeld, M. A. (2019). Widespread selection and gene flow shape the genomic landscape during a radiation of monkeyflowers. PLOS Biology, 17(7), e3000391. https://doi.org/10.1371/journal.pbio.3000391\n\n\nWakeley, J. (2008). Coalescent Theory: An Introduction (1st Edition edition). Roberts and Company Publishers.\n\n\nY. C. Brandt, D., Wei, X., Deng, Y., Vaughn, A. H., & Nielsen, R. (2022). Evaluation of methods for estimating coalescence times using ancestral recombination graphs. Genetics, iyac044. https://doi.org/10.1093/genetics/iyac044\n\n\n\n\nSimulation primer"
  },
  {
    "objectID": "slides/variant_filtering/index.html#why-we-need-to-filter-variants",
    "href": "slides/variant_filtering/index.html#why-we-need-to-filter-variants",
    "title": "Variant filtering",
    "section": "Why we need to filter variants",
    "text": "Why we need to filter variants\n\n\n\n\nFigure 1: Overlap in raw variant calls for different combinations of read mappers and variant callers.\n\n\n\nError rate of variant calls (SNPs and INDELs) largely unknown. Two major sources of error are\n\nerroneous realignment in low-complexity regions\nincomplete reference sequence\n\n\n\n\nFigure 2: Overlap in filtered variant calls for different combinations of read mappers and variant callers\n\n\n\n\nLi (2014)\n\n\n\nError rate of variant calls (SNPs and INDELs) and leading causal artifacts remain unclear and largely unknown (Li, 2014). This study compared several read mappers and variant callers on a haploid data set. For comparison, the following variant filters were applied:\n\nlow-complexity (LC) filter\nmaximum depth (MD)\nallele balance (AD) - filter sites where non-reference (ALT) too low\ndouble strand (DS) - filter if ALT too low on one strand\nFisher strand (FS) - filter if strong REF/ALT correlation with +/- strand\nquality filter (QU) - variant quality threshold\n\nHere, AB, DS and FS filters are caller dependent!"
  },
  {
    "objectID": "slides/variant_filtering/index.html#manual-filtering-sets-thresholds-on-context-statistics",
    "href": "slides/variant_filtering/index.html#manual-filtering-sets-thresholds-on-context-statistics",
    "title": "Variant filtering",
    "section": "Manual filtering sets thresholds on context statistics",
    "text": "Manual filtering sets thresholds on context statistics\n\n\n\n\nTable 1: Key data filters (Table 3 Lou et al., 2021, p. 5974)\n\n\n\n\n\n\n\nCategory\nFilter\nRecommendation (examples)\n\n\n\n\nGeneral filters\nBase quality\nRecalibrate / &lt;Q20\n\n\n\nMapping quality\nMAQ &lt; 20 / improper pairs\n\n\n\nMinimum depth and/ or number of individuals\nVaries; e.g. &lt;50% individuals, &lt;0.8X average depth\n\n\n\nMaximum depth\n1-2 sd above median depth\n\n\n\nDuplicate reads\nRemove\n\n\n\nIndels\nRealign reads / haplotype-based caller / exclude bases flanking indels\n\n\n\nOverlapping sections of paired-­end reads\nSoft-clip to avoid double-counting\n\n\nFilters on polymorphic sites\n\\(p\\)-value\n\\(10^{-6}\\)\n\n\n\nSNPs with more than two alleles\nFilter; methods often assume bi-allelic sites\n\n\n\nMinimum minor allele frequency (MAF)\n1%-10% for some analyses (PCA/admixture/LD/\\(\\mathsf{F_{ST}}\\))\n\n\nRestricting analysis to a predefined site list\nList of global SNPs\nUse global call set for analyses requiring shared sites\n\n\n\n\n\n\nProcedure\nLook at annotations (context statistics) and set thresholds.\nExample: filter all sites with MAF&lt;1%\n\nNB: bypassing recommendations often means doing custom analyses. For instance, Talla et al. (2019) include GATK tri-allelic sites due to different bi-allelic pairs segregating in different subpopulations (e.g. A/G in pop 1, A/T in pop 2)\nVerbose explanations of filters\nSource: (Lou et al., 2021)\n\nBase quality scores are factored into the calculation of genotype likelihoods, so if they accurately reflect the probability of sequencing error, bases with low scores also carry useful information. However, base quality scores are sometimes miscalibrated, so noise may be reduced if bases with scores below a threshold (e.g., 20) are either trimmed off prior to analysis or ignored. Alternatively, all base quality scores can be recalibrated based on estimated error profiles in the data (see Section 3.1).\nMapping quality is not considered in genotype likelihood estimation in currently available tools, so it is often advisable to remove low-­confidence and/or nonuniquely mapped reads prior to analysis (e.g., reads with mapping quality &lt;20). Filtering out reads that do not map in proper pairs should also further increase confidence in reads being mapped to the correct location, but could cause biases in regions with structural variation.\nTo avoid sites with low or confounding data support in downstream analysis, minimum depth and/or minimum number of individual filters can be used to exclude sites with much reduced sequencing coverage compared to the rest of the genome (e.g., regions with low unique mapping rates, such as repetitive sequences). Appropriate thresholds will vary between data sets, but could, for example, exclude sites with read data for &lt;50% of individuals (globally or within each population), or with &lt;0.8× average depth across individuals (after filtering on mapping quality)\nMaximum depth filters are used to exclude sites with exceptionally high coverage (e.g., regions that are susceptible to dubious mapping, such as copy number variants). Common maximum depth thresholds could be one or two standard deviations above the median genome-­wide depth.\nPCR and optical duplicates can give inflated impressions of how many unique molecules have been sequenced, which—­particularly in the presence of preferential amplification of one allele—­ could bias genotype likelihood estimation. We therefore recommend removing duplicate reads prior to any analysis.\nReads mapped across indels are frequently misaligned, especially if the ends of reads span an indel. To avoid false SNP calls, we recommend either using dedicated tools to realign reads covering indels, using a haplotype-­based variant caller (e.g., freebayes or gatk) to estimate genotype likelihoods, or excluding bases flanking indels.\nIf the DNA insert in a library fragment is shorter than the combined length of paired reads, there will be a section of overlap between the forward and reverse reads. While some variant callers (e.g., gatk) account for the pseudoreplication in overlapping ends of read pairs, the current implementation of angsd treats each end of a read pair as independent (this may change in a future release (T. Korneliussen, personal communication)). When treated as independent, read support for overlapping sections will be “double counted,” which may bias genotype likelihoods. A conservative approach is to soft-­clip one of the overlapping read ends.\nThe significance threshold (often in the form of maximum p-­value) can be adjusted to fine-­tune the sensitivity of polymorphism detection, with lower p-­values leading to fewer, but higher confidence, SNP calls. A commonly used cut-­off is 10 −6.\nMost software programs for downstream analyses assume that all SNPs are biallelic, so SNPs with more than two alleles can be filtered out in the SNP identification step to avoid violation of such assumptions.\nFor many types of analysis, such as PCA, admixture analysis, detection of FST outliers and estimation of LD, low-­frequency SNPs are uninformative and can even bias results (e.g. Linck & Battey, 2019; Roesti et al., 2012). For those types of analysis, imposing a minimum MAF filter of 1%–­10% can substantially speed up computation time. Appropriate thresholds depend on coverage, sample size (how many copies does an MAF threshold correspond to) and the type of downstream analysis.\nFor comparison of parameter estimates for multiple populations, it is important to ensure that data are obtained for a shared set of sites and that SNP polarization (which allele we track the frequency of) is consistent. For programs such as angsd where population-­specific estimates are obtained by analysing the data from each population separately, a good strategy is to first conduct a global SNP calling with all samples and then restrict population-­specific analysis to those SNPs with consistent major and minor allele designations (-­doMajorMinor 3 in angsd) no MAF or SNP p-­value filter (because that would incorrectly generate “missing data” if a site is fixed in a particular population)."
  },
  {
    "objectID": "slides/variant_filtering/index.html#guidelines-what-guidelines",
    "href": "slides/variant_filtering/index.html#guidelines-what-guidelines",
    "title": "Variant filtering",
    "section": "Guidelines? What guidelines?",
    "text": "Guidelines? What guidelines?\nGATK hard filters\n\nHowever, because we want to help, we have formulated some generic recommendations that should at least provide a starting point for people to experiment with their data.\n\n\n\n\nSNPs\nQualByDepth (QD) &lt; 2.0\nRMSMappingQuality (MQ) &lt; 40.0\nFisherStrand (FS) &gt; 60.0\nStrandOddsRatio (SOR) &gt; 3.0\nMappingQualityRankSumTest (MQRankSum) &lt; -12.5\nReadPosRankSumTest (ReadPosRankSum) &lt; -8.0\n\nIndels\nQualByDepth (QD) &lt; 2.0\nReadPosRankSum (ReadPosRankSumTest) &lt; -20.0\nInbreedingCoeff &lt; -0.8\nFisherStrand (FS) &gt; 200.0\nStrandOddsRatio (SOR) &gt; 10.0\n\n\n\n\n\nThat said, you ABSOLUTELY SHOULD NOT expect to run these commands and be done with your analyses.\n\n\n\nhttps://gatk.broadinstitute.org/hc/en-us/articles/360037499012\n\n\n\nOn RAD-seq filtering\n\n… the effects of SNP filtering practices on population genetic inference have received much less attention\n\n\nThere Is No ‘Rule of Thumb’: Genomic Filter Settings for a Small Plant Population to Obtain Unbiased Gene Flow Estimates (Nazareno & Knowles, 2021)\n\n\n\nGeneral guidelines on manual filters are not discussed much in the literature, simply due to the fact that there is no set of rule of thumbs. Every problem requires its own settings, as the GATK developers maintain.\nGATK guidelines explained (see https://gatk.broadinstitute.org/hc/en-us/articles/360035890471):\n\nQualByDepth (QFD): variant confidence (QUAL) divided by unfiltered depth\nFisherStrand (FS): checks for strand bias (i.e., if minor allele occurs more often on one strand)\nStrandOddsRatio (SOR): alternative strand bias test\nRMSMappingQuality (MQ): root mean square mapping quality over all reads\nMappingQualytRankSumTest (MQRankSum): compares mapping qualities of ref and alt alleles\nReadPosRankSumTest (ReadPosRankSum): looks at site position within reads\nInbreedingCoeff: population-level statistics that requires at least 10 individuals"
  },
  {
    "objectID": "slides/variant_filtering/index.html#what-about-machine-learning",
    "href": "slides/variant_filtering/index.html#what-about-machine-learning",
    "title": "Variant filtering",
    "section": "What about machine learning?",
    "text": "What about machine learning?\n\n\n\n\nDePristo et al. (2011)\n\n\n\nVariant Quality Score Recalibration\n\nMotivation: look at context statistics and integrate over multiple dimensions\n\ntraining data: subset of known variants (from validated resources, e.g. 1000 Genomes)\ncompile multiple statistics (allele depth, read count, quality, …)\nfit Gaussian mixture model\nreassign quality scores to variant call set\n\n\nCaveat: database of known variants often not known for non-model organisms.\n\n\n\n\nKey take home: thresholds that previously were binary yes/no filters now depend on context; for instance, an AD (allele depth) cutoff of 4 will in VQSR sometimes pass, sometimes not, depending on other information\nFigure legend:\n\nRelationship in the HiSeq call set between strand bias and quality by depth for genomic locations in HapMap3 (red) and dbSNP (orange) used for training the variant quality score recalibrator (left), (b) and the same annotations applied to differentiate likely true positive (green) from false positive (purple) new SNPs. (c–e) Quality tranches in the recalibrated HiSeq (c), exome (d) and low-pass CEU (e) calls beginning with (top) the highest quality but smallest call set with an estimated false positive rate among new SNP calls of &lt;1/1000 to a more comprehensive call set (bottom) that includes effectively all true positives in the raw call set along with more false positive calls for a cumulative false positive rate of 10%. Each successive call set contains within it the previous tranche’s true- and false-positive calls (shaded bars) as well as tranche-specific calls of both classes (solid bars). The tranche selected for further analyses here is indicated."
  },
  {
    "objectID": "slides/variant_filtering/index.html#monkeyflower-variants",
    "href": "slides/variant_filtering/index.html#monkeyflower-variants",
    "title": "Variant filtering",
    "section": "Monkeyflower variants",
    "text": "Monkeyflower variants\n\nbcftools stats variantsites.vcf.gz | grep \"^SN\"\n\nSN  0   number of samples:  10\nSN  0   number of records:  12794\nSN  0   number of no-ALTs:  0\nSN  0   number of SNPs: 10487\nSN  0   number of MNPs: 0\nSN  0   number of indels:   2339\nSN  0   number of others:   0\nSN  0   number of multiallelic sites:   1018\nSN  0   number of multiallelic SNP sites:   201\n\n\nUse vcftools to compile data to generate summary statistics\nPlot and select thresholds"
  },
  {
    "objectID": "slides/variant_filtering/index.html#mean-depth-and-variant-quality-distribution",
    "href": "slides/variant_filtering/index.html#mean-depth-and-variant-quality-distribution",
    "title": "Variant filtering",
    "section": "Mean depth and variant quality distribution",
    "text": "Mean depth and variant quality distribution\n\n\n\n\nCode\nvcf &lt;- \"variantsites.vcf.gz\"\nsystem(paste(\"vcftools --gzvcf\", vcf, \"--site-depth 2&gt;/dev/null\"))\ndata &lt;- read.table(\"out.ldepth\", header = TRUE)\nx &lt;- as.data.frame(table(data$SUM_DEPTH))\nlower &lt;- 0.8 * median(data$SUM_DEPTH)\nupper &lt;- median(data$SUM_DEPTH) + 1 * sd(data$SUM_DEPTH)\nxupper &lt;- ceiling(upper/100) * 100\nggplot(x, aes(x = as.numeric(as.character(Var1)), y = Freq)) + geom_line() + xlab(\"Depth\") +\n    ylab(\"bp\") + xlim(0, xupper) + geom_vline(xintercept = lower, color = \"red\",\n    size = 1.3) + geom_vline(xintercept = upper, color = \"red\", size = 1.3) + ggtitle(\"Example threshold: 0.8X median depth, median depth + 2sd\")\n\n\n\n\n\n\n\n\n\nDepth uneven. High coverage often repetitive sequence. Too low coverage will bias SNP calling due to undersampling of alleles.\n\n\n\nCode\nsystem(paste(\"vcftools --gzvcf\", vcf, \"--site-quality 2&gt;/dev/null\"))\ndata &lt;- read.table(\"out.lqual\", header = TRUE)\nggplot(subset(data, QUAL &lt; 1000), aes(x = QUAL)) + geom_histogram(fill = \"white\",\n    color = \"black\", bins = 50) + xlab(\"Quality value\") + ylab(\"Count\") + geom_vline(xintercept = 30,\n    color = \"red\", size = 1.3) + ggtitle(\"Example threshold: Q30\")\n\n\n\n\n\n\n\n\n\nFilter variants with too low quality (Q30=0.001% chance of being wrong)"
  },
  {
    "objectID": "slides/variant_filtering/index.html#missing-data-per-individual-and-site",
    "href": "slides/variant_filtering/index.html#missing-data-per-individual-and-site",
    "title": "Variant filtering",
    "section": "Missing data per individual and site",
    "text": "Missing data per individual and site\n\n\n\n\nCode\nsystem(paste(\"vcftools --gzvcf\", vcf, \"--missing-indv 2&gt;/dev/null\"))\ndata &lt;- read.table(\"out.imiss\", header = TRUE)\nggplot(data, aes(x = F_MISS, y = INDV)) + geom_point(size = 3) + ggtitle(\"Missing data per individual\")\n\n\n\n\n\n\n\n\n\nMissing number of sites per individual. Too many would indicate poor sample quality.\n\n\n\nCode\nsystem(paste(\"vcftools --gzvcf\", vcf, \"--missing-site 2&gt;/dev/null\"))\ndata &lt;- read.table(\"out.lmiss\", header = TRUE)\nggplot(data, aes(x = F_MISS)) + geom_histogram(fill = \"white\", color = \"black\", bins = 10) +\n    xlab(\"F_MISS\") + ylab(\"Count\") + geom_vline(xintercept = 0.25, color = \"red\",\n    size = 1.3) + ggtitle(\"Missing data per site: example threshold F_MISS=0.25\")\n\n\n\n\n\n\n\n\n\nFraction missing calls per site. Could warrant separate filters when comparing populations (e.g., total missing 0.2, but population A has 0.1 missing, population B 0.4)."
  },
  {
    "objectID": "slides/variant_filtering/index.html#minor-allele-frequency-and-heterozygosity",
    "href": "slides/variant_filtering/index.html#minor-allele-frequency-and-heterozygosity",
    "title": "Variant filtering",
    "section": "Minor allele frequency and heterozygosity",
    "text": "Minor allele frequency and heterozygosity\n\n\n\n\n\n\nCode\nsystem(paste(\"vcftools --gzvcf\", vcf, \"--freq2 --max-alleles 2 2&gt;/dev/null\"))\ndata &lt;- read.table(\"out.frq\", skip = 1)\ncolnames(data) &lt;- c(\"CHROM\", \"POS\", \"N_ALLELES\", \"N_CHR\", \"FREQ1\", \"FREQ2\")\ndata$MAF &lt;- apply(data, 1, function(x) as.numeric(min(x[5], x[6])))\nggplot(data, aes(x = MAF)) + geom_histogram(fill = \"white\", color = \"black\", bins = 10) +\n    xlab(\"MAF\") + ylab(\"Count\") + geom_vline(xintercept = 0.1, color = \"red\", size = 1.3) +\n    ggtitle(\"Minor allele frequency: example threshold MAF=0.1\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n56320471\n\nn=12; mutations 0, 4, 5 (red) are singletons and would fail MAF&lt;=0.1\n\n\nReasonable cutoff 0.05-0.1 for PCA, population structure.\nBut! Statistics based on diversity or the SFS should not be filtered on MAF\n\n\n\nCode\nsystem(paste(\"vcftools --gzvcf\", vcf, \"--het 2&gt;/dev/null\"))\ndata &lt;- read.table(\"out.het\", header = TRUE)\nggplot(data, aes(x = F, y = INDV)) + geom_point(size = 3) + ggtitle(\"Inbreeding coefficient\")\n\n\n\n\n\n\n\n\n\n\nF=0: Hardy-Weinberg Equilibrium\nF&gt;0: deficit of heterozygotes; inbreeding, Wahlund effect (population substructure), allele dropout\nF&lt;0: surplus of heterozygotes; could be sample contamination, poor sequence quality (mismapping)"
  },
  {
    "objectID": "slides/variant_filtering/index.html#monkeyflower-call-set-with-invariant-sites",
    "href": "slides/variant_filtering/index.html#monkeyflower-call-set-with-invariant-sites",
    "title": "Variant filtering",
    "section": "Monkeyflower call set with invariant sites",
    "text": "Monkeyflower call set with invariant sites\n\nbcftools stats allsites.vcf.gz | grep \"^SN\"\n\nSN  0   number of samples:  10\nSN  0   number of records:  10039\nSN  0   number of no-ALTs:  9232\nSN  0   number of SNPs: 414\nSN  0   number of MNPs: 0\nSN  0   number of indels:   110\nSN  0   number of others:   0\nSN  0   number of multiallelic sites:   45\nSN  0   number of multiallelic SNP sites:   7\n\n\nFiltering as before but excluding MAF, variant quality filters"
  },
  {
    "objectID": "slides/variant_filtering/index.html#motivation",
    "href": "slides/variant_filtering/index.html#motivation",
    "title": "Variant filtering",
    "section": "Motivation",
    "text": "Motivation\n\n\nSome organisms generate a lot of data…\n\nTotal variant file size: 7.4T!!!\nWithout invariant sites!\n\n\nSolution: sequence masks\n\n…it may be possible for more advanced users to achieve similar results with existing tools. For example, with the inclusion of a user-created “accessibility mask”, it should be possible to avoid the “missing sites” effect…\n\n\n(Korunes & Samuk, 2021)\n\n\n\n\nSpruce variant files, chromosome 1\n\n\n48G     PA_chr01_10.vcf.gz\n45G     PA_chr01_11.vcf.gz\n51G     PA_chr01_12.vcf.gz\n50G     PA_chr01_13.vcf.gz\n45G     PA_chr01_14.vcf.gz\n51G     PA_chr01_15.vcf.gz\n51G     PA_chr01_16.vcf.gz\n35G     PA_chr01_17.vcf.gz\n49G     PA_chr01_1.vcf.gz\n50G     PA_chr01_2.vcf.gz\n52G     PA_chr01_3.vcf.gz\n51G     PA_chr01_4.vcf.gz\n54G     PA_chr01_5.vcf.gz\n51G     PA_chr01_6.vcf.gz\n37G     PA_chr01_7.vcf.gz\n51G     PA_chr01_8.vcf.gz\n47G     PA_chr01_9.vcf.gz"
  },
  {
    "objectID": "slides/variant_filtering/index.html#coverage-tracks-and-sequence-masks",
    "href": "slides/variant_filtering/index.html#coverage-tracks-and-sequence-masks",
    "title": "Variant filtering",
    "section": "Coverage tracks and sequence masks",
    "text": "Coverage tracks and sequence masks"
  },
  {
    "objectID": "slides/variant_filtering/index.html#coverage-tracks-and-sequence-masks-1",
    "href": "slides/variant_filtering/index.html#coverage-tracks-and-sequence-masks-1",
    "title": "Variant filtering",
    "section": "Coverage tracks and sequence masks",
    "text": "Coverage tracks and sequence masks"
  },
  {
    "objectID": "slides/variant_filtering/index.html#coverage-tracks-and-sequence-masks-2",
    "href": "slides/variant_filtering/index.html#coverage-tracks-and-sequence-masks-2",
    "title": "Variant filtering",
    "section": "Coverage tracks and sequence masks",
    "text": "Coverage tracks and sequence masks"
  },
  {
    "objectID": "slides/variant_filtering/index.html#coverage-tracks-and-sequence-masks-3",
    "href": "slides/variant_filtering/index.html#coverage-tracks-and-sequence-masks-3",
    "title": "Variant filtering",
    "section": "Coverage tracks and sequence masks",
    "text": "Coverage tracks and sequence masks"
  },
  {
    "objectID": "slides/variant_filtering/index.html#coverage-tracks-and-sequence-masks-4",
    "href": "slides/variant_filtering/index.html#coverage-tracks-and-sequence-masks-4",
    "title": "Variant filtering",
    "section": "Coverage tracks and sequence masks",
    "text": "Coverage tracks and sequence masks"
  },
  {
    "objectID": "slides/variant_filtering/index.html#coverage-tracks-and-sequence-masks-5",
    "href": "slides/variant_filtering/index.html#coverage-tracks-and-sequence-masks-5",
    "title": "Variant filtering",
    "section": "Coverage tracks and sequence masks",
    "text": "Coverage tracks and sequence masks"
  },
  {
    "objectID": "slides/variant_filtering/index.html#coverage-tracks-and-sequence-masks-6",
    "href": "slides/variant_filtering/index.html#coverage-tracks-and-sequence-masks-6",
    "title": "Variant filtering",
    "section": "Coverage tracks and sequence masks",
    "text": "Coverage tracks and sequence masks"
  },
  {
    "objectID": "slides/variant_filtering/index.html#coverage-tracks-and-sequence-masks-7",
    "href": "slides/variant_filtering/index.html#coverage-tracks-and-sequence-masks-7",
    "title": "Variant filtering",
    "section": "Coverage tracks and sequence masks",
    "text": "Coverage tracks and sequence masks"
  },
  {
    "objectID": "slides/variant_filtering/index.html#filters-and-masks",
    "href": "slides/variant_filtering/index.html#filters-and-masks",
    "title": "Variant filtering",
    "section": "Filters and masks",
    "text": "Filters and masks\n\n\n\n\n\nReference\nCoverage mask\n\n\n\n\n\n&gt;LG4 LG4:12000001-12100000\nGGACAATTACCCCCTCCGTTATGTTTCAGTCAATTTCATGTTTGACTTTTAGATTTTTAA\n000000000011111111110000000000000011111111111000000000000110\n\n\n\n\n\nMask could also represent annotation features, such as exons, four-fold degenerate sites etc to be combined with coverage mask:\n\n\n\n\n\nReference\nCoverage mask\nExons\n\nCombined\n\n\n\n\n\n&gt;LG4 LG4:12000001-12100000\nGGACAATTACCCCCTCCGTTATGTTTCAGTCAATTTCATGTTTGACTTTTAGATTTTTAA\n111111111100000000001111111111111100000000000111111111111001\n111110000000000000000000000000111111111100000000001111111111\n\n111111111100000000001111111111111111111100000111111111111111\n\n\n\n\n\n\nUse with vcftools --mask to restrict analyses to certain positions.\nNB! Here 0 is a position that is unmasked, &gt;0 masked"
  },
  {
    "objectID": "slides/variant_filtering/index.html#bibliography",
    "href": "slides/variant_filtering/index.html#bibliography",
    "title": "Variant filtering",
    "section": "Bibliography",
    "text": "Bibliography\n\n\nDePristo, M. A., Banks, E., Poplin, R., Garimella, K. V., Maguire, J. R., Hartl, C., Philippakis, A. A., del Angel, G., Rivas, M. A., Hanna, M., McKenna, A., Fennell, T. J., Kernytsky, A. M., Sivachenko, A. Y., Cibulskis, K., Gabriel, S. B., Altshuler, D., & Daly, M. J. (2011). A framework for variation discovery and genotyping using next-generation DNA sequencing data. Nature Genetics, 43(5), 491–498. https://doi.org/10.1038/ng.806\n\n\nKorunes, K. L., & Samuk, K. (2021). Pixy: Unbiased estimation of nucleotide diversity and divergence in the presence of missing data. Molecular Ecology Resources, 21(4), 1359–1368. https://doi.org/10.1111/1755-0998.13326\n\n\nLi, H. (2014). Toward better understanding of artifacts in variant calling from high-coverage samples. Bioinformatics, 30(20), 2843–2851. https://doi.org/10.1093/bioinformatics/btu356\n\n\nLou, R. N., Jacobs, A., Wilder, A. P., & Therkildsen, N. O. (2021). A beginner’s guide to low-coverage whole genome sequencing for population genomics. Molecular Ecology, 30(23), 5966–5993. https://doi.org/10.1111/mec.16077\n\n\nNazareno, A. G., & Knowles, L. L. (2021). There Is No “Rule of Thumb”: Genomic Filter Settings for a Small Plant Population to Obtain Unbiased Gene Flow Estimates. Frontiers in Plant Science, 12. https://www.frontiersin.org/articles/10.3389/fpls.2021.677009\n\n\nTalla, V., Soler, L., Kawakami, T., Dincă, V., Vila, R., Friberg, M., Wiklund, C., & Backström, N. (2019). Dissecting the Effects of Selection and Mutation on Genetic Diversity in Three Wood White (Leptidea) Butterfly Species. Genome Biology and Evolution, 11(10), 2875–2886. https://doi.org/10.1093/gbe/evz212\n\n\n\n\nVariant filtering"
  },
  {
    "objectID": "slides/population_structure/index.html#pca-in-population-genetics-cavalli-sforza",
    "href": "slides/population_structure/index.html#pca-in-population-genetics-cavalli-sforza",
    "title": "Population structure",
    "section": "PCA in population genetics: Cavalli-Sforza",
    "text": "PCA in population genetics: Cavalli-Sforza\n\n(Menozzi P, 1978) noticed that genetic distances seem to correlate with geographical distances"
  },
  {
    "objectID": "slides/population_structure/index.html#pca-in-population-genetics-john-novembre",
    "href": "slides/population_structure/index.html#pca-in-population-genetics-john-novembre",
    "title": "Population structure",
    "section": "PCA in population genetics: John Novembre",
    "text": "PCA in population genetics: John Novembre\n\n\n\n(Novembre J, 2008)\n\n\ngenetics seems to mirrow the map of Europe\ncaveate: it is not always the case\nJ. Novembre selected samples"
  },
  {
    "objectID": "slides/population_structure/index.html#pca-and-mds-are-matrix-factorization-techniques",
    "href": "slides/population_structure/index.html#pca-and-mds-are-matrix-factorization-techniques",
    "title": "Population structure",
    "section": "PCA and MDS are matrix factorization techniques",
    "text": "PCA and MDS are matrix factorization techniques"
  },
  {
    "objectID": "slides/population_structure/index.html#toy-example-of-pca-for-population-genetics",
    "href": "slides/population_structure/index.html#toy-example-of-pca-for-population-genetics",
    "title": "Population structure",
    "section": "Toy example of PCA for population genetics",
    "text": "Toy example of PCA for population genetics\n\n\n\ngen &lt;- t(matrix(c(1, 0, 2, 0, 2, 0, 2, 1, 1, 1, 0, 1, 0, 2, 1, 2, 1, 1, 1, 1, 1,\n    0, 1, 0, 2, 0, 1, 1, 0, 2, 1, 2, 0, 1, 0), 5, by = TRUE))\ncolnames(gen) &lt;- paste0(\"Ind\", 1:5)\nrownames(gen) &lt;- paste0(\"SNP\", 1:7)\nprint(gen)\n\n     Ind1 Ind2 Ind3 Ind4 Ind5\nSNP1    1    1    1    0    0\nSNP2    0    1    2    1    2\nSNP3    2    1    1    0    1\nSNP4    0    0    1    2    2\nSNP5    2    1    1    0    0\nSNP6    0    0    1    1    1\nSNP7    2    2    1    1    0\n\n\n\n\ngen_centered &lt;- scale(gen, center = TRUE, scale = FALSE)\ncovariance &lt;- t(gen_centered) %*% gen_centered\neig &lt;- eigen(covariance)\nbarplot(eig$values/sum(eig$values), names = paste0(\"PC\", 1:5))\n\n\n\n\n\n\n\n\nplot(eig$vectors[, 1:2], xlab = \"PC1\", ylab = \"PC2\", pch = 16, cex = 5, col = 2:6)\npoints(eig$vectors[, 1:2], pch = as.character(1:5))\n\n\n\n\nIdea: project the data into a low dimensional space that explains the largest amount of variance"
  },
  {
    "objectID": "slides/population_structure/index.html#variance-maximization-and-eigen-value-decomposition",
    "href": "slides/population_structure/index.html#variance-maximization-and-eigen-value-decomposition",
    "title": "Population structure",
    "section": "Variance maximization and eigen value decomposition",
    "text": "Variance maximization and eigen value decomposition"
  },
  {
    "objectID": "slides/population_structure/index.html#toy-example-of-mds-for-population-genetics",
    "href": "slides/population_structure/index.html#toy-example-of-mds-for-population-genetics",
    "title": "Population structure",
    "section": "Toy example of MDS for population genetics",
    "text": "Toy example of MDS for population genetics\n\n\n\ngen &lt;- t(matrix(c(1, 0, 2, 0, 2, 0, 2, 1, 1, 1, 0, 1, 0, 2, 1, 2, 1, 1, 1, 1, 1,\n    0, 1, 0, 2, 0, 1, 1, 0, 2, 1, 2, 0, 1, 0), 5, by = TRUE))\ncolnames(gen) &lt;- paste0(\"Ind\", 1:5)\nrownames(gen) &lt;- paste0(\"SNP\", 1:7)\nprint(gen)\n\n     Ind1 Ind2 Ind3 Ind4 Ind5\nSNP1    1    1    1    0    0\nSNP2    0    1    2    1    2\nSNP3    2    1    1    0    1\nSNP4    0    0    1    2    2\nSNP5    2    1    1    0    0\nSNP6    0    0    1    1    1\nSNP7    2    2    1    1    0\n\n\n\n\nmy_dist &lt;- dist(t(gen), method = \"manhattan\", upper = TRUE, diag = TRUE)\nmy_dist\n\n     Ind1 Ind2 Ind3 Ind4 Ind5\nInd1    0    3    7   10   11\nInd2    3    0    4    7    8\nInd3    7    4    0    5    4\nInd4   10    7    5    0    3\nInd5   11    8    4    3    0\n\nmy_mds &lt;- cmdscale(my_dist)\nmy_mds\n\n          [,1]       [,2]\nInd1 -6.114866  0.2977272\nInd2 -3.077094  0.2402932\nInd3  0.621230 -1.7944048\nInd4  3.723118  2.1483083\nInd5  4.847612 -0.8919238\n\n\n\n\n\n\nplot(my_mds, xlab = \"MDS1\", ylab = \"MDS2\", pch = 16, cex = 5, col = 6:2)\npoints(my_mds, pch = as.character(5:1))\n\n\n\n\nIdea: project the data into a low dimensional space that preserves distances"
  },
  {
    "objectID": "slides/population_structure/index.html#example-of-pca-plot-from-1000g-project",
    "href": "slides/population_structure/index.html#example-of-pca-plot-from-1000g-project",
    "title": "Population structure",
    "section": "Example of PCA plot from 1000G project",
    "text": "Example of PCA plot from 1000G project\n\n\nWe will use ANGSD (Korneliussen T, 2014) and compute genotype likelihoods on 435 bam-files from the 1000G project.\n\ncd /home/nikolay/Documents/Teaching/PopGen_2023/data/1000G_bam_files\nfind $PWD -name '*.bam' &gt; 1000G_bam_list.txt\nangsd -bam 1000G_bam_list.txt -GL 2 -doMajorMinor 1 -doMaf 1 -SNP_pval 2e-6 \\\n-minMapQ 30 -minQ 20 -minInd 25 -minMaf 0.05 -doGlf 2 -out 1000G -P 5\n\nNext, we will run PCAANGSD to infer admixures proportions:\n\npcangsd -b 1000G.beagle.gz -o pca_1000G -t 4\n\nand finally we will plots the results using custom R scripts:\n\nC &lt;- as.matrix(read.table(\"pca_1000G.cov\"))\ne &lt;- eigen(C)\npops &lt;- readLines(\"1000G_bam_list.txt\")\npops &lt;- sapply(strsplit(pops, \"\\\\.\"), function(x) x[6])\nmycolor &lt;- rep(\"red\", length(pops))\nmycolor[pops == \"CEU\"] &lt;- \"blue\"\nmycolor[pops == \"CHB\"] &lt;- \"green\"\nmycolor[pops == \"MXL\"] &lt;- \"brown\"\nmycolor[pops == \"ASW\"] &lt;- \"magenta\"\nplot(e$vectors[, 1:2], xlab = \"PC1\", ylab = \"PC2\", main = \"PCA 1000G Project\",\n    col = mycolor, pch = 19)\nlegend(\"topright\", c(\"YRI\", \"CEU\", \"CHB\", \"MXL\", \"ASW\"), fill = c(\"red\", \"blue\",\n    \"green\", \"brown\", \"magenta\"), cex = 2, inset = 0.02)"
  },
  {
    "objectID": "slides/population_structure/index.html#angsd-genotype-likelihood-tool-for-low-coverage-data",
    "href": "slides/population_structure/index.html#angsd-genotype-likelihood-tool-for-low-coverage-data",
    "title": "Population structure",
    "section": "ANGSD: genotype likelihood tool for low-coverage data",
    "text": "ANGSD: genotype likelihood tool for low-coverage data\n\n(Korneliussen T, 2014)"
  },
  {
    "objectID": "slides/population_structure/index.html#hard-genotype-calls-vs.-genotype-likelihoods",
    "href": "slides/population_structure/index.html#hard-genotype-calls-vs.-genotype-likelihoods",
    "title": "Population structure",
    "section": "Hard genotype calls vs. genotype likelihoods",
    "text": "Hard genotype calls vs. genotype likelihoods\n\n\n\nMinor allele frequency based on hard calls: \\[\\rm{MAF_{hc}}=\\frac{1+1+2}{2*5}=\\frac{4}{10}\\]\n\n\n\n\nMinor allele frequency based on genotype likelihoods: \\[\\rm{MAF_{gl}}=\\frac{0*(0.98+0.20+0.89+0.10+0.15)+1*(0.02+0.75+0.10+0.80+0.20)+2*(0.00+0.05+0.01+0.10+0.65)}{2*5}=\\frac{3.49}{10}\\]"
  },
  {
    "objectID": "slides/population_structure/index.html#a-known-pitfall-of-pca-uneven-sampling",
    "href": "slides/population_structure/index.html#a-known-pitfall-of-pca-uneven-sampling",
    "title": "Population structure",
    "section": "A known pitfall of PCA: uneven sampling",
    "text": "A known pitfall of PCA: uneven sampling\n\n\n\n\n\n\n\n(McVean, 2009)\n\n“The results described here provide an explanation. First, from Equation 10 it can be seen that the matrix M is influenced by the relative sample size from each population through the components \\(t_i\\). For instance, even if all populations are equally divergent from each other, those for which there are fewer samples will have larger values of \\(t_i\\) because relatively more pairwise comparisons are between populations.”\n\\[M=XX^T=\\frac{1}{N}\\sum_{ij}x_ix_j\\] \\[N=N_{pop1}+N_{pop2}+N_{pop3}+...=\\sum_k N_k\\] \\[M_{uneven}=\\sum_{ijk}\\frac{1}{N_k}x_{ik}x_{jk}\\]\n\nPotential solution: normalize each sample by its population size before computing the covariance matrix.\nIs it still an unsupervised technique?"
  },
  {
    "objectID": "slides/population_structure/index.html#example-of-uneven-sampling-from-1000g-project",
    "href": "slides/population_structure/index.html#example-of-uneven-sampling-from-1000g-project",
    "title": "Population structure",
    "section": "Example of uneven sampling from 1000G project",
    "text": "Example of uneven sampling from 1000G project\n\n\n\nDownsampled Europeans\n\n\nDownsampled Asians"
  },
  {
    "objectID": "slides/population_structure/index.html#admixture-underlying-assumtions",
    "href": "slides/population_structure/index.html#admixture-underlying-assumtions",
    "title": "Population structure",
    "section": "Admixture: underlying assumtions",
    "text": "Admixture: underlying assumtions\n\n\n\n\n\ngenetic clustering algorithm\nat least two unadmixed populations\nat least one admixed population\nMaximum Likelihood: ADMIXTURE\nBayesian: STRUCTURE\ndelivers admixture proportions Q\ndelivers allele frequencies F for all loci for all K populations"
  },
  {
    "objectID": "slides/population_structure/index.html#q-and-f-outputs-of-admixture-analysis",
    "href": "slides/population_structure/index.html#q-and-f-outputs-of-admixture-analysis",
    "title": "Population structure",
    "section": "Q and F outputs of admixture analysis",
    "text": "Q and F outputs of admixture analysis"
  },
  {
    "objectID": "slides/population_structure/index.html#ngsadmix-vs.-admixture",
    "href": "slides/population_structure/index.html#ngsadmix-vs.-admixture",
    "title": "Population structure",
    "section": "NGSadmix vs. ADMIXTURE",
    "text": "NGSadmix vs. ADMIXTURE"
  },
  {
    "objectID": "slides/population_structure/index.html#example-of-admixture-plot-from-1000g-project",
    "href": "slides/population_structure/index.html#example-of-admixture-plot-from-1000g-project",
    "title": "Population structure",
    "section": "Example of admixture plot from 1000G project",
    "text": "Example of admixture plot from 1000G project\n\n\nWe will use ANGSD (Korneliussen T, 2014) and compute genotype likelihoods on 435 bam-files from the 1000G project.\n\ncd /home/nikolay/Documents/Teaching/PopGen_2023/data/1000G_bam_files\nfind $PWD -name '*.bam' &gt; 1000G_bam_list.txt\nangsd -bam 1000G_bam_list.txt -GL 2 -doMajorMinor 1 -doMaf 1 -SNP_pval 2e-6 \\\n-minMapQ 30 -minQ 20 -minInd 25 -minMaf 0.05 -doGlf 2 -out 1000G -P 5\n\nNext, we will run NGSadmix to infer admixures proportions:\n\nNGSadmix -likes 1000G.beagle.gz -K 3 -minMaf 0.05 -seed 1 -o 1000G\n\nand finally we will plots the results using custom R scripts:\n\npops &lt;- readLines(\"1000G_bam_list.txt\")\npops &lt;- sapply(strsplit(pops, \"\\\\.\"), function(x) x[6])\nsource(\"https://raw.githubusercontent.com/GenisGE/evalAdmix/master/visFuns.R\")\nqopts &lt;- read.table(\"1000G.qopt\")\nord &lt;- orderInds(pop = pops, q = qopts, popord = c(\"YRI\", \"ASW\", \"CEU\", \"MXL\",\n    \"CHB\"))\nbarplot(t(qopts)[, ord], col = c(3, 2, 4), las = 2, space = 0, border = NA)\ntext(sort(tapply(1:length(pops), pops[ord], mean)), -0.05, unique(pops[ord]))\nabline(v = cumsum(sapply(unique(pops[ord]), function(x) {\n    sum(pops[ord] == x)\n})), col = 1, lwd = 1.2)"
  },
  {
    "objectID": "slides/population_structure/index.html#admixture-bar-plots-should-not-be-over-interpreted",
    "href": "slides/population_structure/index.html#admixture-bar-plots-should-not-be-over-interpreted",
    "title": "Population structure",
    "section": "Admixture bar plots should not be over-interpreted",
    "text": "Admixture bar plots should not be over-interpreted\n\n(Lawson DJ, 2018)"
  },
  {
    "objectID": "slides/population_structure/index.html#haplotype-clustering",
    "href": "slides/population_structure/index.html#haplotype-clustering",
    "title": "Population structure",
    "section": "Haplotype clustering",
    "text": "Haplotype clustering\n\n\n\n\n\n\n\n\n\nAncestry assignments in STRUCTURE / ADMIXTURE do not identify where admixture has occurred\nHaplotype-based methods explore local ancestry, LD, recombination and subsequently fine-scale patterns of population structure at different scales\nChromosome painting: the genome is a mosaic of LD blocks separated by recombination\nChromoPainter and fineSTRUCTURE are tools for resolving subtle differences between populations.\n\n(D. Lawson, 2012)\n(Schraiber & Akey, 2015)"
  },
  {
    "objectID": "slides/population_structure/index.html#fixation-index-f_st",
    "href": "slides/population_structure/index.html#fixation-index-f_st",
    "title": "Population structure",
    "section": "Fixation index \\(F_{st}\\)",
    "text": "Fixation index \\(F_{st}\\)\n\n\n\n\\(F_{st}\\) is a measure of population differentiation due to population structure\nExpressed through nucleotide diversity \\(\\pi\\) as relative nucleotide diversity between populations minus average nucleotide diversity within populations. If we have two populations 1 and 2, then:\n\n\\[\nF_{st}=\\frac{\\pi_{12}-\\frac{\\pi_{1}+\\pi_{2}}{2}}{\\pi_{12}} \\sim\n\\frac{\\sigma_{subpops}^2}{\\sigma_{total}^2}\n\\]\n\nlibrary(\"admixtools\")\nlibrary(\"tidyverse\")\n\nadmixtools::extract_f2(\"AADR\", outdir = \"f2_AADR\")\n\nf2_aadr &lt;- read_f2(\"f2_AADR\")\nfst_aadr &lt;- fst(f2_aadr)\nfst_aadr\n\nmat &lt;- f2(f2_aadr, unique_only = F) %&gt;%\n    select(-se) %&gt;%\n    pivot_wider(names_from = pop2, values_from = est) %&gt;%\n    column_to_rownames(\"pop1\") %&gt;%\n    as.matrix()\n\nlibrary(\"pheatmap\")\npheatmap(mat, cluster_rows = TRUE, cluster_cols = TRUE)"
  },
  {
    "objectID": "slides/population_structure/index.html#allen-ancient-dna-resource-aadr-dataset",
    "href": "slides/population_structure/index.html#allen-ancient-dna-resource-aadr-dataset",
    "title": "Population structure",
    "section": "Allen Ancient DNA Resource (AADR) dataset",
    "text": "Allen Ancient DNA Resource (AADR) dataset\n\n\n\n https://reich.hms.harvard.edu/allen-ancient-dna-resource-aadr-downloadable-genotypes-present-day-and-ancient-dna-data\n\n\n\nhead data/DavidReich/AADR.ind\n\n             ALT-116 M    Tubalar\n             ALT-117 M    Tubalar\n             ALT-165 M    Tubalar\n             ALT-845 M    Tubalar\n             ALT-846 M    Tubalar\n             GEO-002 M   Georgian\n             GEO-005 M   Georgian\n             GEO-010 M   Georgian\n             GEO-015 M   Georgian\n             GEO-020 M   Georgian\n\n\n\nhead -n 8 data/DavidReich/AADR.snp\n\n           rs3094315     1        0.020130          752566 G A\n           rs7419119     1        0.022518          842013 T G\n          rs13302957     1        0.024116          891021 G A\n           rs6696609     1        0.024457          903426 C T\n              rs8997     1        0.025727          949654 A G\n           rs9442372     1        0.026288         1018704 A G\n         rs147606383     1        0.026665         1045331 G A\n           rs4970405     1        0.026674         1048955 A G\n\n\n\nhead data/DavidReich/AADR.geno\n\n12109000100001100012110220021200101020000110010200001011011000011010000011000111000011011010212912100101100100011102112122221212221110000010100000001002291001111100000011000010000000100000000001100001100000111102222220111211202221121121120000001210110100001000100000001111111021222210000000000110000001011122010100011000101120101211000000010100000000000000101010100111100110011000100000011001100011001111111110110211120012021102222101112011222221122222222221212110011001100011010000000001100101011001000111011009001122112010011121112112102101010000001000000010100001000000000000101100011001000010000000000000002000000001011000000001911001\n12122211222121212210121002100111200122211022221121010222112122001012002201122111211111221221222222112211222122111111212202221212212112221222222222212222202122112221222222212212212102222222122222222221122222221222112222222222222222212012222212222111210222221222122221222111111211011122222222222122222201111222222121212210222121112222222122222222212211112222122222212122121122122221222021001112122210210212212122222121111222222222222112122212221212212212222222022202222212122122112121112112211212122212222212212122222222212221222212101021220022021222222121122222222222222222221222222212220122222122202222121222122222222121221212001121102210\n22000100100000000010011000001111001120001111001110001010021001111200020010000000100001110000001112000000000010012020211201001012111022221222222112200121000010000100000000000000110001000101001102101121011029011011112000001110010000101101110001000111211022121221111200020001000000000000000000000100001001002110000100001100000001000101201010001100010201111210000110001010100000000000010200210111100010001010101001001101111112020011000110200011010200000000111001000020100000100000000200012000101111201000001000002000100000011011112000201110200100110100101000100010100000010000000101000000010000000111000111011001110001100111011010111021111110\n20212111212120212212102212121100202122211121121202122222122221121022022222022112100111210121122221122212222212210201012100221100021120000001011001121122210112121111222222210212102101221121221020121212201121210000210210111002192111010100111211220001210200101001111020202122222221222222222122221221222100210001211121221211222111112101021112212122212121111122121112112022222222122221112221222122922211211100111121112121000000100001219011001100009000110000110011001902211211222222222022211221121010121221222212211012212100000020221112221221101121021222212122122212222222111222212112122222210121222112222111210221122222222111221212011101201111\n00000000011111900000000000000000000000000000000100010000000000000000000000000010000010001000000000000010000000011120121122110122212120000000000000010101200000000010200000100020000000000010000010000000090900102100110112101209110010121111220000000212911100000900000000002000000000000000000000000000000101202102000100010000011001001111000001001000000000001000100100000100000000000010000000000000000000000211211001010201021101200111102112121911221121110112102112111101000010010000010000000002000100012000000100010012000112111110100001001001000011000000001000000001000010001000000001000110000000001000000000000000001001000000000000000100000000\n00001100010112211012210220121110121000000120020200101001101000111011100011000100021110210010101211210010011110000110010002000122102000000010101001121220011221100122210001100100010110000110000000000000009000011111202211100122211112201121121101012111000000000000000001000110101201010111111100100000001121111200000210011121111101000110010001010001011000001200101121122210100101000121000001011002100101001201021110211111112211112012111121111120112011201112111111121112011011011000110000210001000210210012000210021122012110021211100011012111122211112100011110001010000020100000000000000010001101000000100001001002111000000000010000000100000111\n22222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222211222222222222222222222222222222222222222222222222222222292222222222222222222222222222222222222222222222222222222222222222222222221222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222122222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n22222212222122112220021200001212221221222101222121221222211121212222222112222222222222121222121122122212222222222222222222222222222221212222221221102221212121222201122222112222222112222122222122222222222222222222222222222222222222222222221122211222222222222222222221222112111020212211222222122212112222222222022122922122222221121222222212212221222222221022221222112122222212122221212221212210221222222222222222222222222222222222222222222222222222222222222222222222222212221222222222212222222222112212222222221212222222222212222211110122121011122222120112221212211212122222211222212222221121122222222221221221112222222222222222222212222222\n22222102212120012220021200001212201221222101222121121222111121212221222111221121201112021212111012012201211122121122121101221111112121212222221221102201201000122100022222022122222112222112222122292222222222112000220011221211121129121212221121210122002122222222222221210112111020212210121122122211111101211110022122121111111120121110922211212221211222221022221121111021122111121111212221211210221922222212122221211220222002221119222012110201202122221211202212222201222211211222212222112222222212110211222222211201220011112212212211110121101011120122110012221212211212122222211222112212221121122222122221221220011222229222222222222112222221\n22222222222222222222220220222222222222222222221222212222221222222222222222222212122221212222222222222222222222211221101220111211121210212222112221222222222212222222222222222222222222222222222222222222222222111110110012100212012222111202211222222111110022222222222222221012919990910202222122222222222222120100222222221222222222222200222222222222222222229222221222222221122222222222222222122212221222222221212111112211021110111112122002101211201122021211011121121101122222122221222221222221122212221121222222212122222110221202212221222222122212221222222222122222222222222122222222222222222222222212222212222221212222222222222222222222222222"
  },
  {
    "objectID": "slides/population_structure/index.html#example-of-fst-computation-from-1000g-project",
    "href": "slides/population_structure/index.html#example-of-fst-computation-from-1000g-project",
    "title": "Population structure",
    "section": "Example of Fst computation from 1000G project",
    "text": "Example of Fst computation from 1000G project\n\n\nWe will use ANGSD (Korneliussen T, 2014) and compute Fst between CEU and YRI populations from the 1000G project.\n\nangsd -b 1000G_CEU_bam_list.txt -anc anc.fa -out CEU -dosaf 1 -gl 1\nangsd -b 1000G_YRI_bam_list.txt -anc anc.fa -out YRI -dosaf 1 -gl 1\nrealSFS CEU.saf.idx YRI.saf.idx &gt; CEU.YRI.ml\nrealSFS fst index CEU.saf.idx YRI.saf.idx -sfs CEU.YRI.ml -fstout CEU_YRI\nrealSFS fst stats  CEU_YRI.fst.idx\nrealSFS fst stats2 CEU_YRI.fst.idx -win 50 -step 10 &gt; slidingwindow_win50_step10\n\nand finally we will plots the results using custom R scripts:\n\ndf &lt;- read.delim(\"slidingwindow_win50_step10\", header = FALSE)\ndf &lt;- df[-1, ]\ndf$V2 &lt;- as.numeric(df$V2)\ndf$V3 &lt;- as.numeric(df$V3)\ndf$V5 &lt;- as.numeric(df$V5)\ndf &lt;- df[order(df$V2, df$V3), ]\nrownames(df) &lt;- seq(1, dim(df)[1], 1)\nplot(df$V5, col = df$V2, xlab = \"Chromosomes\", ylab = \"Fst\", xaxt = \"n\")\nmyticks &lt;- as.numeric(rownames(df[!duplicated(df$V2), ]))\naxis(side = 1, at = myticks, labels = seq(1, 21, 1))"
  },
  {
    "objectID": "slides/population_structure/index.html#f-statistics-underlying-assumtions",
    "href": "slides/population_structure/index.html#f-statistics-underlying-assumtions",
    "title": "Population structure",
    "section": "F-statistics: underlying assumtions",
    "text": "F-statistics: underlying assumtions\n\n\n\n\n\nTreeness test: are populations related in a tree-like fashion (Reich et al. 2009)?\nAdmixture test: ss a particular population descended from multiple ancestral populations (Reich et al. 2009)?\nAdmixture proportions: what are the contributions from different populations to a focal population (Green et al. 2010; Haak et al. 2015)?\nNumber of founders: how many founder populations are there for a certain region (Reich et al. 2012; Lazaridis et al. 2014)?\nComplex demography: how can mixtures and splits of population explain demography (Patterson et al. 2012; Lipson et al. 2013)?\nClosest relative: what is the closest relative to a contemporary or ancient population (Raghavan et al. 2014)?\n\n(Peter, 2016)"
  },
  {
    "objectID": "slides/population_structure/index.html#f2-statistic-and-f3-statistic",
    "href": "slides/population_structure/index.html#f2-statistic-and-f3-statistic",
    "title": "Population structure",
    "section": "F2-statistic and F3-statistic",
    "text": "F2-statistic and F3-statistic\n\n\n\n\\(F_2\\) is a covarinace in contrast to \\(F_{st}\\) which is a correlation coefficeint, therefore \\(F_2\\) is tree-additive by its definition\n\n\\[F_2=2\\pi_{12}-\\pi_{1}-\\pi_{2}\\]\n\n\\(F_3\\) can be expressed through a combination of \\(F_2\\)-statistic\n\n\\[F_3(P_X; P_1, P_2)=\\frac{1}{2}\\left(F_2(P_X, P_1)+F_2(P_X, P_2)-F_2(P_1, P_2)\\right)\\]\n\nOutgroup \\(F_3\\)-statistic: for an unknown population \\(P_X\\) find the closest population from a panel \\(P_i\\) computing the distances via an outgroup \\(P_O\\)."
  },
  {
    "objectID": "slides/population_structure/index.html#example-of-f3-outgroup-statistic-for-an-unknown-population",
    "href": "slides/population_structure/index.html#example-of-f3-outgroup-statistic-for-an-unknown-population",
    "title": "Population structure",
    "section": "Example of F3-outgroup-statistic for an Unknown population",
    "text": "Example of F3-outgroup-statistic for an Unknown population\n\n\nWe will use the AADR dataset and compute F3-statistic for a (presumably!) European population, which is marked as Unknown in the dataset, with respect to a panel of other World populations using a Mbuti as an outgroup population.\n\nlibrary(\"admixtools\")\nlibrary(\"tidyverse\")\n\nadmixtools::extract_f2(\"AADR\", outdir = \"f2_AADR\")\n\nf2_aadr &lt;- read_f2(\"f2_AADR\")\nfst_aadr &lt;- fst(f2_aadr)\nfst_aadr\n\nf3_aadr &lt;- f3(f2_aadr, pop1 = \"Mbuti\", pop2 = \"Unknown\", pop3 = unique(ind$pop)) %&gt;%\n    arrange(est)\nf3_aadr\n\n\nviz_outgroup_f3 &lt;- function(f3_res) {\n    f3_res %&gt;%\n        mutate(pop3 = fct_reorder(pop3, est)) %&gt;%\n        ggplot(aes(x = pop3, y = est, ymin = est - 3 * se, ymax = est + 3 * se)) +\n        geom_point() + geom_errorbar() + coord_flip() + theme_bw(25) + xlab(NULL) +\n        ylab(\"f3\")\n}\nviz_outgroup_f3(f3_aadr)\n\nCan you guess what was the Unknown population?"
  },
  {
    "objectID": "slides/population_structure/index.html#relation-between-f-statistics-and-pca",
    "href": "slides/population_structure/index.html#relation-between-f-statistics-and-pca",
    "title": "Population structure",
    "section": "Relation between F-statistics and PCA",
    "text": "Relation between F-statistics and PCA\n\n(Peter, 2022)"
  },
  {
    "objectID": "slides/population_structure/index.html#f4-statistic-d-statistic-abba-baba-test",
    "href": "slides/population_structure/index.html#f4-statistic-d-statistic-abba-baba-test",
    "title": "Population structure",
    "section": "F4-statistic, D-statistic: ABBA-BABA test",
    "text": "F4-statistic, D-statistic: ABBA-BABA test\n\n\n\n\n\n\n\n\n\nFour populations considered: Ape is an outgroup, Europeans and Africans are tested for their gene flow with Neanderthals\nA – ancestral allele, B – derived allele\nCount number of sites corresponding to ABBA and BABA situations\n\n\\[D=\\frac{N_{ABBA}-N_{BABA}}{N_{ABBA}+N_{BABA}}\\]\n\n\\(N_{ABBA}\\) the total counts of ABBA patterns, \\(N_{BABA}\\) the total counts of BABA patterns\nExess of shared derived alleles between Europeans and Neanderthals indicates a gene flow between them\nPositive values of D imply Neanderthals are closer to Europeans\nNegative values of D imply Neanderthals are closer to Africans"
  },
  {
    "objectID": "slides/population_structure/index.html#example-of-d-statistic-computation-from-1000g-project",
    "href": "slides/population_structure/index.html#example-of-d-statistic-computation-from-1000g-project",
    "title": "Population structure",
    "section": "Example of D-statistic computation from 1000G project",
    "text": "Example of D-statistic computation from 1000G project\n\n\nWe will use ANGSD (Korneliussen T, 2014) and compute D-statistic in irder to test potential Neanderthal introgression to European (CEU) and African (YRI) populations from the 1000G project.\n\necho Neandertal.bam &gt; bams\nfind $PWD -name '*YRI*.bam' | head -10 &gt;&gt; bams\nfind $PWD -name '*CEU*.bam' | head -10 &gt;&gt; bams\nangsd -out out -doAbbababa 1 -bam bams -doCounts 1 -anc anc.fa\nRscript jackKnife.R file=out.abbababa indNames=bams outfile=out_abbababa_results\n\nand, finally, we will display the resulting table of D-statistics and plot the ABBA and BABA counts using custom R scripts:\n\ndf &lt;- read.delim(file.path(path, \"out_abbababa_results.txt\"), header = T, sep = \"\\t\")\ndf &lt;- df[grepl(\"Neandertal\", as.character(df$H3)), ]\ndf &lt;- df[grepl(\"CEU\", as.character(df$H2)), ]\ndf &lt;- df[grepl(\"YRI\", as.character(df$H1)), ]\nYRI &lt;- matrix(unlist(strsplit(as.character(df$H1), \"\\\\.\")), ncol = 9, byrow = T)\ndf$H1 &lt;- paste(YRI[, 6], YRI[, 2], sep = \"_\")\nCEU &lt;- matrix(unlist(strsplit(as.character(df$H2), \"\\\\.\")), ncol = 9, byrow = T)\ndf$H2 &lt;- paste(CEU[, 6], CEU[, 2], sep = \"_\")\ndf$H3 &lt;- \"NEAND\"\ndf[1:8, 1:8]\n\n            H1          H2    H3 nABBA nBABA       Dstat     jackEst        SE\n11 YRI_NA19102 CEU_NA12342 NEAND    51    46  0.05154639  0.05154639 0.1220787\n12 YRI_NA19213 CEU_NA12342 NEAND    38    31  0.10144930  0.10144930 0.1286760\n13 YRI_NA18504 CEU_NA12342 NEAND    50    53 -0.02912621 -0.02912621 0.1353893\n14 YRI_NA19108 CEU_NA12342 NEAND    38    42 -0.05000000 -0.05000000 0.1393287\n15 YRI_NA19238 CEU_NA12342 NEAND    44    38  0.07317073  0.07317073 0.1305890\n16 YRI_NA19102 CEU_NA12348 NEAND    46    45  0.01098901  0.01098901 0.1076116\n17 YRI_NA19213 CEU_NA12348 NEAND    37    34  0.04225352  0.04225352 0.1122396\n18 YRI_NA18504 CEU_NA12348 NEAND    42    49 -0.07692308 -0.07692308 0.1068372\n\n\n\n\nboxplot(df$nABBA, df$nBABA, names = c(\"ABBA\", \"BABA\"), ylab = \"COUNTS\", col = 2)\n\n\n\nwilcox.test(df$nABBA, df$nBABA)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  df$nABBA and df$nBABA\nW = 367, p-value = 0.2933\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "slides/population_structure/index.html#refs",
    "href": "slides/population_structure/index.html#refs",
    "title": "Population structure",
    "section": "Refs",
    "text": "Refs\n\n\nD. Lawson, S. M., G. Hellenthal. (2012). Inference of population structure using dense haplotype data. PLoS Genet. 8(1):e1002453. https://doi.org/doi: 10.1371/journal.pgen.1002453\n\n\nKorneliussen T, N. R., Albrechtsen A. (2014). ANGSD: Analysis of next generation sequencing data. BMC Bioinformatics 15(1):356. https://doi.org/doi: 10.1186/s12859-014-0356-4\n\n\nLawson DJ, F. D., van Dorp L. (2018). A tutorial on how not to over-interpret STRUCTURE and ADMIXTURE bar plots. Nat Commun. 14;9(1):3258. https://doi.org/doi: 10.1038/s41467-018-05257-7\n\n\nMcVean. (2009). A genealogical interpretation of principal components analysis. PLoS Genetics Oct;5(10):e1000686. https://doi.org/doi: 10.1371/journal.pgen.1000686\n\n\nMenozzi P, C.-S. L., Piazza A. (1978). Synthetic maps of human gene frequencies in europeans. Science 1;201(4358):786-92. https://doi.org/doi: 10.1126/science.356262\n\n\nNovembre J, B. K., Johnson T. (2008). Genes mirror geography within europe. Nature. 2008 Nov 6;456(7218):98-101. https://doi.org/doi: 10.1038/nature07331\n\n\nPeter, B. (2016). Admixture, population structure, and f-statistics. Genetics 202(4):1485-501. https://doi.org/doi: 10.1534/genetics.115.183913\n\n\nPeter, B. (2022). A geometric relationship of F2, F3 and F4-statistics with principal component analysis. Philos Trans R Soc Lond B Biol Sci. 377(1852):20200413. https://doi.org/doi: 10.1098/rstb.2020.0413\n\n\nSchraiber, J., & Akey, J. (2015). Methods and models for unravelling human evolutionary history. Nat Rev Genet. 16(12):727-40. https://doi.org/doi: 10.1038/nrg4005\n\n\n\n\nPopulation structure"
  },
  {
    "objectID": "slides/selection/index.html",
    "href": "slides/selection/index.html",
    "title": "Selection",
    "section": "",
    "text": "Important\n\n\n\nLecture notes TBA"
  },
  {
    "objectID": "recipes/slim/index.html",
    "href": "recipes/slim/index.html",
    "title": "\n1 SLiM recipes",
    "section": "",
    "text": "SLiM recipes can be run with wrapper pgip-slim to generate multiple simulations.\n\nCodepgip-slim --help\n## Usage: pgip-slim [OPTIONS] SLIM\n## \n##   pgip slim simulator CLI.\n## \n##   Wrapper that runs slim on SLIM controlfile.\n## \n## Options:\n##   -o, --outdir PATH               Output directory\n##   -N, --population-size INTEGER   Population size\n##   -r, --recombination_rate FLOAT  Recombination rate\n##   -m, --mutation_rate FLOAT       Mutation rate\n##   -l, --sequence_length INTEGER   Sequence length\n##   -n, --repetitions INTEGER RANGE\n##                                   Number of repetitions  [x&gt;=1]\n##   --seed TEXT                     Random seed\n##   --threads INTEGER RANGE         Number of parallel threads to run  [x&gt;=1]\n##   --prefix TEXT                   File output prefix\n##   --no-recapitate                 Don't do recapitation\n##   --debug                         Print debugging info\n##   --help                          Show this message and exit.\n\n\nAs an example, the following command can be used to generate 10 simulations using the selective sweep recipe.\n\nCodepgip-slim --seed 42 -n 10 -r 1e-6 -m 1e-7 --threads 12 \\\n    selective_sweep.slim -l 1000000 --outdir results/slim\n\n\n\n\nslim code to simulate a selective sweep at a locus on a 1Mbp chromosome, with mutation rate \\(\\mu=10^{-8}\\), recombination rate \\(\\rho=10^{-8}\\), and \\(N_e=5,000\\).initialize() {\n  defineConstant(\"Nref\", 5e3);\n  if (!exists(\"seed\"))\n    defineConstant(\"seed\", getSeed());\n  defineConstant(\"SimID\", seed);\n  if (!exists(\"N\"))\n    defineConstant(\"N\", Nref);\n  if (!exists(\"outdir\"))\n    defineConstant(\"outdir\", tempdir());\n  if (!exists(\"mu\"))\n    defineConstant(\"mu\", 1e-8);\n  if (!exists(\"rho\"))\n    defineConstant(\"rho\", 1e-8);\n  if (!exists(\"seqlength\"))\n    defineConstant(\"seqlength\", 1e6);\n  if (!exists(\"position\"))\n    defineConstant(\"position\", asInteger(seqlength / 2));\n  if (!exists(\"outfile\"))\n    defineConstant(\"outfile\", outdir + \"slim_\" + SimID + \".rho_\" + rho + \".mu_\" + mu + \".N_\" + N + \".trees\");\n\n  setSeed(seed);\n\n  initializeTreeSeq(simplificationRatio=INF);\n  initializeMutationRate(0);\n  initializeMutationType(\"m1\", 0.5, \"f\", 0.0);\n  initializeMutationType(\"m2\", 1.0, \"f\", 0.5);  // introduced mutation\n  initializeGenomicElementType(\"g1\", m1, 1.0);\n  initializeGenomicElement(g1, 0, seqlength - 1);\n  initializeRecombinationRate(rho);\n}\n1 early() {\n  // Chapter 14.9: SLiM models diploid individuals that contain two\n  // haploid genomes; this is, at present, a design constraint in SLiM\n  // that cannot be modified. IOW: N individuals, 2*N genomes\n  sim.addSubpop(\"p1\", N);\n}\n1000 late() {\n  // introduce the sweep mutation\n  target = sample(p1.genomes, 1);\n  target.addNewDrawnMutation(m2, position);\n  // save the state of the simulation\n  sim.treeSeqOutput(tempdir() + \"slim_\" + SimID + \".trees\");\n}\n1000:100000 late() {\n  if (sim.countOfMutationsOfType(m2) == 0)\n    {\n      fixed = (sum(sim.substitutions.mutationType == m2) == 1);\n\n      if (fixed)\n    {\n      cat(SimID + \": FIXED\\n\");\n      cat(\"Writing output file : \" + outfile + \"\\n\");\n      sim.treeSeqOutput(outfile);\n      sim.simulationFinished();\n    }\n      else\n    {\n      cat(SimID + \": LOST - RESTARTING\\n\");\n\n      // go back to tick 1000\n      sim.readFromPopulationFile(tempdir() + \"slim_\" + SimID + \".trees\");\n      setSeed(rdunif(1, 0, asInteger(2^62) - 1));\n    }\n    }\n}\n\n\nRecipe to simulate a selective sweep.\n\n\nslim code to simulate a neutrally evolving locus on a 100kbp chromosome, with mutation rate \\(\\mu=10^{-8}\\), recombination rate \\(\\rho=10^{-8}\\), and \\(N_e=5,000\\).initialize() {\n  defineConstant(\"Nref\", 5e3);\n  if (!exists(\"seed\"))\n    defineConstant(\"seed\", getSeed());\n  defineConstant(\"SimID\", seed);\n  if (!exists(\"N\"))\n    defineConstant(\"N\", Nref);\n  if (!exists(\"outdir\"))\n    defineConstant(\"outdir\", tempdir());\n  if (!exists(\"mu\"))\n    defineConstant(\"mu\", 1e-7);\n  if (!exists(\"rho\"))\n    defineConstant(\"rho\", 1e-8);\n  if (!exists(\"seqlength\"))\n    defineConstant(\"seqlength\", 1e5);\n  if (!exists(\"outfile\"))\n    defineConstant(\"outfile\", outdir + \"slim_\" + SimID + \".rho_\" + rho + \".mu_\" + mu + \".N_\" + N + \".trees\");\n  setSeed(seed);\n\n  initializeTreeSeq(simplificationRatio=INF);\n  initializeMutationRate(0);\n  initializeMutationType(\"m1\", 0.5, \"f\", 0.0);\n  initializeGenomicElementType(\"g1\", m1, 1.0);\n  initializeGenomicElement(g1, 0, seqlength - 1);\n  initializeRecombinationRate(rho);\n}\n1 early() {\n  sim.addSubpop(\"p1\", N);\n}\n10000 early() {\n      cat(\"Writing output file : \" + outfile + \"\\n\");\n      sim.treeSeqOutput(outfile);\n      sim.simulationFinished();\n}\n\n\nRecipe to simulate a neutrally evolving locus."
  },
  {
    "objectID": "recipes/slim/index.html#sec-slim-recipe-selective-sweep",
    "href": "recipes/slim/index.html#sec-slim-recipe-selective-sweep",
    "title": "\n1 SLiM recipes",
    "section": "",
    "text": "slim code to simulate a selective sweep at a locus on a 1Mbp chromosome, with mutation rate \\(\\mu=10^{-8}\\), recombination rate \\(\\rho=10^{-8}\\), and \\(N_e=5,000\\).initialize() {\n  defineConstant(\"Nref\", 5e3);\n  if (!exists(\"seed\"))\n    defineConstant(\"seed\", getSeed());\n  defineConstant(\"SimID\", seed);\n  if (!exists(\"N\"))\n    defineConstant(\"N\", Nref);\n  if (!exists(\"outdir\"))\n    defineConstant(\"outdir\", tempdir());\n  if (!exists(\"mu\"))\n    defineConstant(\"mu\", 1e-8);\n  if (!exists(\"rho\"))\n    defineConstant(\"rho\", 1e-8);\n  if (!exists(\"seqlength\"))\n    defineConstant(\"seqlength\", 1e6);\n  if (!exists(\"position\"))\n    defineConstant(\"position\", asInteger(seqlength / 2));\n  if (!exists(\"outfile\"))\n    defineConstant(\"outfile\", outdir + \"slim_\" + SimID + \".rho_\" + rho + \".mu_\" + mu + \".N_\" + N + \".trees\");\n\n  setSeed(seed);\n\n  initializeTreeSeq(simplificationRatio=INF);\n  initializeMutationRate(0);\n  initializeMutationType(\"m1\", 0.5, \"f\", 0.0);\n  initializeMutationType(\"m2\", 1.0, \"f\", 0.5);  // introduced mutation\n  initializeGenomicElementType(\"g1\", m1, 1.0);\n  initializeGenomicElement(g1, 0, seqlength - 1);\n  initializeRecombinationRate(rho);\n}\n1 early() {\n  // Chapter 14.9: SLiM models diploid individuals that contain two\n  // haploid genomes; this is, at present, a design constraint in SLiM\n  // that cannot be modified. IOW: N individuals, 2*N genomes\n  sim.addSubpop(\"p1\", N);\n}\n1000 late() {\n  // introduce the sweep mutation\n  target = sample(p1.genomes, 1);\n  target.addNewDrawnMutation(m2, position);\n  // save the state of the simulation\n  sim.treeSeqOutput(tempdir() + \"slim_\" + SimID + \".trees\");\n}\n1000:100000 late() {\n  if (sim.countOfMutationsOfType(m2) == 0)\n    {\n      fixed = (sum(sim.substitutions.mutationType == m2) == 1);\n\n      if (fixed)\n    {\n      cat(SimID + \": FIXED\\n\");\n      cat(\"Writing output file : \" + outfile + \"\\n\");\n      sim.treeSeqOutput(outfile);\n      sim.simulationFinished();\n    }\n      else\n    {\n      cat(SimID + \": LOST - RESTARTING\\n\");\n\n      // go back to tick 1000\n      sim.readFromPopulationFile(tempdir() + \"slim_\" + SimID + \".trees\");\n      setSeed(rdunif(1, 0, asInteger(2^62) - 1));\n    }\n    }\n}\n\n\nRecipe to simulate a selective sweep."
  },
  {
    "objectID": "recipes/slim/index.html#sec-slim-recipe-neutral",
    "href": "recipes/slim/index.html#sec-slim-recipe-neutral",
    "title": "\n1 SLiM recipes",
    "section": "",
    "text": "slim code to simulate a neutrally evolving locus on a 100kbp chromosome, with mutation rate \\(\\mu=10^{-8}\\), recombination rate \\(\\rho=10^{-8}\\), and \\(N_e=5,000\\).initialize() {\n  defineConstant(\"Nref\", 5e3);\n  if (!exists(\"seed\"))\n    defineConstant(\"seed\", getSeed());\n  defineConstant(\"SimID\", seed);\n  if (!exists(\"N\"))\n    defineConstant(\"N\", Nref);\n  if (!exists(\"outdir\"))\n    defineConstant(\"outdir\", tempdir());\n  if (!exists(\"mu\"))\n    defineConstant(\"mu\", 1e-7);\n  if (!exists(\"rho\"))\n    defineConstant(\"rho\", 1e-8);\n  if (!exists(\"seqlength\"))\n    defineConstant(\"seqlength\", 1e5);\n  if (!exists(\"outfile\"))\n    defineConstant(\"outfile\", outdir + \"slim_\" + SimID + \".rho_\" + rho + \".mu_\" + mu + \".N_\" + N + \".trees\");\n  setSeed(seed);\n\n  initializeTreeSeq(simplificationRatio=INF);\n  initializeMutationRate(0);\n  initializeMutationType(\"m1\", 0.5, \"f\", 0.0);\n  initializeGenomicElementType(\"g1\", m1, 1.0);\n  initializeGenomicElement(g1, 0, seqlength - 1);\n  initializeRecombinationRate(rho);\n}\n1 early() {\n  sim.addSubpop(\"p1\", N);\n}\n10000 early() {\n      cat(\"Writing output file : \" + outfile + \"\\n\");\n      sim.treeSeqOutput(outfile);\n      sim.simulationFinished();\n}\n\n\nRecipe to simulate a neutrally evolving locus."
  },
  {
    "objectID": "exercises/population_structure/pca_admixture_1000G.html",
    "href": "exercises/population_structure/pca_admixture_1000G.html",
    "title": "PCA and Admixture for 1000 genomes (1000G) project",
    "section": "",
    "text": "In this notebook, we will apply PCA and Admixture analyses to real human data from the 1000 genomes project that aims to explore genetic diversity of human populations across the globe.\n\n\n\n1000 genomes project\n\n\n\n\nWe will be using low-coverage Phase 1 human from from the 1000G project. The data are not heavy, so easy to download and work with, and one can test a few popgen methods using these real data. First, you will need to make a directory, for example population_structure, for running the population structure analysis.\n\ncd /home/nikolay/Documents/Teaching/PopGen_2023\nmkdir population_structure\ncd population_structure\npwd\n\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure\n\n\n\nNext, we will download the bam-alignments from the 1000G project and unzip them.\n\nwget https://export.uppmax.uu.se/uppstore2018095/1000G.tar.gz\n#wget https://export.uppmax.uu.se/naiss2023-22-1084/1000G.tar.gz\ntar -xzf 1000G.tar.gz\nrm 1000G.tar.gz\n\n--2023-11-07 13:14:16--  https://export.uppmax.uu.se/uppstore2018095/1000G.tar.gz\nResolving export.uppmax.uu.se (export.uppmax.uu.se)... 89.44.248.44\nConnecting to export.uppmax.uu.se (export.uppmax.uu.se)|89.44.248.44|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 294605223 (281M) [application/x-gzip]\nSaving to: ‘1000G.tar.gz’\n\n1000G.tar.gz          0%[                    ]       0  --.-KB/s               1000G.tar.gz          1%[                    ]   2,95M  14,7MB/s               1000G.tar.gz          2%[                    ]   8,27M  20,7MB/s               1000G.tar.gz          4%[                    ]  13,65M  22,7MB/s               1000G.tar.gz          6%[&gt;                   ]  19,05M  23,8MB/s               1000G.tar.gz          9%[&gt;                   ]  26,20M  26,2MB/s               1000G.tar.gz         11%[=&gt;                  ]  33,34M  27,8MB/s               1000G.tar.gz         14%[=&gt;                  ]  40,50M  28,9MB/s               1000G.tar.gz         16%[==&gt;                 ]  47,65M  29,8MB/s               1000G.tar.gz         19%[==&gt;                 ]  54,78M  30,4MB/s               1000G.tar.gz         22%[===&gt;                ]  61,96M  31,0MB/s               1000G.tar.gz         24%[===&gt;                ]  69,09M  31,4MB/s               1000G.tar.gz         27%[====&gt;               ]  76,45M  31,8MB/s               1000G.tar.gz         29%[====&gt;               ]  83,61M  32,1MB/s               1000G.tar.gz         32%[=====&gt;              ]  91,00M  32,5MB/s               1000G.tar.gz         34%[=====&gt;              ]  98,15M  32,7MB/s    eta 6s     1000G.tar.gz         37%[======&gt;             ] 105,34M  33,8MB/s    eta 6s     1000G.tar.gz         40%[=======&gt;            ] 112,47M  34,4MB/s    eta 6s     1000G.tar.gz         42%[=======&gt;            ] 119,63M  35,3MB/s    eta 6s     1000G.tar.gz         45%[========&gt;           ] 126,79M  35,7MB/s    eta 6s     1000G.tar.gz         47%[========&gt;           ] 133,95M  35,9MB/s    eta 4s     1000G.tar.gz         50%[=========&gt;          ] 141,10M  35,9MB/s    eta 4s     1000G.tar.gz         52%[=========&gt;          ] 147,97M  35,8MB/s    eta 4s     1000G.tar.gz         55%[==========&gt;         ] 155,16M  35,8MB/s    eta 4s     1000G.tar.gz         57%[==========&gt;         ] 162,31M  35,8MB/s    eta 4s     1000G.tar.gz         60%[===========&gt;        ] 169,42M  35,8MB/s    eta 3s     1000G.tar.gz         62%[===========&gt;        ] 176,60M  35,8MB/s    eta 3s     1000G.tar.gz         65%[============&gt;       ] 183,77M  35,8MB/s    eta 3s     1000G.tar.gz         67%[============&gt;       ] 190,84M  35,7MB/s    eta 3s     1000G.tar.gz         69%[============&gt;       ] 196,58M  35,2MB/s    eta 3s     1000G.tar.gz         72%[=============&gt;      ] 203,15M  35,0MB/s    eta 2s     1000G.tar.gz         74%[=============&gt;      ] 210,30M  35,0MB/s    eta 2s     1000G.tar.gz         77%[==============&gt;     ] 217,40M  34,9MB/s    eta 2s     1000G.tar.gz         79%[==============&gt;     ] 224,59M  35,0MB/s    eta 2s     1000G.tar.gz         82%[===============&gt;    ] 231,89M  35,0MB/s    eta 2s     1000G.tar.gz         85%[================&gt;   ] 239,13M  35,0MB/s    eta 1s     1000G.tar.gz         87%[================&gt;   ] 246,30M  35,0MB/s    eta 1s     1000G.tar.gz         90%[=================&gt;  ] 253,51M  35,1MB/s    eta 1s     1000G.tar.gz         92%[=================&gt;  ] 260,66M  35,2MB/s    eta 1s     1000G.tar.gz         95%[==================&gt; ] 267,75M  35,1MB/s    eta 1s     1000G.tar.gz         97%[==================&gt; ] 274,86M  35,1MB/s    eta 0s     1000G.tar.gz        100%[===================&gt;] 280,96M  35,1MB/s    in 8,2s    \n\n2023-11-07 13:14:24 (34,4 MB/s) - ‘1000G.tar.gz’ saved [294605223/294605223]\n\n\n\n\nFor running the PCA and Admixture analyses with ANGSD, we will need to build a list of the available bam-files. It is also useful for us to check from this list what human populations are present in the Phase 1 of 1000G project.\n\ncd 1000G_bam_files\nfind $PWD -name '*.bam' &gt; ../1000G_bam_list.txt\ncd ..\nhead 1000G_bam_list.txt\n\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18543.mapped.ILLUMINA.bwa.CHB.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA20334.mapped.ILLUMINA.bwa.ASW.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18633.mapped.ILLUMINA.bwa.CHB.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12348.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12842.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA11832.mapped.ILLUMINA.bwa.CEU.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12275.mapped.ILLUMINA.bwa.CEU.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA19761.mapped.ILLUMINA.bwa.MXL.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA19213.mapped.ILLUMINA.bwa.YRI.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18558.mapped.ILLUMINA.bwa.CHB.low_coverage.20130415.bam\n\n\n\n\nwc -l 1000G_bam_list.txt\n\n435 1000G_bam_list.txt\n\n\n\nWe can see that in total our dataset includes 435 bam-files corresponding to African (YRI), European (CEU) and Asian (CHB) populations, as well as two admixed populations: African-American (ASW) and Mexican (MXL). ANGSD operates with genetic variation computed via genotype likelihoods. Therefore, we will have to perform genotype likelihoods variant calling prior to PCA and Admixture analyses. If you do not have ANGSD installed already, it can be downloaded and installed using instrictions from http://www.popgen.dk/angsd/index.php/Installation.\n\nangsd -bam 1000G_bam_list.txt -GL 2 -doMajorMinor 1 -doMaf 1 -SNP_pval 2e-6 -minMapQ 30 -minQ 20 -minInd 25 -minMaf 0.05 -doGlf 2 -out 1000G -P 5\n\n    -&gt; angsd version: 0.940-dirty (htslib: 1.16) build(Aug 23 2023 11:40:54)\n    -&gt; angsd -bam 1000G_bam_list.txt -GL 2 -doMajorMinor 1 -doMaf 1 -SNP_pval 2e-6 -minMapQ 30 -minQ 20 -minInd 25 -minMaf 0.05 -doGlf 2 -out 1000G -P 5 \n    -&gt; Inputtype is BAM/CRAM\n[multiReader] 435 samples in 435 input files\n    -&gt; SNP-filter using a pvalue: 2.000000e-06 correspond to 22.595043 likelihood units\n    -&gt; Parsing 435 number of samples \n\n    -&gt; Allocated ~ 10 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 20 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 30 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 40 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 50 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 60 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 70 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 80 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 90 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 100 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 110 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 120 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 130 million nodes to the nodepool, this is not an estimate of the memory usage\n    -&gt; Printing at chr: 7 pos:20911210 chunknumber 100 contains 2 sites -&gt; Printing at chr: 14 pos:20692360 chunknumber 200 contains 699 sites\n    -&gt; Done reading data waiting for calculations to finish\n    -&gt; Done waiting for threads\n    -&gt; Output filenames:\n        -&gt;\"1000G.arg\"\n        -&gt;\"1000G.beagle.gz\"\n        -&gt;\"1000G.mafs.gz\"\n    -&gt; Tue Nov  7 13:38:46 2023\n    -&gt; Arguments and parameters for all analysis are located in .arg file\n    -&gt; Total number of sites analyzed: 167518\n    -&gt; Number of sites retained after filtering: 1306 \n    [ALL done] cpu-time used =  150.90 sec\n    [ALL done] walltime used =  61.00 sec\n\n\n\nThe calculated genotype likelihoods for 106 variable sites are contained within the 1000G.beagle.gz file, which we are now going to use for performing PCA analysis. The second returned file, 1000G.mafs.gz, contains information about allele frequencies of the identified genetic variants. You can read about advantages of doing PCA via genotype likelihoods for example here. The PCANGSD method can be installed separately from ANGSD from https://github.com/Rosemeis/pcangsd.\n\npcangsd -b 1000G.beagle.gz -o pca_1000G -t 4\n\n-------------------------------------\nPCAngsd v1.2\nJonas Meisner and Anders Albrechtsen.\nUsing 4 thread(s).\n-------------------------------------\n\nParsing Beagle file.\nLoaded 1306 sites and 435 individuals.\nEstimating minor allele frequencies.\nEM (MAF) converged at iteration: 16\nNumber of sites after MAF filtering (0.05): 1306\n\nEstimating covariance matrix.\nUsing 15 principal components (MAP test).\nIndividual allele frequencies estimated (1).\nIndividual allele frequencies estimated (2).    RMSE=0.066385679\nIndividual allele frequencies estimated (3).    RMSE=0.050454147\nIndividual allele frequencies estimated (4).    RMSE=0.006292501\nIndividual allele frequencies estimated (5).    RMSE=0.025063241\nIndividual allele frequencies estimated (6).    RMSE=0.003102337\nIndividual allele frequencies estimated (7).    RMSE=0.024891028\nIndividual allele frequencies estimated (8).    RMSE=0.002931002\nIndividual allele frequencies estimated (9).    RMSE=0.024905935\nIndividual allele frequencies estimated (10).   RMSE=0.003440379\nIndividual allele frequencies estimated (11).   RMSE=0.024913993\nIndividual allele frequencies estimated (12).   RMSE=0.002420334\nIndividual allele frequencies estimated (13).   RMSE=0.002137294\nIndividual allele frequencies estimated (14).   RMSE=0.001955432\nIndividual allele frequencies estimated (15).   RMSE=0.001708493\nIndividual allele frequencies estimated (16).   RMSE=0.001492948\nIndividual allele frequencies estimated (17).   RMSE=0.001377949\nIndividual allele frequencies estimated (18).   RMSE=0.024781208\nIndividual allele frequencies estimated (19).   RMSE=0.001125538\nIndividual allele frequencies estimated (20).   RMSE=0.02478423\nIndividual allele frequencies estimated (21).   RMSE=0.000906437\nIndividual allele frequencies estimated (22).   RMSE=0.000914994\nIndividual allele frequencies estimated (23).   RMSE=0.000651902\nIndividual allele frequencies estimated (24).   RMSE=0.000590639\nIndividual allele frequencies estimated (25).   RMSE=0.000566323\nIndividual allele frequencies estimated (26).   RMSE=0.024761193\nIndividual allele frequencies estimated (27).   RMSE=0.000427994\nIndividual allele frequencies estimated (28).   RMSE=0.000424277\nIndividual allele frequencies estimated (29).   RMSE=0.00039096\nIndividual allele frequencies estimated (30).   RMSE=0.000348833\nIndividual allele frequencies estimated (31).   RMSE=0.000310296\nIndividual allele frequencies estimated (32).   RMSE=0.000292033\nIndividual allele frequencies estimated (33).   RMSE=0.000268337\nIndividual allele frequencies estimated (34).   RMSE=0.024759974\nIndividual allele frequencies estimated (35).   RMSE=0.000225774\nIndividual allele frequencies estimated (36).   RMSE=0.000209186\nIndividual allele frequencies estimated (37).   RMSE=0.000194486\nIndividual allele frequencies estimated (38).   RMSE=0.000179259\nIndividual allele frequencies estimated (39).   RMSE=0.000164353\nIndividual allele frequencies estimated (40).   RMSE=0.000144426\nIndividual allele frequencies estimated (41).   RMSE=0.000147983\nIndividual allele frequencies estimated (42).   RMSE=0.000143973\nIndividual allele frequencies estimated (43).   RMSE=0.000138792\nIndividual allele frequencies estimated (44).   RMSE=0.000135654\nIndividual allele frequencies estimated (45).   RMSE=0.000153877\nIndividual allele frequencies estimated (46).   RMSE=0.000120664\nIndividual allele frequencies estimated (47).   RMSE=0.000112655\nIndividual allele frequencies estimated (48).   RMSE=0.000110528\nIndividual allele frequencies estimated (49).   RMSE=0.000133146\nIndividual allele frequencies estimated (50).   RMSE=0.000102072\nIndividual allele frequencies estimated (51).   RMSE=0.000100332\nIndividual allele frequencies estimated (52).   RMSE=0.024759417\nIndividual allele frequencies estimated (53).   RMSE=8.5162e-05\nIndividual allele frequencies estimated (54).   RMSE=8.0157e-05\nIndividual allele frequencies estimated (55).   RMSE=7.5776e-05\nIndividual allele frequencies estimated (56).   RMSE=7.2006e-05\nIndividual allele frequencies estimated (57).   RMSE=0.024759391\nIndividual allele frequencies estimated (58).   RMSE=6.5975e-05\nIndividual allele frequencies estimated (59).   RMSE=6.2556e-05\nIndividual allele frequencies estimated (60).   RMSE=6.0224e-05\nIndividual allele frequencies estimated (61).   RMSE=5.7719e-05\nIndividual allele frequencies estimated (62).   RMSE=5.5379e-05\nIndividual allele frequencies estimated (63).   RMSE=5.3232e-05\nIndividual allele frequencies estimated (64).   RMSE=5.0864e-05\nIndividual allele frequencies estimated (65).   RMSE=4.9148e-05\nIndividual allele frequencies estimated (66).   RMSE=4.7062e-05\nIndividual allele frequencies estimated (67).   RMSE=4.5683e-05\nIndividual allele frequencies estimated (68).   RMSE=4.4471e-05\nIndividual allele frequencies estimated (69).   RMSE=5.0811e-05\nIndividual allele frequencies estimated (70).   RMSE=4.275e-05\nIndividual allele frequencies estimated (71).   RMSE=4.1382e-05\nIndividual allele frequencies estimated (72).   RMSE=4.005e-05\nIndividual allele frequencies estimated (73).   RMSE=3.9036e-05\nIndividual allele frequencies estimated (74).   RMSE=3.7008e-05\nIndividual allele frequencies estimated (75).   RMSE=3.5606e-05\nIndividual allele frequencies estimated (76).   RMSE=3.4998e-05\nIndividual allele frequencies estimated (77).   RMSE=3.3238e-05\nIndividual allele frequencies estimated (78).   RMSE=3.3203e-05\nIndividual allele frequencies estimated (79).   RMSE=3.0969e-05\nIndividual allele frequencies estimated (80).   RMSE=3.0605e-05\nIndividual allele frequencies estimated (81).   RMSE=2.9137e-05\nIndividual allele frequencies estimated (82).   RMSE=2.8265e-05\nIndividual allele frequencies estimated (83).   RMSE=2.8226e-05\nIndividual allele frequencies estimated (84).   RMSE=2.6588e-05\nIndividual allele frequencies estimated (85).   RMSE=2.6364e-05\nIndividual allele frequencies estimated (86).   RMSE=2.5135e-05\nIndividual allele frequencies estimated (87).   RMSE=2.4293e-05\nIndividual allele frequencies estimated (88).   RMSE=2.3529e-05\nIndividual allele frequencies estimated (89).   RMSE=2.2974e-05\nIndividual allele frequencies estimated (90).   RMSE=2.1807e-05\nIndividual allele frequencies estimated (91).   RMSE=2.1036e-05\nIndividual allele frequencies estimated (92).   RMSE=2.1025e-05\nIndividual allele frequencies estimated (93).   RMSE=2.0272e-05\nIndividual allele frequencies estimated (94).   RMSE=1.9758e-05\nIndividual allele frequencies estimated (95).   RMSE=1.9355e-05\nIndividual allele frequencies estimated (96).   RMSE=1.8164e-05\nIndividual allele frequencies estimated (97).   RMSE=1.8058e-05\nIndividual allele frequencies estimated (98).   RMSE=1.7484e-05\nIndividual allele frequencies estimated (99).   RMSE=1.7081e-05\nIndividual allele frequencies estimated (100).  RMSE=1.6462e-05\nIndividual allele frequencies estimated (101).  RMSE=1.6259e-05\nPCAngsd did not converge!\nSaved covariance matrix as pca_1000G.cov\n\n\nTotal elapsed time: 0m3s\n\n\n\nA peculiarity of computing PCA via ANGSD is that it does not directly generates a PCA plot but returns a variance-covariance matrix pca_1000G.cov which you will have to manually eigen-value-decompose and plot the eigen vectors in R. Note, that in order to color data points on the PCA plot, we will parse the list of bam-files from above in R, and extract the populations labels.\n\nsetwd(\"/home/nikolay/Documents/Teaching/PopGen_2023/population_structure\")\n\nC &lt;- as.matrix(read.table(\"pca_1000G.cov\"))\ne &lt;- eigen(C)\npops &lt;- readLines(\"1000G_bam_list.txt\")\npops &lt;- sapply(strsplit(pops, \"\\\\.\"), function(x) x[6])\nmycolor &lt;- rep(\"red\", length(pops))\nmycolor[pops == \"CEU\"] &lt;- \"blue\"\nmycolor[pops == \"CHB\"] &lt;- \"green\"\nmycolor[pops == \"MXL\"] &lt;- \"brown\"\nmycolor[pops == \"ASW\"] &lt;- \"magenta\"\nplot(e$vectors[, 1:2], xlab = \"PC1\", ylab = \"PC2\", main = \"PCA 1000G Project\", col = mycolor, pch = 19)\nlegend(\"bottomright\", c(\"YRI\", \"CEU\", \"CHB\", \"MXL\", \"ASW\"), fill = c(\"red\", \"blue\", \"green\", \"brown\", \"magenta\"), cex = 1, inset = 0.02)\n\n\n\n\n\n\n\n\nAs expected, we have three clear clusters (main sources of variation) corresponding to African (YRI), European (CEU) and Asian (CHB) populations, with the admixed populations falling in between. Let us see that this conclusion can be further confirmed from the Admixture analysis in the next section.\n\n\n\nIn this section, we will perform admixture analysis using the genetic variation data from 1000G project identified in the previous section, i.e. the file 1000G.beagle.gz. We will keep using the genotype likelihoods approach with ANGSD, and utilize NGSadmix, which is a tool within ANGSD. You do not need to install NGSadmix separetely as it is installed together with ANGSD, however, in case there are problems, the NGSadmix executable can be found within pcangsd/misc and launched from there. Please note that below we explicitly ask NGSadmix to detect K = 3 clusters.\n\nNGSadmix -likes 1000G.beagle.gz -K 3 -minMaf 0.05 -seed 1 -o 1000G\n\nInput: lname=1000G.beagle.gz nPop=3, fname=(null) qname=(null) outfiles=1000G\nSetup: seed=1 nThreads=1 method=1\nConvergence: maxIter=2000 tol=0.000010 tolLike50=0.100000 dymBound=0\nFilters: misTol=0.050000 minMaf=0.050000 minLrt=0.000000 minInd=0\nInput file has dim: nsites=1306 nind=435\nInput file has dim (AFTER filtering): nsites=1306 nind=435\niter[start] like is=725129.713622\niter[50] like is=-454493.026878 thres=0.000841\niter[100] like is=-454474.788034 thres=0.000032\nEM accelerated has reached convergence with tol 0.000010\nbest like=-454474.752968 after 115 iterations\n    -&gt; Dumpedfiles are: 1000G.log\n    -&gt; Dumpedfiles are: 1000G.qopt\n    -&gt; Dumpedfiles are: 1000G.fopt.gz\n    [ALL done] cpu-time used =  4.84 sec\n    [ALL done] walltime used =  5.00 sec\n\n\n\nNGSadmix produces two files: 1000G.qopt and 1000G.fopt.gz containing admixture proportions and allele frequencies, respectively. If we look inside the 1000G.qopt files, we will see that for eahc of the 435 data points it contains fractions (i.e. contributions) of each of the 3 clusters that we required NGSadmix to identify.\n\nhead 1000G.qopt\n\n0.00543120337380969750 0.03047764250291678037 0.96409115412327339723 \n0.39746657097866411323 0.59699325992555196674 0.00554016909578402498 \n0.00291473396727394071 0.00000000099999999999 0.99708526503272598696 \n0.89272766803245084954 0.00000008404621942802 0.10727224792132973585 \n0.87148184717709176184 0.12851815182290812767 0.00000000099999999997 \n0.81529873054609225402 0.15780315987658605215 0.02689810957732174240 \n0.83248589650022153386 0.07729402969534844570 0.09022007380443013147 \n0.71004516603356415683 0.00000000099999999998 0.28995483296643576043 \n0.09294217159488990521 0.90705782740511009532 0.00000000099999999997 \n0.00000000099999999994 0.00000000099999999994 0.99999999799999994554 \n\n\n\nFinally, we will plot the results using some helping functions from the ANGSD and NGSadmix developers.\n\nsetwd(\"/home/nikolay/Documents/Teaching/PopGen_2023/population_structure\")\n\npops &lt;- readLines(\"1000G_bam_list.txt\")\npops &lt;- sapply(strsplit(pops, \"\\\\.\"), function(x) x[6])\nsource(\"https://raw.githubusercontent.com/GenisGE/evalAdmix/master/visFuns.R\")\nqopts &lt;- read.table(\"1000G.qopt\")\nord &lt;- orderInds(pop = pops, q = qopts, popord = c(\"YRI\", \"ASW\", \"CEU\", \"MXL\", \"CHB\"))\nbarplot(t(qopts)[, ord], col = c(3, 2, 4), las = 2, space = 0, border = NA)\ntext(sort(tapply(1:length(pops), pops[ord], mean)), 0.1, unique(pops[ord]))\nabline(v = cumsum(sapply(unique(pops[ord]), function(x) {sum(pops[ord] == x)})), col = 1, lwd = 1.2)\n\n\n\n\n\n\n\n\nAgain, we see three nearly unadmixed populations: YRI, CHB and CEU, and two admixed populations: MXL (mixture of CEU and CHB) and ASW (mixture of YRI and CEU). Therefore, one can infer for each individual, how much this individual is admixed and what are the populations contributing to the admixture.\n\n\n\nIn this section, we will perform Fst analysis via genotype likelihoods using the 1000G data, i.e. we will compare allele frequencies between European (CEU) and African (YRI) populations. The way ANGSD does it, it first computes Site Frequency Spectra (SFS) for CEU and YRI individually. So we will have to subset the list of bam-files to CEU and YRI individuals only and compute SFS. Below, we will start with CEU:\n\ngrep CEU 1000G_bam_list.txt &gt; 1000G_CEU_bam_list.txt\nwc -l 1000G_CEU_bam_list.txt\nhead 1000G_CEU_bam_list.txt\n\n99 1000G_CEU_bam_list.txt\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12348.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12842.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA11832.mapped.ILLUMINA.bwa.CEU.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12275.mapped.ILLUMINA.bwa.CEU.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA11830.mapped.ILLUMINA.bwa.CEU.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12777.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12287.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA07357.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12286.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA11930.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n\n\n\n\nangsd -b 1000G_CEU_bam_list.txt -anc anc.fa -out CEU -dosaf 1 -gl 1\n\n    -&gt; angsd version: 0.940-dirty (htslib: 1.16) build(Aug 23 2023 11:40:54)\n    -&gt; angsd -b 1000G_CEU_bam_list.txt -anc anc.fa -out CEU -dosaf 1 -gl 1 \n    -&gt; Inputtype is BAM/CRAM\n[multiReader] 99 samples in 99 input files\n    -&gt; Reading fasta: anc.fa\n    -&gt; Parsing 99 number of samples \n    -&gt; Printing at chr: 7 pos:20690960 chunknumber 100 contains 621 sites   -&gt; Printing at chr: 13 pos:20676861 chunknumber 200 contains 833 sites\n    -&gt; Done reading data waiting for calculations to finish\n    -&gt; Done waiting for threads\n    -&gt; Output filenames:\n        -&gt;\"CEU.arg\"\n        -&gt;\"CEU.saf.gz\"\n        -&gt;\"CEU.saf.pos.gz\"\n        -&gt;\"CEU.saf.idx\"\n    -&gt; Tue Nov  7 14:21:40 2023\n    -&gt; Arguments and parameters for all analysis are located in .arg file\n    -&gt; Total number of sites analyzed: 163347\n    -&gt; Number of sites retained after filtering: 162624 \n    [ALL done] cpu-time used =  41.99 sec\n    [ALL done] walltime used =  42.00 sec\n\n\n\nNow, we will subset YRI individuals and compute SFS for the African population.\n\ngrep YRI 1000G_bam_list.txt &gt; 1000G_YRI_bam_list.txt\nwc -l 1000G_YRI_bam_list.txt\nhead 1000G_YRI_bam_list.txt\n\n108 1000G_YRI_bam_list.txt\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA19213.mapped.ILLUMINA.bwa.YRI.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18504.mapped.ILLUMINA.bwa.YRI.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA19108.mapped.ILLUMINA.bwa.YRI.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA19238.mapped.ILLUMINA.bwa.YRI.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA19204.mapped.ILLUMINA.bwa.YRI.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18516.mapped.ILLUMINA.bwa.YRI.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18878.mapped.ILLUMINA.bwa.YRI.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18874.mapped.ILLUMINA.bwa.YRI.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18488.mapped.ILLUMINA.bwa.YRI.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18861.mapped.ILLUMINA.bwa.YRI.low_coverage.20130415.bam\n\n\n\n\nangsd -b 1000G_YRI_bam_list.txt -anc anc.fa -out YRI -dosaf 1 -gl 1\n\n    -&gt; angsd version: 0.940-dirty (htslib: 1.16) build(Aug 23 2023 11:40:54)\n    -&gt; angsd -b 1000G_YRI_bam_list.txt -anc anc.fa -out YRI -dosaf 1 -gl 1 \n    -&gt; Inputtype is BAM/CRAM\n[multiReader] 108 samples in 108 input files\n    -&gt; Reading fasta: anc.fa\n    -&gt; Parsing 108 number of samples \n    -&gt; Printing at chr: 8 pos:20152114 chunknumber 100 contains 597 sites   -&gt; Printing at chr: 16 pos:20080879 chunknumber 200 contains 601 sites\n    -&gt; Done reading data waiting for calculations to finish\n    -&gt; Done waiting for threads\n    -&gt; Output filenames:\n        -&gt;\"YRI.arg\"\n        -&gt;\"YRI.saf.gz\"\n        -&gt;\"YRI.saf.pos.gz\"\n        -&gt;\"YRI.saf.idx\"\n    -&gt; Tue Nov  7 14:22:50 2023\n    -&gt; Arguments and parameters for all analysis are located in .arg file\n    -&gt; Total number of sites analyzed: 159100\n    -&gt; Number of sites retained after filtering: 158453 \n    [ALL done] cpu-time used =  44.02 sec\n    [ALL done] walltime used =  44.00 sec\n\n\n\n\nrealSFS CEU.saf.idx YRI.saf.idx &gt; CEU.YRI.ml\n\n[persaf::persaf_init] Version of CEU.saf.idx is 3\n[persaf::persaf_init] Assuming .saf.gz file is CEU.saf.gz\n[persaf::persaf_init] Assuming .saf.pos.gz file is CEU.saf.pos.gz\n[persaf::persaf_init] Version of YRI.saf.idx is 3\n[persaf::persaf_init] Assuming .saf.gz file is YRI.saf.gz\n[persaf::persaf_init] Assuming .saf.pos.gz file is YRI.saf.pos.gz\n    -&gt; args: tole:0.000000 nthreads:4 maxiter:100 nsites(block):0 start:(null) chr:(null) start:-1 stop:-1 fstout:(null) oldout:0 seed:-1 bootstrap:0 resample_chr:0 whichFst:0 fold:0 ref:(null) anc:(null)\n[main] Multi SFS is 'still' under development. Please report strange behaviour.\n    -&gt; The choice of -nSites will require atleast: 45.203266 megabyte memory, that is at least: 0.28% of total memory\n    -&gt; dim(CEU.saf.idx):199\n    -&gt; dim(YRI.saf.idx):217\n    -&gt; Dimension of parameter space: 43183\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:1\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[1] from pop0:  11218\n    -&gt; Sites to keep[1] from pop1:  11218\n    -&gt; [readdata] lastread:11218 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:11218\n    -&gt; Only read nSites: 11218 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:10\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[10] from pop0: 10005\n    -&gt; Sites to keep[10] from pop1: 10005\n    -&gt; [readdata] lastread:10005 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:21223\n    -&gt; Only read nSites: 21223 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:11\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[11] from pop0: 11825\n    -&gt; Sites to keep[11] from pop1: 11825\n    -&gt; [readdata] lastread:11825 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:33048\n    -&gt; Only read nSites: 33048 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:12\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[12] from pop0: 7433\n    -&gt; Sites to keep[12] from pop1: 7433\n    -&gt; [readdata] lastread:7433 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:40481\n    -&gt; Only read nSites: 40481 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:13\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[13] from pop0: 4580\n    -&gt; Sites to keep[13] from pop1: 4580\n    -&gt; [readdata] lastread:4580 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:45061\n    -&gt; Only read nSites: 45061 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:14\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[14] from pop0: 4269\n    -&gt; Sites to keep[14] from pop1: 4269\n    -&gt; [readdata] lastread:4269 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:49330\n    -&gt; Only read nSites: 49330 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:16\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[16] from pop0: 8855\n    -&gt; Sites to keep[16] from pop1: 8855\n    -&gt; [readdata] lastread:8855 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:58185\n    -&gt; Only read nSites: 58185 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:17\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[17] from pop0: 1564\n    -&gt; Sites to keep[17] from pop1: 1564\n    -&gt; [readdata] lastread:1564 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:59749\n    -&gt; Only read nSites: 59749 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:18\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[18] from pop0: 6271\n    -&gt; Sites to keep[18] from pop1: 6271\n    -&gt; [readdata] lastread:6271 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:66020\n    -&gt; Only read nSites: 66020 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:19\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[19] from pop0: 1406\n    -&gt; Sites to keep[19] from pop1: 1406\n    -&gt; [readdata] lastread:1406 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:67426\n    -&gt; Only read nSites: 67426 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:2\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[2] from pop0:  9853\n    -&gt; Sites to keep[2] from pop1:  9853\n    -&gt; [readdata] lastread:9853 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:77279\n    -&gt; Only read nSites: 77279 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:20\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[20] from pop0: 11636\n    -&gt; Sites to keep[20] from pop1: 11636\n    -&gt; [readdata] lastread:11636 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:88915\n    -&gt; Only read nSites: 88915 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:21\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[21] from pop0: 7716\n    -&gt; Sites to keep[21] from pop1: 7716\n    -&gt; [readdata] lastread:7716 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:96631\n    -&gt; Only read nSites: 96631 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:22\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[22] from pop0: 3014\n    -&gt; Sites to keep[22] from pop1: 3014\n    -&gt; [readdata] lastread:3014 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:99645\n    -&gt; Only read nSites: 99645 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:3\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[3] from pop0:  7606\n    -&gt; Sites to keep[3] from pop1:  7606\n    -&gt; [readdata] lastread:7606 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:107251\n    -&gt; Only read nSites: 107251 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:4\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[4] from pop0:  6424\n    -&gt; Sites to keep[4] from pop1:  6424\n    -&gt; [readdata] lastread:6424 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:113675\n    -&gt; Only read nSites: 113675 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:5\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[5] from pop0:  3210\n    -&gt; Sites to keep[5] from pop1:  3210\n    -&gt; [readdata] lastread:3210 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:116885\n    -&gt; Only read nSites: 116885 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:6\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[6] from pop0:  9615\n    -&gt; Sites to keep[6] from pop1:  9615\n    -&gt; [readdata] lastread:9615 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:126500\n    -&gt; Only read nSites: 126500 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:7\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[7] from pop0:  8824\n    -&gt; Sites to keep[7] from pop1:  8824\n    -&gt; [readdata] lastread:8824 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:135324\n    -&gt; Only read nSites: 135324 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:8\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[8] from pop0:  16633\n    -&gt; Sites to keep[8] from pop1:  16633\n    -&gt; [readdata] lastread:16633 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:151957\n    -&gt; Only read nSites: 151957 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:9\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[9] from pop0:  6247\n    -&gt; Sites to keep[9] from pop1:  6247\n    -&gt; [readdata] lastread:6247 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:158204\n    -&gt; Only read nSites: 158204 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Will run optimization on nSites: 158204\n------------\nstartlik=-1500482.960971\nlik[2]=-51446.465409 diff=1.449036e+06 alpha:1.000000 sr2:2.565215e-01 nsites_difference[0]: 1.304900e+05\n    -&gt; Instability detected, accelerated guess is too close to bound or outside will fallback to regular EM for this step\nlik[4]=-36952.653747 diff=1.449381e+04 alpha:1.520022 sr2:1.189258e-02 nsites_difference[0]: 2.079652e+04\nlik[6]=-35693.960846 diff=1.258693e+03 alpha:1.000000 sr2:1.954655e-04 nsites_difference[0]: 2.559705e+03\nlik[8]=-35550.497375 diff=1.434635e+02 alpha:1.802902 sr2:5.252347e-06 nsites_difference[0]: 4.155786e+02\nlik[10]=-35515.651398 diff=3.484598e+01 alpha:1.000000 sr2:2.383104e-07 nsites_difference[0]: 8.639444e+01\nlik[12]=-35497.489801 diff=1.816160e+01 alpha:2.286558 sr2:1.786152e-08 nsites_difference[1]: 2.290752e+01\nlik[14]=-35485.181049 diff=1.230875e+01 alpha:1.000000 sr2:2.166627e-09 nsites_difference[1]: 8.282941e+00\nlik[16]=-35476.102765 diff=9.078283e+00 alpha:3.702718 sr2:4.923696e-10 nsites_difference[1]: 3.370521e+00\nlik[18]=-35469.117497 diff=6.985269e+00 alpha:1.000000 sr2:2.181576e-10 nsites_difference[7]: 1.982587e+00\nlik[20]=-35463.588847 diff=5.528650e+00 alpha:4.000000 sr2:1.404275e-10 nsites_difference[7]: 1.666359e+00\nlik[22]=-35459.119268 diff=4.469579e+00 alpha:1.000000 sr2:1.036972e-10 nsites_difference[7]: 1.395785e+00\nlik[24]=-35455.444426 diff=3.674842e+00 alpha:4.000000 sr2:8.067148e-11 nsites_difference[7]: 1.171575e+00\nlik[26]=-35452.380826 diff=3.063601e+00 alpha:1.000000 sr2:6.443842e-11 nsites_difference[7]: 9.876003e-01\nlik[28]=-35449.796828 diff=2.583998e+00 alpha:4.000000 sr2:5.239715e-11 nsites_difference[7]: 8.364649e-01\nlik[30]=-35447.595469 diff=2.201359e+00 alpha:1.000000 sr2:4.321692e-11 nsites_difference[7]: 7.116037e-01\nlik[32]=-35445.703737 diff=1.891731e+00 alpha:4.000000 sr2:3.608661e-11 nsites_difference[11]: 6.311199e-01\nlik[34]=-35444.065627 diff=1.638110e+00 alpha:1.000000 sr2:3.046627e-11 nsites_difference[11]: 5.900838e-01\nlik[36]=-35442.637478 diff=1.428149e+00 alpha:4.000000 sr2:2.597932e-11 nsites_difference[11]: 5.522152e-01\nlik[38]=-35441.384775 diff=1.252703e+00 alpha:1.000000 sr2:2.235567e-11 nsites_difference[11]: 5.171917e-01\nlik[40]=-35440.279895 diff=1.104880e+00 alpha:4.000000 sr2:1.939778e-11 nsites_difference[11]: 4.847370e-01\nlik[42]=-35439.300487 diff=9.794077e-01 alpha:1.000000 sr2:1.695900e-11 nsites_difference[11]: 4.546117e-01\nlik[44]=-35438.428292 diff=8.721947e-01 alpha:4.000000 sr2:1.492908e-11 nsites_difference[11]: 4.266064e-01\nlik[46]=-35437.648264 diff=7.800289e-01 alpha:1.000000 sr2:1.322427e-11 nsites_difference[11]: 4.005367e-01\nlik[48]=-35436.947904 diff=7.003600e-01 alpha:4.000000 sr2:1.178030e-11 nsites_difference[11]: 3.762390e-01\nlik[50]=-35436.316761 diff=6.311430e-01 alpha:1.000000 sr2:1.054743e-11 nsites_difference[11]: 3.535673e-01\nlik[52]=-35435.746037 diff=5.707233e-01 alpha:4.000000 sr2:9.486871e-12 nsites_difference[16]: 3.430160e-01\nlik[54]=-35435.228286 diff=5.177516e-01 alpha:1.000000 sr2:8.568103e-12 nsites_difference[16]: 3.329148e-01\nlik[56]=-35434.757167 diff=4.711190e-01 alpha:4.000000 sr2:7.766956e-12 nsites_difference[16]: 3.230556e-01\nlik[58]=-35434.327258 diff=4.299086e-01 alpha:1.000000 sr2:7.064145e-12 nsites_difference[16]: 3.134433e-01\nlik[60]=-35433.933901 diff=3.933572e-01 alpha:4.000000 sr2:6.444171e-12 nsites_difference[16]: 3.040804e-01\nlik[62]=-35433.573075 diff=3.608262e-01 alpha:1.000000 sr2:5.894488e-12 nsites_difference[16]: 2.949677e-01\nlik[64]=-35433.241296 diff=3.317786e-01 alpha:4.000000 sr2:5.404870e-12 nsites_difference[16]: 2.861046e-01\nlik[66]=-35432.935536 diff=3.057603e-01 alpha:1.000000 sr2:4.966920e-12 nsites_difference[16]: 2.774893e-01\nlik[68]=-35432.653149 diff=2.823863e-01 alpha:4.000000 sr2:4.573696e-12 nsites_difference[16]: 2.691193e-01\nlik[70]=-35432.391821 diff=2.613280e-01 alpha:1.000000 sr2:4.219417e-12 nsites_difference[16]: 2.609914e-01\nlik[72]=-35432.149517 diff=2.423047e-01 alpha:4.000000 sr2:3.899235e-12 nsites_difference[16]: 2.531018e-01\nlik[74]=-35431.924441 diff=2.250752e-01 alpha:1.000000 sr2:3.609056e-12 nsites_difference[16]: 2.454464e-01\nlik[76]=-35431.715010 diff=2.094317e-01 alpha:4.000000 sr2:3.345401e-12 nsites_difference[16]: 2.380208e-01\nlik[78]=-35431.519815 diff=1.951947e-01 alpha:1.000000 sr2:3.105296e-12 nsites_difference[16]: 2.308202e-01\nlik[80]=-35431.337606 diff=1.822086e-01 alpha:4.000000 sr2:2.886179e-12 nsites_difference[16]: 2.238396e-01\nlik[82]=-35431.167268 diff=1.703380e-01 alpha:1.000000 sr2:2.685833e-12 nsites_difference[16]: 2.170740e-01\nlik[84]=-35431.007803 diff=1.594649e-01 alpha:4.000000 sr2:2.502330e-12 nsites_difference[16]: 2.105180e-01\nlik[86]=-35430.858317 diff=1.494862e-01 alpha:1.000000 sr2:2.333982e-12 nsites_difference[16]: 2.041665e-01\nlik[88]=-35430.718006 diff=1.403111e-01 alpha:4.000000 sr2:2.179306e-12 nsites_difference[16]: 1.980140e-01\nlik[90]=-35430.586146 diff=1.318602e-01 alpha:1.000000 sr2:2.036993e-12 nsites_difference[16]: 1.920553e-01\nlik[92]=-35430.462083 diff=1.240630e-01 alpha:4.000000 sr2:1.905885e-12 nsites_difference[16]: 1.862849e-01\nlik[94]=-35430.345226 diff=1.168575e-01 alpha:1.000000 sr2:1.784948e-12 nsites_difference[16]: 1.806975e-01\nlik[96]=-35430.235037 diff=1.101884e-01 alpha:4.000000 sr2:1.673264e-12 nsites_difference[16]: 1.752880e-01\nlik[98]=-35430.131030 diff=1.040069e-01 alpha:1.000000 sr2:1.570008e-12 nsites_difference[16]: 1.700509e-01\nlik[100]=-35430.032761 diff=9.826906e-02 alpha:4.000000 sr2:1.474443e-12 nsites_difference[16]: 1.649813e-01\nlikelihood: -35430.032761\n------------\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n\n    -&gt; NB output is no longer log probs of the frequency spectrum!\n    -&gt; Output is now simply the expected values! \n    -&gt; You can convert to the old format simply with log(norm(x))\n\n    -&gt; Please check that it has converged!\n    -&gt; You can add start new optimization by supplying -sfs FILE, where is &gt;FILE from this run\n    -&gt; -maxIter INT -tole FLOAT\n\n\n\n\nrealSFS fst index CEU.saf.idx YRI.saf.idx -sfs CEU.YRI.ml -fstout CEU_YRI\n\n[persaf::persaf_init] Version of CEU.saf.idx is 3\n[persaf::persaf_init] Assuming .saf.gz file is CEU.saf.gz\n[persaf::persaf_init] Assuming .saf.pos.gz file is CEU.saf.pos.gz\n[persaf::persaf_init] Version of YRI.saf.idx is 3\n[persaf::persaf_init] Assuming .saf.gz file is YRI.saf.gz\n[persaf::persaf_init] Assuming .saf.pos.gz file is YRI.saf.pos.gz\n    -&gt; args: tole:0.000000 nthreads:4 maxiter:100 nsites(block):0 start:CEU.YRI.ml chr:(null) start:-1 stop:-1 fstout:CEU_YRI oldout:0 seed:-1 bootstrap:0 resample_chr:0 whichFst:0 fold:0 ref:(null) anc:(null)\n    -&gt; nSites: 100000\n    -&gt; IMPORTANT: please make sure that your saf files haven't been folded with -fold 1 in -doSaf in angsd\n    -&gt; [reynoldFst] sfs1:198 sfs2:216 dimspace:43183 \n    -&gt; generating offset remapper lookup\n    -&gt; isSame:1 adjusting foldfactors\n    -&gt; Reading: CEU.YRI.ml assuming counts (will normalize to probs internally)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[1] from pop0:  11218\n    -&gt; Sites to keep[1] from pop1:  11218\n    -&gt; [readdata] lastread:11218 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:11218\n    -&gt; Will now do fst temp dump using a chunk of 11218\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[10] from pop0: 10005\n    -&gt; Sites to keep[10] from pop1: 10005\n    -&gt; [readdata] lastread:10005 posi:20004692\n    -&gt; Comparing positions: 1 with 0 has:10005\n    -&gt; Will now do fst temp dump using a chunk of 10005\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[11] from pop0: 11825\n    -&gt; Sites to keep[11] from pop1: 11825\n    -&gt; [readdata] lastread:11825 posi:20009117\n    -&gt; Comparing positions: 1 with 0 has:11825\n    -&gt; Will now do fst temp dump using a chunk of 11825\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[12] from pop0: 7433\n    -&gt; Sites to keep[12] from pop1: 7433\n    -&gt; [readdata] lastread:7433 posi:20008763\n    -&gt; Comparing positions: 1 with 0 has:7433\n    -&gt; Will now do fst temp dump using a chunk of 7433\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[13] from pop0: 4580\n    -&gt; Sites to keep[13] from pop1: 4580\n    -&gt; [readdata] lastread:4580 posi:20147408\n    -&gt; Comparing positions: 1 with 0 has:4580\n    -&gt; Will now do fst temp dump using a chunk of 4580\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[14] from pop0: 4269\n    -&gt; Sites to keep[14] from pop1: 4269\n    -&gt; [readdata] lastread:4269 posi:20435704\n    -&gt; Comparing positions: 1 with 0 has:4269\n    -&gt; Will now do fst temp dump using a chunk of 4269\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[16] from pop0: 8855\n    -&gt; Sites to keep[16] from pop1: 8855\n    -&gt; [readdata] lastread:8855 posi:20019440\n    -&gt; Comparing positions: 1 with 0 has:8855\n    -&gt; Will now do fst temp dump using a chunk of 8855\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[17] from pop0: 1564\n    -&gt; Sites to keep[17] from pop1: 1564\n    -&gt; [readdata] lastread:1564 posi:20012246\n    -&gt; Comparing positions: 1 with 0 has:1564\n    -&gt; Will now do fst temp dump using a chunk of 1564\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[18] from pop0: 6271\n    -&gt; Sites to keep[18] from pop1: 6271\n    -&gt; [readdata] lastread:6271 posi:20015325\n    -&gt; Comparing positions: 1 with 0 has:6271\n    -&gt; Will now do fst temp dump using a chunk of 6271\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[19] from pop0: 1406\n    -&gt; Sites to keep[19] from pop1: 1406\n    -&gt; [readdata] lastread:1406 posi:20061451\n    -&gt; Comparing positions: 1 with 0 has:1406\n    -&gt; Will now do fst temp dump using a chunk of 1406\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[2] from pop0:  9853\n    -&gt; Sites to keep[2] from pop1:  9853\n    -&gt; [readdata] lastread:9853 posi:20016996\n    -&gt; Comparing positions: 1 with 0 has:9853\n    -&gt; Will now do fst temp dump using a chunk of 9853\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[20] from pop0: 11636\n    -&gt; Sites to keep[20] from pop1: 11636\n    -&gt; [readdata] lastread:11636 posi:20014854\n    -&gt; Comparing positions: 1 with 0 has:11636\n    -&gt; Will now do fst temp dump using a chunk of 11636\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[21] from pop0: 7716\n    -&gt; Sites to keep[21] from pop1: 7716\n    -&gt; [readdata] lastread:7716 posi:20023741\n    -&gt; Comparing positions: 1 with 0 has:7716\n    -&gt; Will now do fst temp dump using a chunk of 7716\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[22] from pop0: 3014\n    -&gt; Sites to keep[22] from pop1: 3014\n    -&gt; [readdata] lastread:3014 posi:20010629\n    -&gt; Comparing positions: 1 with 0 has:3014\n    -&gt; Will now do fst temp dump using a chunk of 3014\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[3] from pop0:  7606\n    -&gt; Sites to keep[3] from pop1:  7606\n    -&gt; [readdata] lastread:7606 posi:20003128\n    -&gt; Comparing positions: 1 with 0 has:7606\n    -&gt; Will now do fst temp dump using a chunk of 7606\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[4] from pop0:  6424\n    -&gt; Sites to keep[4] from pop1:  6424\n    -&gt; [readdata] lastread:6424 posi:20064982\n    -&gt; Comparing positions: 1 with 0 has:6424\n    -&gt; Will now do fst temp dump using a chunk of 6424\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[5] from pop0:  3210\n    -&gt; Sites to keep[5] from pop1:  3210\n    -&gt; [readdata] lastread:3210 posi:20115852\n    -&gt; Comparing positions: 1 with 0 has:3210\n    -&gt; Will now do fst temp dump using a chunk of 3210\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[6] from pop0:  9615\n    -&gt; Sites to keep[6] from pop1:  9615\n    -&gt; [readdata] lastread:9615 posi:20001826\n    -&gt; Comparing positions: 1 with 0 has:9615\n    -&gt; Will now do fst temp dump using a chunk of 9615\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[7] from pop0:  8824\n    -&gt; Sites to keep[7] from pop1:  8824\n    -&gt; [readdata] lastread:8824 posi:20006767\n    -&gt; Comparing positions: 1 with 0 has:8824\n    -&gt; Will now do fst temp dump using a chunk of 8824\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[8] from pop0:  16633\n    -&gt; Sites to keep[8] from pop1:  16633\n    -&gt; [readdata] lastread:16633 posi:20007911\n    -&gt; Comparing positions: 1 with 0 has:16633\n    -&gt; Will now do fst temp dump using a chunk of 16633\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[9] from pop0:  6247\n    -&gt; Sites to keep[9] from pop1:  6247\n    -&gt; [readdata] lastread:6247 posi:20000499\n    -&gt; Comparing positions: 1 with 0 has:6247\n    -&gt; Will now do fst temp dump using a chunk of 6247\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; fst index finished with no errors!\n         Example runs:\n     realSFS fst stats  CEU_YRI.fst.idx \n     realSFS fst stats2 CEU_YRI.fst.idx \n\n\n\nNow we will compute the average Fst for CEU vs, YRI populations.\n\nrealSFS fst stats CEU_YRI.fst.idx \n\n    -&gt; Assuming idxname:CEU_YRI.fst.idx\n    -&gt; Assuming .fst.gz file: CEU_YRI.fst.gz\n    -&gt; FST.Unweight[nObs:158204]:0.008683 Fst.Weight:0.134346\n0.008683    0.134346\n\n\n\nThe average Fst is not very informative as we do not know what loci the selection signal comes from. To figure tis out, we will have to compute Fst for CEU vs, YRI populations in a sliding window.\n\nrealSFS fst stats2 CEU_YRI.fst.idx -win 50 -step 10 &gt; slidingwindow_win50_step10\n\n    -&gt; Assuming idxname:CEU_YRI.fst.idx\n    -&gt; Assuming .fst.gz file: CEU_YRI.fst.gz\n    -&gt; args: tole:0.000000 nthreads:4 maxiter:100 nsites(block):0 start:(null) chr:(null) start:-1 stop:-1 fstout:(null) oldout:0 seed:-1 bootstrap:0 resample_chr:0 whichFst:0 fold:0 ref:(null) anc:(null)\nwin:50 step:10\nnSites:11218\nnSites:10005\nnSites:11825\nnSites:7433\nnSites:4580\nnSites:4269\nnSites:8855\nnSites:1564\nnSites:6271\nnSites:1406\nnSites:9853\nnSites:11636\nnSites:7716\nnSites:3014\nnSites:7606\nnSites:6424\nnSites:3210\nnSites:9615\nnSites:8824\nnSites:16633\nnSites:6247\n\n\n\nAnd finally we will plot the results using custom R scripts:\n\ndf &lt;- read.delim(\"slidingwindow_win50_step10\", header = FALSE)\ndf &lt;- df[-1, ]\ndf$V2 &lt;- as.numeric(df$V2)\ndf$V3 &lt;- as.numeric(df$V3)\ndf$V5 &lt;- as.numeric(df$V5)\ndf &lt;- df[order(df$V2, df$V3), ]\nrownames(df) &lt;- seq(1, dim(df)[1], 1)\nplot(df$V5, col = df$V2, xlab = \"Chromosomes\", ylab = \"Fst\", xaxt = \"n\")\nmyticks &lt;- as.numeric(rownames(df[!duplicated(df$V2), ]))\naxis(side = 1, at = myticks, labels = seq(1, 21, 1))"
  },
  {
    "objectID": "exercises/population_structure/pca_admixture_1000G.html#pca-on-1000g-data",
    "href": "exercises/population_structure/pca_admixture_1000G.html#pca-on-1000g-data",
    "title": "PCA and Admixture for 1000 genomes (1000G) project",
    "section": "",
    "text": "We will be using low-coverage Phase 1 human from from the 1000G project. The data are not heavy, so easy to download and work with, and one can test a few popgen methods using these real data. First, you will need to make a directory, for example population_structure, for running the population structure analysis.\n\ncd /home/nikolay/Documents/Teaching/PopGen_2023\nmkdir population_structure\ncd population_structure\npwd\n\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure\n\n\n\nNext, we will download the bam-alignments from the 1000G project and unzip them.\n\nwget https://export.uppmax.uu.se/uppstore2018095/1000G.tar.gz\n#wget https://export.uppmax.uu.se/naiss2023-22-1084/1000G.tar.gz\ntar -xzf 1000G.tar.gz\nrm 1000G.tar.gz\n\n--2023-11-07 13:14:16--  https://export.uppmax.uu.se/uppstore2018095/1000G.tar.gz\nResolving export.uppmax.uu.se (export.uppmax.uu.se)... 89.44.248.44\nConnecting to export.uppmax.uu.se (export.uppmax.uu.se)|89.44.248.44|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 294605223 (281M) [application/x-gzip]\nSaving to: ‘1000G.tar.gz’\n\n1000G.tar.gz          0%[                    ]       0  --.-KB/s               1000G.tar.gz          1%[                    ]   2,95M  14,7MB/s               1000G.tar.gz          2%[                    ]   8,27M  20,7MB/s               1000G.tar.gz          4%[                    ]  13,65M  22,7MB/s               1000G.tar.gz          6%[&gt;                   ]  19,05M  23,8MB/s               1000G.tar.gz          9%[&gt;                   ]  26,20M  26,2MB/s               1000G.tar.gz         11%[=&gt;                  ]  33,34M  27,8MB/s               1000G.tar.gz         14%[=&gt;                  ]  40,50M  28,9MB/s               1000G.tar.gz         16%[==&gt;                 ]  47,65M  29,8MB/s               1000G.tar.gz         19%[==&gt;                 ]  54,78M  30,4MB/s               1000G.tar.gz         22%[===&gt;                ]  61,96M  31,0MB/s               1000G.tar.gz         24%[===&gt;                ]  69,09M  31,4MB/s               1000G.tar.gz         27%[====&gt;               ]  76,45M  31,8MB/s               1000G.tar.gz         29%[====&gt;               ]  83,61M  32,1MB/s               1000G.tar.gz         32%[=====&gt;              ]  91,00M  32,5MB/s               1000G.tar.gz         34%[=====&gt;              ]  98,15M  32,7MB/s    eta 6s     1000G.tar.gz         37%[======&gt;             ] 105,34M  33,8MB/s    eta 6s     1000G.tar.gz         40%[=======&gt;            ] 112,47M  34,4MB/s    eta 6s     1000G.tar.gz         42%[=======&gt;            ] 119,63M  35,3MB/s    eta 6s     1000G.tar.gz         45%[========&gt;           ] 126,79M  35,7MB/s    eta 6s     1000G.tar.gz         47%[========&gt;           ] 133,95M  35,9MB/s    eta 4s     1000G.tar.gz         50%[=========&gt;          ] 141,10M  35,9MB/s    eta 4s     1000G.tar.gz         52%[=========&gt;          ] 147,97M  35,8MB/s    eta 4s     1000G.tar.gz         55%[==========&gt;         ] 155,16M  35,8MB/s    eta 4s     1000G.tar.gz         57%[==========&gt;         ] 162,31M  35,8MB/s    eta 4s     1000G.tar.gz         60%[===========&gt;        ] 169,42M  35,8MB/s    eta 3s     1000G.tar.gz         62%[===========&gt;        ] 176,60M  35,8MB/s    eta 3s     1000G.tar.gz         65%[============&gt;       ] 183,77M  35,8MB/s    eta 3s     1000G.tar.gz         67%[============&gt;       ] 190,84M  35,7MB/s    eta 3s     1000G.tar.gz         69%[============&gt;       ] 196,58M  35,2MB/s    eta 3s     1000G.tar.gz         72%[=============&gt;      ] 203,15M  35,0MB/s    eta 2s     1000G.tar.gz         74%[=============&gt;      ] 210,30M  35,0MB/s    eta 2s     1000G.tar.gz         77%[==============&gt;     ] 217,40M  34,9MB/s    eta 2s     1000G.tar.gz         79%[==============&gt;     ] 224,59M  35,0MB/s    eta 2s     1000G.tar.gz         82%[===============&gt;    ] 231,89M  35,0MB/s    eta 2s     1000G.tar.gz         85%[================&gt;   ] 239,13M  35,0MB/s    eta 1s     1000G.tar.gz         87%[================&gt;   ] 246,30M  35,0MB/s    eta 1s     1000G.tar.gz         90%[=================&gt;  ] 253,51M  35,1MB/s    eta 1s     1000G.tar.gz         92%[=================&gt;  ] 260,66M  35,2MB/s    eta 1s     1000G.tar.gz         95%[==================&gt; ] 267,75M  35,1MB/s    eta 1s     1000G.tar.gz         97%[==================&gt; ] 274,86M  35,1MB/s    eta 0s     1000G.tar.gz        100%[===================&gt;] 280,96M  35,1MB/s    in 8,2s    \n\n2023-11-07 13:14:24 (34,4 MB/s) - ‘1000G.tar.gz’ saved [294605223/294605223]\n\n\n\n\nFor running the PCA and Admixture analyses with ANGSD, we will need to build a list of the available bam-files. It is also useful for us to check from this list what human populations are present in the Phase 1 of 1000G project.\n\ncd 1000G_bam_files\nfind $PWD -name '*.bam' &gt; ../1000G_bam_list.txt\ncd ..\nhead 1000G_bam_list.txt\n\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18543.mapped.ILLUMINA.bwa.CHB.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA20334.mapped.ILLUMINA.bwa.ASW.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18633.mapped.ILLUMINA.bwa.CHB.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12348.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12842.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA11832.mapped.ILLUMINA.bwa.CEU.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12275.mapped.ILLUMINA.bwa.CEU.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA19761.mapped.ILLUMINA.bwa.MXL.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA19213.mapped.ILLUMINA.bwa.YRI.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18558.mapped.ILLUMINA.bwa.CHB.low_coverage.20130415.bam\n\n\n\n\nwc -l 1000G_bam_list.txt\n\n435 1000G_bam_list.txt\n\n\n\nWe can see that in total our dataset includes 435 bam-files corresponding to African (YRI), European (CEU) and Asian (CHB) populations, as well as two admixed populations: African-American (ASW) and Mexican (MXL). ANGSD operates with genetic variation computed via genotype likelihoods. Therefore, we will have to perform genotype likelihoods variant calling prior to PCA and Admixture analyses. If you do not have ANGSD installed already, it can be downloaded and installed using instrictions from http://www.popgen.dk/angsd/index.php/Installation.\n\nangsd -bam 1000G_bam_list.txt -GL 2 -doMajorMinor 1 -doMaf 1 -SNP_pval 2e-6 -minMapQ 30 -minQ 20 -minInd 25 -minMaf 0.05 -doGlf 2 -out 1000G -P 5\n\n    -&gt; angsd version: 0.940-dirty (htslib: 1.16) build(Aug 23 2023 11:40:54)\n    -&gt; angsd -bam 1000G_bam_list.txt -GL 2 -doMajorMinor 1 -doMaf 1 -SNP_pval 2e-6 -minMapQ 30 -minQ 20 -minInd 25 -minMaf 0.05 -doGlf 2 -out 1000G -P 5 \n    -&gt; Inputtype is BAM/CRAM\n[multiReader] 435 samples in 435 input files\n    -&gt; SNP-filter using a pvalue: 2.000000e-06 correspond to 22.595043 likelihood units\n    -&gt; Parsing 435 number of samples \n\n    -&gt; Allocated ~ 10 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 20 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 30 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 40 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 50 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 60 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 70 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 80 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 90 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 100 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 110 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 120 million nodes to the nodepool, this is not an estimate of the memory usage\n\n    -&gt; Allocated ~ 130 million nodes to the nodepool, this is not an estimate of the memory usage\n    -&gt; Printing at chr: 7 pos:20911210 chunknumber 100 contains 2 sites -&gt; Printing at chr: 14 pos:20692360 chunknumber 200 contains 699 sites\n    -&gt; Done reading data waiting for calculations to finish\n    -&gt; Done waiting for threads\n    -&gt; Output filenames:\n        -&gt;\"1000G.arg\"\n        -&gt;\"1000G.beagle.gz\"\n        -&gt;\"1000G.mafs.gz\"\n    -&gt; Tue Nov  7 13:38:46 2023\n    -&gt; Arguments and parameters for all analysis are located in .arg file\n    -&gt; Total number of sites analyzed: 167518\n    -&gt; Number of sites retained after filtering: 1306 \n    [ALL done] cpu-time used =  150.90 sec\n    [ALL done] walltime used =  61.00 sec\n\n\n\nThe calculated genotype likelihoods for 106 variable sites are contained within the 1000G.beagle.gz file, which we are now going to use for performing PCA analysis. The second returned file, 1000G.mafs.gz, contains information about allele frequencies of the identified genetic variants. You can read about advantages of doing PCA via genotype likelihoods for example here. The PCANGSD method can be installed separately from ANGSD from https://github.com/Rosemeis/pcangsd.\n\npcangsd -b 1000G.beagle.gz -o pca_1000G -t 4\n\n-------------------------------------\nPCAngsd v1.2\nJonas Meisner and Anders Albrechtsen.\nUsing 4 thread(s).\n-------------------------------------\n\nParsing Beagle file.\nLoaded 1306 sites and 435 individuals.\nEstimating minor allele frequencies.\nEM (MAF) converged at iteration: 16\nNumber of sites after MAF filtering (0.05): 1306\n\nEstimating covariance matrix.\nUsing 15 principal components (MAP test).\nIndividual allele frequencies estimated (1).\nIndividual allele frequencies estimated (2).    RMSE=0.066385679\nIndividual allele frequencies estimated (3).    RMSE=0.050454147\nIndividual allele frequencies estimated (4).    RMSE=0.006292501\nIndividual allele frequencies estimated (5).    RMSE=0.025063241\nIndividual allele frequencies estimated (6).    RMSE=0.003102337\nIndividual allele frequencies estimated (7).    RMSE=0.024891028\nIndividual allele frequencies estimated (8).    RMSE=0.002931002\nIndividual allele frequencies estimated (9).    RMSE=0.024905935\nIndividual allele frequencies estimated (10).   RMSE=0.003440379\nIndividual allele frequencies estimated (11).   RMSE=0.024913993\nIndividual allele frequencies estimated (12).   RMSE=0.002420334\nIndividual allele frequencies estimated (13).   RMSE=0.002137294\nIndividual allele frequencies estimated (14).   RMSE=0.001955432\nIndividual allele frequencies estimated (15).   RMSE=0.001708493\nIndividual allele frequencies estimated (16).   RMSE=0.001492948\nIndividual allele frequencies estimated (17).   RMSE=0.001377949\nIndividual allele frequencies estimated (18).   RMSE=0.024781208\nIndividual allele frequencies estimated (19).   RMSE=0.001125538\nIndividual allele frequencies estimated (20).   RMSE=0.02478423\nIndividual allele frequencies estimated (21).   RMSE=0.000906437\nIndividual allele frequencies estimated (22).   RMSE=0.000914994\nIndividual allele frequencies estimated (23).   RMSE=0.000651902\nIndividual allele frequencies estimated (24).   RMSE=0.000590639\nIndividual allele frequencies estimated (25).   RMSE=0.000566323\nIndividual allele frequencies estimated (26).   RMSE=0.024761193\nIndividual allele frequencies estimated (27).   RMSE=0.000427994\nIndividual allele frequencies estimated (28).   RMSE=0.000424277\nIndividual allele frequencies estimated (29).   RMSE=0.00039096\nIndividual allele frequencies estimated (30).   RMSE=0.000348833\nIndividual allele frequencies estimated (31).   RMSE=0.000310296\nIndividual allele frequencies estimated (32).   RMSE=0.000292033\nIndividual allele frequencies estimated (33).   RMSE=0.000268337\nIndividual allele frequencies estimated (34).   RMSE=0.024759974\nIndividual allele frequencies estimated (35).   RMSE=0.000225774\nIndividual allele frequencies estimated (36).   RMSE=0.000209186\nIndividual allele frequencies estimated (37).   RMSE=0.000194486\nIndividual allele frequencies estimated (38).   RMSE=0.000179259\nIndividual allele frequencies estimated (39).   RMSE=0.000164353\nIndividual allele frequencies estimated (40).   RMSE=0.000144426\nIndividual allele frequencies estimated (41).   RMSE=0.000147983\nIndividual allele frequencies estimated (42).   RMSE=0.000143973\nIndividual allele frequencies estimated (43).   RMSE=0.000138792\nIndividual allele frequencies estimated (44).   RMSE=0.000135654\nIndividual allele frequencies estimated (45).   RMSE=0.000153877\nIndividual allele frequencies estimated (46).   RMSE=0.000120664\nIndividual allele frequencies estimated (47).   RMSE=0.000112655\nIndividual allele frequencies estimated (48).   RMSE=0.000110528\nIndividual allele frequencies estimated (49).   RMSE=0.000133146\nIndividual allele frequencies estimated (50).   RMSE=0.000102072\nIndividual allele frequencies estimated (51).   RMSE=0.000100332\nIndividual allele frequencies estimated (52).   RMSE=0.024759417\nIndividual allele frequencies estimated (53).   RMSE=8.5162e-05\nIndividual allele frequencies estimated (54).   RMSE=8.0157e-05\nIndividual allele frequencies estimated (55).   RMSE=7.5776e-05\nIndividual allele frequencies estimated (56).   RMSE=7.2006e-05\nIndividual allele frequencies estimated (57).   RMSE=0.024759391\nIndividual allele frequencies estimated (58).   RMSE=6.5975e-05\nIndividual allele frequencies estimated (59).   RMSE=6.2556e-05\nIndividual allele frequencies estimated (60).   RMSE=6.0224e-05\nIndividual allele frequencies estimated (61).   RMSE=5.7719e-05\nIndividual allele frequencies estimated (62).   RMSE=5.5379e-05\nIndividual allele frequencies estimated (63).   RMSE=5.3232e-05\nIndividual allele frequencies estimated (64).   RMSE=5.0864e-05\nIndividual allele frequencies estimated (65).   RMSE=4.9148e-05\nIndividual allele frequencies estimated (66).   RMSE=4.7062e-05\nIndividual allele frequencies estimated (67).   RMSE=4.5683e-05\nIndividual allele frequencies estimated (68).   RMSE=4.4471e-05\nIndividual allele frequencies estimated (69).   RMSE=5.0811e-05\nIndividual allele frequencies estimated (70).   RMSE=4.275e-05\nIndividual allele frequencies estimated (71).   RMSE=4.1382e-05\nIndividual allele frequencies estimated (72).   RMSE=4.005e-05\nIndividual allele frequencies estimated (73).   RMSE=3.9036e-05\nIndividual allele frequencies estimated (74).   RMSE=3.7008e-05\nIndividual allele frequencies estimated (75).   RMSE=3.5606e-05\nIndividual allele frequencies estimated (76).   RMSE=3.4998e-05\nIndividual allele frequencies estimated (77).   RMSE=3.3238e-05\nIndividual allele frequencies estimated (78).   RMSE=3.3203e-05\nIndividual allele frequencies estimated (79).   RMSE=3.0969e-05\nIndividual allele frequencies estimated (80).   RMSE=3.0605e-05\nIndividual allele frequencies estimated (81).   RMSE=2.9137e-05\nIndividual allele frequencies estimated (82).   RMSE=2.8265e-05\nIndividual allele frequencies estimated (83).   RMSE=2.8226e-05\nIndividual allele frequencies estimated (84).   RMSE=2.6588e-05\nIndividual allele frequencies estimated (85).   RMSE=2.6364e-05\nIndividual allele frequencies estimated (86).   RMSE=2.5135e-05\nIndividual allele frequencies estimated (87).   RMSE=2.4293e-05\nIndividual allele frequencies estimated (88).   RMSE=2.3529e-05\nIndividual allele frequencies estimated (89).   RMSE=2.2974e-05\nIndividual allele frequencies estimated (90).   RMSE=2.1807e-05\nIndividual allele frequencies estimated (91).   RMSE=2.1036e-05\nIndividual allele frequencies estimated (92).   RMSE=2.1025e-05\nIndividual allele frequencies estimated (93).   RMSE=2.0272e-05\nIndividual allele frequencies estimated (94).   RMSE=1.9758e-05\nIndividual allele frequencies estimated (95).   RMSE=1.9355e-05\nIndividual allele frequencies estimated (96).   RMSE=1.8164e-05\nIndividual allele frequencies estimated (97).   RMSE=1.8058e-05\nIndividual allele frequencies estimated (98).   RMSE=1.7484e-05\nIndividual allele frequencies estimated (99).   RMSE=1.7081e-05\nIndividual allele frequencies estimated (100).  RMSE=1.6462e-05\nIndividual allele frequencies estimated (101).  RMSE=1.6259e-05\nPCAngsd did not converge!\nSaved covariance matrix as pca_1000G.cov\n\n\nTotal elapsed time: 0m3s\n\n\n\nA peculiarity of computing PCA via ANGSD is that it does not directly generates a PCA plot but returns a variance-covariance matrix pca_1000G.cov which you will have to manually eigen-value-decompose and plot the eigen vectors in R. Note, that in order to color data points on the PCA plot, we will parse the list of bam-files from above in R, and extract the populations labels.\n\nsetwd(\"/home/nikolay/Documents/Teaching/PopGen_2023/population_structure\")\n\nC &lt;- as.matrix(read.table(\"pca_1000G.cov\"))\ne &lt;- eigen(C)\npops &lt;- readLines(\"1000G_bam_list.txt\")\npops &lt;- sapply(strsplit(pops, \"\\\\.\"), function(x) x[6])\nmycolor &lt;- rep(\"red\", length(pops))\nmycolor[pops == \"CEU\"] &lt;- \"blue\"\nmycolor[pops == \"CHB\"] &lt;- \"green\"\nmycolor[pops == \"MXL\"] &lt;- \"brown\"\nmycolor[pops == \"ASW\"] &lt;- \"magenta\"\nplot(e$vectors[, 1:2], xlab = \"PC1\", ylab = \"PC2\", main = \"PCA 1000G Project\", col = mycolor, pch = 19)\nlegend(\"bottomright\", c(\"YRI\", \"CEU\", \"CHB\", \"MXL\", \"ASW\"), fill = c(\"red\", \"blue\", \"green\", \"brown\", \"magenta\"), cex = 1, inset = 0.02)\n\n\n\n\n\n\n\n\nAs expected, we have three clear clusters (main sources of variation) corresponding to African (YRI), European (CEU) and Asian (CHB) populations, with the admixed populations falling in between. Let us see that this conclusion can be further confirmed from the Admixture analysis in the next section."
  },
  {
    "objectID": "exercises/population_structure/pca_admixture_1000G.html#admixture-on-1000g-data",
    "href": "exercises/population_structure/pca_admixture_1000G.html#admixture-on-1000g-data",
    "title": "PCA and Admixture for 1000 genomes (1000G) project",
    "section": "",
    "text": "In this section, we will perform admixture analysis using the genetic variation data from 1000G project identified in the previous section, i.e. the file 1000G.beagle.gz. We will keep using the genotype likelihoods approach with ANGSD, and utilize NGSadmix, which is a tool within ANGSD. You do not need to install NGSadmix separetely as it is installed together with ANGSD, however, in case there are problems, the NGSadmix executable can be found within pcangsd/misc and launched from there. Please note that below we explicitly ask NGSadmix to detect K = 3 clusters.\n\nNGSadmix -likes 1000G.beagle.gz -K 3 -minMaf 0.05 -seed 1 -o 1000G\n\nInput: lname=1000G.beagle.gz nPop=3, fname=(null) qname=(null) outfiles=1000G\nSetup: seed=1 nThreads=1 method=1\nConvergence: maxIter=2000 tol=0.000010 tolLike50=0.100000 dymBound=0\nFilters: misTol=0.050000 minMaf=0.050000 minLrt=0.000000 minInd=0\nInput file has dim: nsites=1306 nind=435\nInput file has dim (AFTER filtering): nsites=1306 nind=435\niter[start] like is=725129.713622\niter[50] like is=-454493.026878 thres=0.000841\niter[100] like is=-454474.788034 thres=0.000032\nEM accelerated has reached convergence with tol 0.000010\nbest like=-454474.752968 after 115 iterations\n    -&gt; Dumpedfiles are: 1000G.log\n    -&gt; Dumpedfiles are: 1000G.qopt\n    -&gt; Dumpedfiles are: 1000G.fopt.gz\n    [ALL done] cpu-time used =  4.84 sec\n    [ALL done] walltime used =  5.00 sec\n\n\n\nNGSadmix produces two files: 1000G.qopt and 1000G.fopt.gz containing admixture proportions and allele frequencies, respectively. If we look inside the 1000G.qopt files, we will see that for eahc of the 435 data points it contains fractions (i.e. contributions) of each of the 3 clusters that we required NGSadmix to identify.\n\nhead 1000G.qopt\n\n0.00543120337380969750 0.03047764250291678037 0.96409115412327339723 \n0.39746657097866411323 0.59699325992555196674 0.00554016909578402498 \n0.00291473396727394071 0.00000000099999999999 0.99708526503272598696 \n0.89272766803245084954 0.00000008404621942802 0.10727224792132973585 \n0.87148184717709176184 0.12851815182290812767 0.00000000099999999997 \n0.81529873054609225402 0.15780315987658605215 0.02689810957732174240 \n0.83248589650022153386 0.07729402969534844570 0.09022007380443013147 \n0.71004516603356415683 0.00000000099999999998 0.28995483296643576043 \n0.09294217159488990521 0.90705782740511009532 0.00000000099999999997 \n0.00000000099999999994 0.00000000099999999994 0.99999999799999994554 \n\n\n\nFinally, we will plot the results using some helping functions from the ANGSD and NGSadmix developers.\n\nsetwd(\"/home/nikolay/Documents/Teaching/PopGen_2023/population_structure\")\n\npops &lt;- readLines(\"1000G_bam_list.txt\")\npops &lt;- sapply(strsplit(pops, \"\\\\.\"), function(x) x[6])\nsource(\"https://raw.githubusercontent.com/GenisGE/evalAdmix/master/visFuns.R\")\nqopts &lt;- read.table(\"1000G.qopt\")\nord &lt;- orderInds(pop = pops, q = qopts, popord = c(\"YRI\", \"ASW\", \"CEU\", \"MXL\", \"CHB\"))\nbarplot(t(qopts)[, ord], col = c(3, 2, 4), las = 2, space = 0, border = NA)\ntext(sort(tapply(1:length(pops), pops[ord], mean)), 0.1, unique(pops[ord]))\nabline(v = cumsum(sapply(unique(pops[ord]), function(x) {sum(pops[ord] == x)})), col = 1, lwd = 1.2)\n\n\n\n\n\n\n\n\nAgain, we see three nearly unadmixed populations: YRI, CHB and CEU, and two admixed populations: MXL (mixture of CEU and CHB) and ASW (mixture of YRI and CEU). Therefore, one can infer for each individual, how much this individual is admixed and what are the populations contributing to the admixture."
  },
  {
    "objectID": "exercises/population_structure/pca_admixture_1000G.html#fst-analysis-on-1000g-data",
    "href": "exercises/population_structure/pca_admixture_1000G.html#fst-analysis-on-1000g-data",
    "title": "PCA and Admixture for 1000 genomes (1000G) project",
    "section": "",
    "text": "In this section, we will perform Fst analysis via genotype likelihoods using the 1000G data, i.e. we will compare allele frequencies between European (CEU) and African (YRI) populations. The way ANGSD does it, it first computes Site Frequency Spectra (SFS) for CEU and YRI individually. So we will have to subset the list of bam-files to CEU and YRI individuals only and compute SFS. Below, we will start with CEU:\n\ngrep CEU 1000G_bam_list.txt &gt; 1000G_CEU_bam_list.txt\nwc -l 1000G_CEU_bam_list.txt\nhead 1000G_CEU_bam_list.txt\n\n99 1000G_CEU_bam_list.txt\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12348.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12842.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA11832.mapped.ILLUMINA.bwa.CEU.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12275.mapped.ILLUMINA.bwa.CEU.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA11830.mapped.ILLUMINA.bwa.CEU.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12777.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12287.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA07357.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA12286.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA11930.mapped.ILLUMINA.bwa.CEU.low_coverage.20130415.bam\n\n\n\n\nangsd -b 1000G_CEU_bam_list.txt -anc anc.fa -out CEU -dosaf 1 -gl 1\n\n    -&gt; angsd version: 0.940-dirty (htslib: 1.16) build(Aug 23 2023 11:40:54)\n    -&gt; angsd -b 1000G_CEU_bam_list.txt -anc anc.fa -out CEU -dosaf 1 -gl 1 \n    -&gt; Inputtype is BAM/CRAM\n[multiReader] 99 samples in 99 input files\n    -&gt; Reading fasta: anc.fa\n    -&gt; Parsing 99 number of samples \n    -&gt; Printing at chr: 7 pos:20690960 chunknumber 100 contains 621 sites   -&gt; Printing at chr: 13 pos:20676861 chunknumber 200 contains 833 sites\n    -&gt; Done reading data waiting for calculations to finish\n    -&gt; Done waiting for threads\n    -&gt; Output filenames:\n        -&gt;\"CEU.arg\"\n        -&gt;\"CEU.saf.gz\"\n        -&gt;\"CEU.saf.pos.gz\"\n        -&gt;\"CEU.saf.idx\"\n    -&gt; Tue Nov  7 14:21:40 2023\n    -&gt; Arguments and parameters for all analysis are located in .arg file\n    -&gt; Total number of sites analyzed: 163347\n    -&gt; Number of sites retained after filtering: 162624 \n    [ALL done] cpu-time used =  41.99 sec\n    [ALL done] walltime used =  42.00 sec\n\n\n\nNow, we will subset YRI individuals and compute SFS for the African population.\n\ngrep YRI 1000G_bam_list.txt &gt; 1000G_YRI_bam_list.txt\nwc -l 1000G_YRI_bam_list.txt\nhead 1000G_YRI_bam_list.txt\n\n108 1000G_YRI_bam_list.txt\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA19213.mapped.ILLUMINA.bwa.YRI.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18504.mapped.ILLUMINA.bwa.YRI.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA19108.mapped.ILLUMINA.bwa.YRI.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA19238.mapped.ILLUMINA.bwa.YRI.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA19204.mapped.ILLUMINA.bwa.YRI.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18516.mapped.ILLUMINA.bwa.YRI.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18878.mapped.ILLUMINA.bwa.YRI.low_coverage.20130415.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18874.mapped.ILLUMINA.bwa.YRI.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18488.mapped.ILLUMINA.bwa.YRI.low_coverage.20120522.bam\n/home/nikolay/Documents/Teaching/PopGen_2023/population_structure/1000G_bam_files/small.NA18861.mapped.ILLUMINA.bwa.YRI.low_coverage.20130415.bam\n\n\n\n\nangsd -b 1000G_YRI_bam_list.txt -anc anc.fa -out YRI -dosaf 1 -gl 1\n\n    -&gt; angsd version: 0.940-dirty (htslib: 1.16) build(Aug 23 2023 11:40:54)\n    -&gt; angsd -b 1000G_YRI_bam_list.txt -anc anc.fa -out YRI -dosaf 1 -gl 1 \n    -&gt; Inputtype is BAM/CRAM\n[multiReader] 108 samples in 108 input files\n    -&gt; Reading fasta: anc.fa\n    -&gt; Parsing 108 number of samples \n    -&gt; Printing at chr: 8 pos:20152114 chunknumber 100 contains 597 sites   -&gt; Printing at chr: 16 pos:20080879 chunknumber 200 contains 601 sites\n    -&gt; Done reading data waiting for calculations to finish\n    -&gt; Done waiting for threads\n    -&gt; Output filenames:\n        -&gt;\"YRI.arg\"\n        -&gt;\"YRI.saf.gz\"\n        -&gt;\"YRI.saf.pos.gz\"\n        -&gt;\"YRI.saf.idx\"\n    -&gt; Tue Nov  7 14:22:50 2023\n    -&gt; Arguments and parameters for all analysis are located in .arg file\n    -&gt; Total number of sites analyzed: 159100\n    -&gt; Number of sites retained after filtering: 158453 \n    [ALL done] cpu-time used =  44.02 sec\n    [ALL done] walltime used =  44.00 sec\n\n\n\n\nrealSFS CEU.saf.idx YRI.saf.idx &gt; CEU.YRI.ml\n\n[persaf::persaf_init] Version of CEU.saf.idx is 3\n[persaf::persaf_init] Assuming .saf.gz file is CEU.saf.gz\n[persaf::persaf_init] Assuming .saf.pos.gz file is CEU.saf.pos.gz\n[persaf::persaf_init] Version of YRI.saf.idx is 3\n[persaf::persaf_init] Assuming .saf.gz file is YRI.saf.gz\n[persaf::persaf_init] Assuming .saf.pos.gz file is YRI.saf.pos.gz\n    -&gt; args: tole:0.000000 nthreads:4 maxiter:100 nsites(block):0 start:(null) chr:(null) start:-1 stop:-1 fstout:(null) oldout:0 seed:-1 bootstrap:0 resample_chr:0 whichFst:0 fold:0 ref:(null) anc:(null)\n[main] Multi SFS is 'still' under development. Please report strange behaviour.\n    -&gt; The choice of -nSites will require atleast: 45.203266 megabyte memory, that is at least: 0.28% of total memory\n    -&gt; dim(CEU.saf.idx):199\n    -&gt; dim(YRI.saf.idx):217\n    -&gt; Dimension of parameter space: 43183\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:1\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[1] from pop0:  11218\n    -&gt; Sites to keep[1] from pop1:  11218\n    -&gt; [readdata] lastread:11218 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:11218\n    -&gt; Only read nSites: 11218 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:10\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[10] from pop0: 10005\n    -&gt; Sites to keep[10] from pop1: 10005\n    -&gt; [readdata] lastread:10005 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:21223\n    -&gt; Only read nSites: 21223 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:11\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[11] from pop0: 11825\n    -&gt; Sites to keep[11] from pop1: 11825\n    -&gt; [readdata] lastread:11825 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:33048\n    -&gt; Only read nSites: 33048 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:12\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[12] from pop0: 7433\n    -&gt; Sites to keep[12] from pop1: 7433\n    -&gt; [readdata] lastread:7433 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:40481\n    -&gt; Only read nSites: 40481 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:13\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[13] from pop0: 4580\n    -&gt; Sites to keep[13] from pop1: 4580\n    -&gt; [readdata] lastread:4580 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:45061\n    -&gt; Only read nSites: 45061 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:14\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[14] from pop0: 4269\n    -&gt; Sites to keep[14] from pop1: 4269\n    -&gt; [readdata] lastread:4269 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:49330\n    -&gt; Only read nSites: 49330 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:16\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[16] from pop0: 8855\n    -&gt; Sites to keep[16] from pop1: 8855\n    -&gt; [readdata] lastread:8855 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:58185\n    -&gt; Only read nSites: 58185 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:17\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[17] from pop0: 1564\n    -&gt; Sites to keep[17] from pop1: 1564\n    -&gt; [readdata] lastread:1564 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:59749\n    -&gt; Only read nSites: 59749 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:18\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[18] from pop0: 6271\n    -&gt; Sites to keep[18] from pop1: 6271\n    -&gt; [readdata] lastread:6271 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:66020\n    -&gt; Only read nSites: 66020 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:19\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[19] from pop0: 1406\n    -&gt; Sites to keep[19] from pop1: 1406\n    -&gt; [readdata] lastread:1406 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:67426\n    -&gt; Only read nSites: 67426 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:2\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[2] from pop0:  9853\n    -&gt; Sites to keep[2] from pop1:  9853\n    -&gt; [readdata] lastread:9853 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:77279\n    -&gt; Only read nSites: 77279 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:20\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[20] from pop0: 11636\n    -&gt; Sites to keep[20] from pop1: 11636\n    -&gt; [readdata] lastread:11636 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:88915\n    -&gt; Only read nSites: 88915 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:21\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[21] from pop0: 7716\n    -&gt; Sites to keep[21] from pop1: 7716\n    -&gt; [readdata] lastread:7716 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:96631\n    -&gt; Only read nSites: 96631 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:22\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[22] from pop0: 3014\n    -&gt; Sites to keep[22] from pop1: 3014\n    -&gt; [readdata] lastread:3014 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:99645\n    -&gt; Only read nSites: 99645 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:3\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[3] from pop0:  7606\n    -&gt; Sites to keep[3] from pop1:  7606\n    -&gt; [readdata] lastread:7606 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:107251\n    -&gt; Only read nSites: 107251 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:4\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[4] from pop0:  6424\n    -&gt; Sites to keep[4] from pop1:  6424\n    -&gt; [readdata] lastread:6424 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:113675\n    -&gt; Only read nSites: 113675 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:5\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[5] from pop0:  3210\n    -&gt; Sites to keep[5] from pop1:  3210\n    -&gt; [readdata] lastread:3210 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:116885\n    -&gt; Only read nSites: 116885 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:6\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[6] from pop0:  9615\n    -&gt; Sites to keep[6] from pop1:  9615\n    -&gt; [readdata] lastread:9615 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:126500\n    -&gt; Only read nSites: 126500 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:7\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[7] from pop0:  8824\n    -&gt; Sites to keep[7] from pop1:  8824\n    -&gt; [readdata] lastread:8824 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:135324\n    -&gt; Only read nSites: 135324 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:8\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[8] from pop0:  16633\n    -&gt; Sites to keep[8] from pop1:  16633\n    -&gt; [readdata] lastread:16633 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:151957\n    -&gt; Only read nSites: 151957 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Is in multi sfs, will now read data from chr:9\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[9] from pop0:  6247\n    -&gt; Sites to keep[9] from pop1:  6247\n    -&gt; [readdata] lastread:6247 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:158204\n    -&gt; Only read nSites: 158204 will therefore prepare next chromosome (or exit)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Will run optimization on nSites: 158204\n------------\nstartlik=-1500482.960971\nlik[2]=-51446.465409 diff=1.449036e+06 alpha:1.000000 sr2:2.565215e-01 nsites_difference[0]: 1.304900e+05\n    -&gt; Instability detected, accelerated guess is too close to bound or outside will fallback to regular EM for this step\nlik[4]=-36952.653747 diff=1.449381e+04 alpha:1.520022 sr2:1.189258e-02 nsites_difference[0]: 2.079652e+04\nlik[6]=-35693.960846 diff=1.258693e+03 alpha:1.000000 sr2:1.954655e-04 nsites_difference[0]: 2.559705e+03\nlik[8]=-35550.497375 diff=1.434635e+02 alpha:1.802902 sr2:5.252347e-06 nsites_difference[0]: 4.155786e+02\nlik[10]=-35515.651398 diff=3.484598e+01 alpha:1.000000 sr2:2.383104e-07 nsites_difference[0]: 8.639444e+01\nlik[12]=-35497.489801 diff=1.816160e+01 alpha:2.286558 sr2:1.786152e-08 nsites_difference[1]: 2.290752e+01\nlik[14]=-35485.181049 diff=1.230875e+01 alpha:1.000000 sr2:2.166627e-09 nsites_difference[1]: 8.282941e+00\nlik[16]=-35476.102765 diff=9.078283e+00 alpha:3.702718 sr2:4.923696e-10 nsites_difference[1]: 3.370521e+00\nlik[18]=-35469.117497 diff=6.985269e+00 alpha:1.000000 sr2:2.181576e-10 nsites_difference[7]: 1.982587e+00\nlik[20]=-35463.588847 diff=5.528650e+00 alpha:4.000000 sr2:1.404275e-10 nsites_difference[7]: 1.666359e+00\nlik[22]=-35459.119268 diff=4.469579e+00 alpha:1.000000 sr2:1.036972e-10 nsites_difference[7]: 1.395785e+00\nlik[24]=-35455.444426 diff=3.674842e+00 alpha:4.000000 sr2:8.067148e-11 nsites_difference[7]: 1.171575e+00\nlik[26]=-35452.380826 diff=3.063601e+00 alpha:1.000000 sr2:6.443842e-11 nsites_difference[7]: 9.876003e-01\nlik[28]=-35449.796828 diff=2.583998e+00 alpha:4.000000 sr2:5.239715e-11 nsites_difference[7]: 8.364649e-01\nlik[30]=-35447.595469 diff=2.201359e+00 alpha:1.000000 sr2:4.321692e-11 nsites_difference[7]: 7.116037e-01\nlik[32]=-35445.703737 diff=1.891731e+00 alpha:4.000000 sr2:3.608661e-11 nsites_difference[11]: 6.311199e-01\nlik[34]=-35444.065627 diff=1.638110e+00 alpha:1.000000 sr2:3.046627e-11 nsites_difference[11]: 5.900838e-01\nlik[36]=-35442.637478 diff=1.428149e+00 alpha:4.000000 sr2:2.597932e-11 nsites_difference[11]: 5.522152e-01\nlik[38]=-35441.384775 diff=1.252703e+00 alpha:1.000000 sr2:2.235567e-11 nsites_difference[11]: 5.171917e-01\nlik[40]=-35440.279895 diff=1.104880e+00 alpha:4.000000 sr2:1.939778e-11 nsites_difference[11]: 4.847370e-01\nlik[42]=-35439.300487 diff=9.794077e-01 alpha:1.000000 sr2:1.695900e-11 nsites_difference[11]: 4.546117e-01\nlik[44]=-35438.428292 diff=8.721947e-01 alpha:4.000000 sr2:1.492908e-11 nsites_difference[11]: 4.266064e-01\nlik[46]=-35437.648264 diff=7.800289e-01 alpha:1.000000 sr2:1.322427e-11 nsites_difference[11]: 4.005367e-01\nlik[48]=-35436.947904 diff=7.003600e-01 alpha:4.000000 sr2:1.178030e-11 nsites_difference[11]: 3.762390e-01\nlik[50]=-35436.316761 diff=6.311430e-01 alpha:1.000000 sr2:1.054743e-11 nsites_difference[11]: 3.535673e-01\nlik[52]=-35435.746037 diff=5.707233e-01 alpha:4.000000 sr2:9.486871e-12 nsites_difference[16]: 3.430160e-01\nlik[54]=-35435.228286 diff=5.177516e-01 alpha:1.000000 sr2:8.568103e-12 nsites_difference[16]: 3.329148e-01\nlik[56]=-35434.757167 diff=4.711190e-01 alpha:4.000000 sr2:7.766956e-12 nsites_difference[16]: 3.230556e-01\nlik[58]=-35434.327258 diff=4.299086e-01 alpha:1.000000 sr2:7.064145e-12 nsites_difference[16]: 3.134433e-01\nlik[60]=-35433.933901 diff=3.933572e-01 alpha:4.000000 sr2:6.444171e-12 nsites_difference[16]: 3.040804e-01\nlik[62]=-35433.573075 diff=3.608262e-01 alpha:1.000000 sr2:5.894488e-12 nsites_difference[16]: 2.949677e-01\nlik[64]=-35433.241296 diff=3.317786e-01 alpha:4.000000 sr2:5.404870e-12 nsites_difference[16]: 2.861046e-01\nlik[66]=-35432.935536 diff=3.057603e-01 alpha:1.000000 sr2:4.966920e-12 nsites_difference[16]: 2.774893e-01\nlik[68]=-35432.653149 diff=2.823863e-01 alpha:4.000000 sr2:4.573696e-12 nsites_difference[16]: 2.691193e-01\nlik[70]=-35432.391821 diff=2.613280e-01 alpha:1.000000 sr2:4.219417e-12 nsites_difference[16]: 2.609914e-01\nlik[72]=-35432.149517 diff=2.423047e-01 alpha:4.000000 sr2:3.899235e-12 nsites_difference[16]: 2.531018e-01\nlik[74]=-35431.924441 diff=2.250752e-01 alpha:1.000000 sr2:3.609056e-12 nsites_difference[16]: 2.454464e-01\nlik[76]=-35431.715010 diff=2.094317e-01 alpha:4.000000 sr2:3.345401e-12 nsites_difference[16]: 2.380208e-01\nlik[78]=-35431.519815 diff=1.951947e-01 alpha:1.000000 sr2:3.105296e-12 nsites_difference[16]: 2.308202e-01\nlik[80]=-35431.337606 diff=1.822086e-01 alpha:4.000000 sr2:2.886179e-12 nsites_difference[16]: 2.238396e-01\nlik[82]=-35431.167268 diff=1.703380e-01 alpha:1.000000 sr2:2.685833e-12 nsites_difference[16]: 2.170740e-01\nlik[84]=-35431.007803 diff=1.594649e-01 alpha:4.000000 sr2:2.502330e-12 nsites_difference[16]: 2.105180e-01\nlik[86]=-35430.858317 diff=1.494862e-01 alpha:1.000000 sr2:2.333982e-12 nsites_difference[16]: 2.041665e-01\nlik[88]=-35430.718006 diff=1.403111e-01 alpha:4.000000 sr2:2.179306e-12 nsites_difference[16]: 1.980140e-01\nlik[90]=-35430.586146 diff=1.318602e-01 alpha:1.000000 sr2:2.036993e-12 nsites_difference[16]: 1.920553e-01\nlik[92]=-35430.462083 diff=1.240630e-01 alpha:4.000000 sr2:1.905885e-12 nsites_difference[16]: 1.862849e-01\nlik[94]=-35430.345226 diff=1.168575e-01 alpha:1.000000 sr2:1.784948e-12 nsites_difference[16]: 1.806975e-01\nlik[96]=-35430.235037 diff=1.101884e-01 alpha:4.000000 sr2:1.673264e-12 nsites_difference[16]: 1.752880e-01\nlik[98]=-35430.131030 diff=1.040069e-01 alpha:1.000000 sr2:1.570008e-12 nsites_difference[16]: 1.700509e-01\nlik[100]=-35430.032761 diff=9.826906e-02 alpha:4.000000 sr2:1.474443e-12 nsites_difference[16]: 1.649813e-01\nlikelihood: -35430.032761\n------------\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n\n    -&gt; NB output is no longer log probs of the frequency spectrum!\n    -&gt; Output is now simply the expected values! \n    -&gt; You can convert to the old format simply with log(norm(x))\n\n    -&gt; Please check that it has converged!\n    -&gt; You can add start new optimization by supplying -sfs FILE, where is &gt;FILE from this run\n    -&gt; -maxIter INT -tole FLOAT\n\n\n\n\nrealSFS fst index CEU.saf.idx YRI.saf.idx -sfs CEU.YRI.ml -fstout CEU_YRI\n\n[persaf::persaf_init] Version of CEU.saf.idx is 3\n[persaf::persaf_init] Assuming .saf.gz file is CEU.saf.gz\n[persaf::persaf_init] Assuming .saf.pos.gz file is CEU.saf.pos.gz\n[persaf::persaf_init] Version of YRI.saf.idx is 3\n[persaf::persaf_init] Assuming .saf.gz file is YRI.saf.gz\n[persaf::persaf_init] Assuming .saf.pos.gz file is YRI.saf.pos.gz\n    -&gt; args: tole:0.000000 nthreads:4 maxiter:100 nsites(block):0 start:CEU.YRI.ml chr:(null) start:-1 stop:-1 fstout:CEU_YRI oldout:0 seed:-1 bootstrap:0 resample_chr:0 whichFst:0 fold:0 ref:(null) anc:(null)\n    -&gt; nSites: 100000\n    -&gt; IMPORTANT: please make sure that your saf files haven't been folded with -fold 1 in -doSaf in angsd\n    -&gt; [reynoldFst] sfs1:198 sfs2:216 dimspace:43183 \n    -&gt; generating offset remapper lookup\n    -&gt; isSame:1 adjusting foldfactors\n    -&gt; Reading: CEU.YRI.ml assuming counts (will normalize to probs internally)\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[1] from pop0:  11218\n    -&gt; Sites to keep[1] from pop1:  11218\n    -&gt; [readdata] lastread:11218 posi:20017990\n    -&gt; Comparing positions: 1 with 0 has:11218\n    -&gt; Will now do fst temp dump using a chunk of 11218\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[10] from pop0: 10005\n    -&gt; Sites to keep[10] from pop1: 10005\n    -&gt; [readdata] lastread:10005 posi:20004692\n    -&gt; Comparing positions: 1 with 0 has:10005\n    -&gt; Will now do fst temp dump using a chunk of 10005\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[11] from pop0: 11825\n    -&gt; Sites to keep[11] from pop1: 11825\n    -&gt; [readdata] lastread:11825 posi:20009117\n    -&gt; Comparing positions: 1 with 0 has:11825\n    -&gt; Will now do fst temp dump using a chunk of 11825\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[12] from pop0: 7433\n    -&gt; Sites to keep[12] from pop1: 7433\n    -&gt; [readdata] lastread:7433 posi:20008763\n    -&gt; Comparing positions: 1 with 0 has:7433\n    -&gt; Will now do fst temp dump using a chunk of 7433\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[13] from pop0: 4580\n    -&gt; Sites to keep[13] from pop1: 4580\n    -&gt; [readdata] lastread:4580 posi:20147408\n    -&gt; Comparing positions: 1 with 0 has:4580\n    -&gt; Will now do fst temp dump using a chunk of 4580\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[14] from pop0: 4269\n    -&gt; Sites to keep[14] from pop1: 4269\n    -&gt; [readdata] lastread:4269 posi:20435704\n    -&gt; Comparing positions: 1 with 0 has:4269\n    -&gt; Will now do fst temp dump using a chunk of 4269\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[16] from pop0: 8855\n    -&gt; Sites to keep[16] from pop1: 8855\n    -&gt; [readdata] lastread:8855 posi:20019440\n    -&gt; Comparing positions: 1 with 0 has:8855\n    -&gt; Will now do fst temp dump using a chunk of 8855\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[17] from pop0: 1564\n    -&gt; Sites to keep[17] from pop1: 1564\n    -&gt; [readdata] lastread:1564 posi:20012246\n    -&gt; Comparing positions: 1 with 0 has:1564\n    -&gt; Will now do fst temp dump using a chunk of 1564\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[18] from pop0: 6271\n    -&gt; Sites to keep[18] from pop1: 6271\n    -&gt; [readdata] lastread:6271 posi:20015325\n    -&gt; Comparing positions: 1 with 0 has:6271\n    -&gt; Will now do fst temp dump using a chunk of 6271\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[19] from pop0: 1406\n    -&gt; Sites to keep[19] from pop1: 1406\n    -&gt; [readdata] lastread:1406 posi:20061451\n    -&gt; Comparing positions: 1 with 0 has:1406\n    -&gt; Will now do fst temp dump using a chunk of 1406\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[2] from pop0:  9853\n    -&gt; Sites to keep[2] from pop1:  9853\n    -&gt; [readdata] lastread:9853 posi:20016996\n    -&gt; Comparing positions: 1 with 0 has:9853\n    -&gt; Will now do fst temp dump using a chunk of 9853\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[20] from pop0: 11636\n    -&gt; Sites to keep[20] from pop1: 11636\n    -&gt; [readdata] lastread:11636 posi:20014854\n    -&gt; Comparing positions: 1 with 0 has:11636\n    -&gt; Will now do fst temp dump using a chunk of 11636\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[21] from pop0: 7716\n    -&gt; Sites to keep[21] from pop1: 7716\n    -&gt; [readdata] lastread:7716 posi:20023741\n    -&gt; Comparing positions: 1 with 0 has:7716\n    -&gt; Will now do fst temp dump using a chunk of 7716\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[22] from pop0: 3014\n    -&gt; Sites to keep[22] from pop1: 3014\n    -&gt; [readdata] lastread:3014 posi:20010629\n    -&gt; Comparing positions: 1 with 0 has:3014\n    -&gt; Will now do fst temp dump using a chunk of 3014\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[3] from pop0:  7606\n    -&gt; Sites to keep[3] from pop1:  7606\n    -&gt; [readdata] lastread:7606 posi:20003128\n    -&gt; Comparing positions: 1 with 0 has:7606\n    -&gt; Will now do fst temp dump using a chunk of 7606\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[4] from pop0:  6424\n    -&gt; Sites to keep[4] from pop1:  6424\n    -&gt; [readdata] lastread:6424 posi:20064982\n    -&gt; Comparing positions: 1 with 0 has:6424\n    -&gt; Will now do fst temp dump using a chunk of 6424\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[5] from pop0:  3210\n    -&gt; Sites to keep[5] from pop1:  3210\n    -&gt; [readdata] lastread:3210 posi:20115852\n    -&gt; Comparing positions: 1 with 0 has:3210\n    -&gt; Will now do fst temp dump using a chunk of 3210\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[6] from pop0:  9615\n    -&gt; Sites to keep[6] from pop1:  9615\n    -&gt; [readdata] lastread:9615 posi:20001826\n    -&gt; Comparing positions: 1 with 0 has:9615\n    -&gt; Will now do fst temp dump using a chunk of 9615\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[7] from pop0:  8824\n    -&gt; Sites to keep[7] from pop1:  8824\n    -&gt; [readdata] lastread:8824 posi:20006767\n    -&gt; Comparing positions: 1 with 0 has:8824\n    -&gt; Will now do fst temp dump using a chunk of 8824\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[8] from pop0:  16633\n    -&gt; Sites to keep[8] from pop1:  16633\n    -&gt; [readdata] lastread:16633 posi:20007911\n    -&gt; Comparing positions: 1 with 0 has:16633\n    -&gt; Will now do fst temp dump using a chunk of 16633\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; Done reading data from chromosome will prepare next chromosome\n    -&gt; hello Im the master merge part of realSFS. and I'll now do a tripple bypass to find intersect \n    -&gt; 1) Will set iter according to chooseChr and start and stop, and possibly using -sites\n    -&gt; Sites to keep[9] from pop0:  6247\n    -&gt; Sites to keep[9] from pop1:  6247\n    -&gt; [readdata] lastread:6247 posi:20000499\n    -&gt; Comparing positions: 1 with 0 has:6247\n    -&gt; Will now do fst temp dump using a chunk of 6247\n    -&gt; Only read nSites: 0 will therefore prepare next chromosome (or exit)\n    -&gt; Will now do fst temp dump using a chunk of 0\n    -&gt; fst index finished with no errors!\n         Example runs:\n     realSFS fst stats  CEU_YRI.fst.idx \n     realSFS fst stats2 CEU_YRI.fst.idx \n\n\n\nNow we will compute the average Fst for CEU vs, YRI populations.\n\nrealSFS fst stats CEU_YRI.fst.idx \n\n    -&gt; Assuming idxname:CEU_YRI.fst.idx\n    -&gt; Assuming .fst.gz file: CEU_YRI.fst.gz\n    -&gt; FST.Unweight[nObs:158204]:0.008683 Fst.Weight:0.134346\n0.008683    0.134346\n\n\n\nThe average Fst is not very informative as we do not know what loci the selection signal comes from. To figure tis out, we will have to compute Fst for CEU vs, YRI populations in a sliding window.\n\nrealSFS fst stats2 CEU_YRI.fst.idx -win 50 -step 10 &gt; slidingwindow_win50_step10\n\n    -&gt; Assuming idxname:CEU_YRI.fst.idx\n    -&gt; Assuming .fst.gz file: CEU_YRI.fst.gz\n    -&gt; args: tole:0.000000 nthreads:4 maxiter:100 nsites(block):0 start:(null) chr:(null) start:-1 stop:-1 fstout:(null) oldout:0 seed:-1 bootstrap:0 resample_chr:0 whichFst:0 fold:0 ref:(null) anc:(null)\nwin:50 step:10\nnSites:11218\nnSites:10005\nnSites:11825\nnSites:7433\nnSites:4580\nnSites:4269\nnSites:8855\nnSites:1564\nnSites:6271\nnSites:1406\nnSites:9853\nnSites:11636\nnSites:7716\nnSites:3014\nnSites:7606\nnSites:6424\nnSites:3210\nnSites:9615\nnSites:8824\nnSites:16633\nnSites:6247\n\n\n\nAnd finally we will plot the results using custom R scripts:\n\ndf &lt;- read.delim(\"slidingwindow_win50_step10\", header = FALSE)\ndf &lt;- df[-1, ]\ndf$V2 &lt;- as.numeric(df$V2)\ndf$V3 &lt;- as.numeric(df$V3)\ndf$V5 &lt;- as.numeric(df$V5)\ndf &lt;- df[order(df$V2, df$V3), ]\nrownames(df) &lt;- seq(1, dim(df)[1], 1)\nplot(df$V5, col = df$V2, xlab = \"Chromosomes\", ylab = \"Fst\", xaxt = \"n\")\nmyticks &lt;- as.numeric(rownames(df[!duplicated(df$V2), ]))\naxis(side = 1, at = myticks, labels = seq(1, 21, 1))"
  }
]